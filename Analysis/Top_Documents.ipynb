{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.33.6)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.25.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.10.3)\n",
      "Requirement already satisfied: numexpr in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.7.0)\n",
      "Requirement already satisfied: pytest in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: future in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: funcy in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.14)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: packaging in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.23)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.17.0->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (2.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/shruti/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/shruti/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import re     \n",
    "import numpy as np\n",
    "# Plotting tools\n",
    "!pip install pyLDAvis\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from Preprocess import Preprocess\n",
    "from Viz import Viz\n",
    "from LDA import LDA\n",
    "import tmtoolkit.topicmod.tm_gensim\n",
    "from tmtoolkit.topicmod.tm_gensim import evaluate_topic_models\n",
    "from tmtoolkit.topicmod.evaluate import results_by_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstracts(file, num_topics, raw_data, target_file):\n",
    "\n",
    "    docs = pickle.load(file)\n",
    "    print(docs)\n",
    "    data = {i: {} for i in range(num_topics)}\n",
    "    raw = pd.read_csv(raw_data, encoding = 'latin1')\n",
    "    abstracts = raw['Abstract']\n",
    "    for topicId, doc in docs.items():\n",
    "        d = doc[0]\n",
    "        for doc_ in d:\n",
    "            data[topicId][doc_] = abstracts[doc_]\n",
    "        \n",
    "    df = pd.DataFrame (data)\n",
    "    df.to_excel(target_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[313, 312, 276, 267, 275, 155, 186, 81, 289, 279]], 1: [[378, 121, 104, 356, 295, 339, 344, 424, 394, 1]], 2: [[272, 266, 25, 364, 370, 142, 139, 327, 271, 317]], 3: [[365, 88, 231, 233, 59, 208, 214, 348, 349, 161]], 4: [[406, 110, 335, 37, 434, 133, 372, 228, 229, 343]], 5: [[]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1415_top_20.pkl','rb')\n",
    "data = get_abstracts(file, 6,'Raw_data/Awards1415.csv', '1415_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[399, 198, 185, 504, 263, 343, 48, 416, 114, 385]], 1: [[132, 46, 304, 314, 129, 128, 166, 171, 205, 206]], 2: [[97, 89, 90, 341, 346, 199, 457, 477, 69, 390]], 3: [[41, 515, 537, 435, 374, 352, 396, 510, 393, 391]], 4: [[25, 541, 465, 482, 484, 529, 409, 22, 428, 372]], 5: [[209, 456, 463, 431, 497, 398, 404, 494, 189, 339]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1516_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file, 6,'Raw_data/Awards1516.csv', '1516_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[12, 13, 574, 364, 557, 617, 442, 135, 462, 620]], 1: [[640, 119, 85, 331, 395, 553, 662, 594, 338, 208]], 2: [[258, 81, 126, 292, 207, 497, 486, 287, 570, 510]], 3: [[80, 79, 533, 296, 298, 276, 249, 659, 285, 403]], 4: [[348, 239, 138, 563, 181, 26, 27, 28, 386, 83]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1617_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file, 7, 'Raw_data/Awards1617.csv', '1617_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[489, 513, 561, 445, 248, 83, 80, 82, 79, 808]], 1: [[781, 494, 261, 268, 260, 247, 418, 742, 768, 724]], 2: [[473, 603, 447, 456, 307, 289, 308, 796, 739, 408]], 3: [[402, 133, 48, 14, 360, 361, 302, 237, 277, 22]], 4: [[174, 201, 679, 705, 142, 144, 378, 250, 263, 711]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1718_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,9 ,'Raw_data/Awards1718.csv', '1718_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[518, 597, 617, 637, 363, 314, 612, 369, 387, 595]], 1: [[939, 505, 1154, 666, 664, 668, 661, 1125, 76, 411]], 2: [[456, 796, 19, 1167, 589, 475, 467, 222, 512, 1047]], 3: [[509, 323, 532, 1064, 1162, 749, 1107, 1095, 500, 717]], 4: [[177, 63, 142, 724, 665, 141, 819, 112, 113, 1090]], 5: [[504, 508, 930, 477, 124, 792, 975, 335, 885, 476]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1819_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1819.csv', '1819_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[280, 288, 1089, 1102, 730, 113, 977, 60, 1050, 116]], 1: [[298, 397, 1440, 1436, 1577, 969, 973, 235, 1599, 1464]], 2: [[572, 892, 1586, 673, 1531, 1327, 1336, 1385, 416, 1029]], 3: [[1051, 1527, 166, 164, 787, 1163, 350, 332, 1293, 1475]], 4: [[1228, 1229, 1257, 30, 29, 1176, 1177, 765, 676, 705]], 5: [[1169, 585, 819, 992, 946, 1095, 1080, 1256, 1170, 1171]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1920_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1920.csv', '1920_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[161, 335, 283, 160, 143, 345, 23, 357, 305, 24]], 1: [[77, 270, 316, 207, 211, 64, 322, 140, 209, 206]], 2: [[113, 103, 145, 67, 121, 115, 245, 99, 120, 12]], 3: [[344, 204, 236, 20, 155, 93, 189, 262, 165, 153]], 4: [[310, 61, 62, 277, 359, 218, 213, 248, 247, 186]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1314_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1314.csv', 'Top_abstracts/1314_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[104, 147, 215, 220, 284, 315, 161, 257, 97, 95]], 1: [[277, 278, 280, 205, 340, 336, 347, 256, 201, 66]], 2: [[188, 133, 172, 191, 8, 44, 270, 272, 248, 233]], 3: [[349, 353, 88, 5, 6, 38, 124, 236, 231, 321]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1213_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1213.csv', 'Top_abstracts/1213_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[16, 139, 140, 169, 174, 184, 34, 35, 33, 32]], 1: [[238, 249, 118, 120, 119, 28, 301, 79, 123, 61]], 2: [[220, 8, 190, 250, 77, 76, 265, 22, 117, 36]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1112_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1112.csv', 'Top_abstracts/1112_topics.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [[18, 14, 133, 135, 83, 211, 286, 294, 292, 5]], 1: [[82, 161, 154, 62, 112, 111, 143, 245, 277, 139]], 2: [[119, 50, 52, 51, 49, 246, 47, 201, 20, 102]]}\n"
     ]
    }
   ],
   "source": [
    "file = open('Pickled_docs/1011_top_20.pkl','rb')\n",
    "data1 = get_abstracts(file,10,'Raw_data/Awards1011.csv', 'Top_abstracts/1011_topics.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
