,AwardNumber,Title,NSFOrganization,Program(s),StartDate,LastAmendmentDate,PrincipalInvestigator,State,Organization,AwardInstrument,ProgramManager,EndDate,AwardedAmountToDate,Co-PIName(s),PIEmailAddress,OrganizationStreet,OrganizationCity,OrganizationState,OrganizationZip,OrganizationPhone,NSFDirectorate,ProgramElementCode(s),ProgramReferenceCode(s),ARRAAmount,Abstract
0,1005411,Cross-Cutting Research Workshops on Intelligent Information Systems,IIS,"Info Integration & Informatics, Robust Intelligence",09/15/2010,06/29/2015,Sanjeev Khudanpur,MD,Johns Hopkins University,Continuing grant,Tatiana Korelsky,09/30/2015,"$599,972.00","Gregory Hager, Sanjeev Khudanpur, David Yarowsky, Rene Vidal",khudanpur@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,"7364, 7495","7364, 7495, 7556",$0.00,"A series of annual research workshops on Intelligent Information Systems, centered on machine learning for speech, language and vision technologies, are being organized at Johns Hopkins University to bring together diverse ?dream teams? of leading professionals, graduate students, and undergraduates, in a truly cooperative, intensive, and substantive effort to advance the state of the science.<br/>The primary goals of the proposed workshop series are to develop machine learning principles applicable to a broad spectrum of intelligent systems, to attract students to the field and to prepare them for research by putting them to work on exciting problems alongside senior researchers in a highly collaborative environment.  Creation of research infrastructure and lasting collaborations are secondary goals.<br/>An open call for workshop project proposals is being issued each year to researchers in the worldwide IIS community. Received proposals are competitively evaluated and cooperatively refined at interactive peer review meetings, where project proponents, government representatives, and experts from related fields meet to assess their scientific merit, viability and potential impact. The graduate students attending the workshop are familiar with the field and are selected in accordance with their demonstrated performance. The undergraduates are entering seniors who are new to the field and who have shown outstanding academic promise; they are selected through a national search. The participation of undergraduates in these research programs encourages talented young scholars to pursue graduate studies in IIS.<br/>By the end of this 3-year workshop series (beginning 2010), more than a hundred individuals will have conducted intensive collaborative research: about 30 academic and industry researchers, 20 researchers from government and national laboratories, 30 graduate students, and 20 undergraduates. Additional benefits of the workshops will be the collection or creation, and dissemination of valuable tools and data for IIS research, the establishment of fruitful and long-lasting collaborations, and the cross-fertilization of ideas among the participants."
1,958576,"II-NEW: Acquiring infrastructure for Artificial Intelligence, Natural Language Processing and Information Retrieval",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,05/01/2010,03/03/2010,Jugal Kalita,CO,University of Colorado at Colorado Springs,Standard Grant,Vijayalakshmi Atluri,04/30/2012,"$195,051.00","Lisa Hines, Carmen Stavrositu",jkalita@uccs.edu,"1420, Austin Bluffs Parkway",Colorado Springs,CO,809183733,7192553153,CSE,7359,"9218, HPCC",$0.00,"This proposal seeks to obtain funding to acquire computing<br/>infrastructure to perform cross-disciplinary research in artificial<br/>intelligence, natural language processing, bioinformatics, social<br/>networks and related fields. In particular, the projects that will<br/>be supported by the infrastructure acquired include developing algorithms<br/>and architectures for large-scale ontology alignment, particularly in<br/>the biomedical domain; mining Wikipedia and similar Web-based sources<br/>for geographical, temporal and ontological information; performing<br/>named entity recognition in biomedical and other domains; performing<br/>computational motivational and content analysis of socially generated<br/>content such a blogs and micro-blogs; undertaking corpus-based computational<br/>linguistics research in under-studied and possibly endangered languages from<br/>India and other locations; developing better-performing algorithms for gene<br/>expression analysis; and developing, implementing and comparing algorithms<br/>for protein structure prediction, particularly proteins that contain<br/>coiled-coil structures. These projects deal with large amounts of data<br/>and information and processing such data and information requires large<br/>amounts of computing power. Our proposal seeks to acquire adequate and<br/>flexible computing hardware to facilitate problem-solving in these and other<br/>areas, so that current and future problems can be solved felicitously. <br/><br/>The infrastructure acquired will enable cutting-edge research by Ph.D.,<br/>Masters and undergraduate students, including REU site students, in a<br/>variety of cross-disciplinary topics that employ ideas and innovations<br/>in artificial intelligence, machine learning and information retrieval.<br/>For example, the results of our research may enable creations of systems<br/>that discover overlaps and matches among large medical ontologies so that<br/>painstakingly created domain-specific information can be fused, compared<br/>and utilized better; and may assist in creating programs that assist in<br/>automatically understanding and/or visualizing content of socially-generated<br/>Websites such as Wikipedia and Twitter.<br/><br/>For further information see the project web site at the URL:<br/>http://www.cs.uccs.edu/~kalita."
2,1025375,"EAAI-10: The First Symposium on Educational Advances in Artificial Intelligence; July 2010; Atlanta, Georgia",IIS,ROBUST INTELLIGENCE,05/15/2010,05/05/2010,Kiri Wagstaff,CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,04/30/2011,"$17,000.00",Mehran Sahami,Kiri.Wagstaff@jpl.nasa.gov,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00,"This award supports participants to EAAI-10: The First Symposium on Educational Advances in Artificial Intelligence. EAAI-10 provides a venue for researchers and educators to discuss pedagogical issues and share resources related to teaching artificial intelligence (AI) and using AI in education across a variety of curricular levels (K-12 through postgraduate training), with a natural emphasis on undergraduate and graduate teaching and learning. The symposium will seek and disseminate contributions showing how to more effectively teach AI, as well as how themes from AI may be used to enhance education more broadly. Examples of this kind of broad AI impact include its use to motivate and inspire students in introductory computing courses or as a means for fostering computational thinking. We encourage the sharing of innovative educational approaches that convey or leverage AI and its many subfields, such as robotics, machine learning, natural language, and computer vision."
5,1014908,"CIF:  Small:  Algorithms, Performance and Design for Sparsity-Enforced Learning",CCF,"Comm & Information Foundations, SIGNAL PROCESSING",08/01/2010,05/03/2012,Arye Nehorai,MO,Washington University,Standard Grant,John Cozzens,07/31/2013,"$327,217.00",,nehorai@ese.wustl.edu,CAMPUS BOX 1054,Saint Louis,MO,631304862,3147474134,CSE,"7797, 7936","7936, 9218, 9251, HPCC",$0.00,"Supervised learning is used to infer an unknown regression function from a set of training data. Applications include time-series prediction, remote sensing, medical image analysis, computer vision, face detection, text categorization, image scene classification, speech recognition, and bioinformatics. Existing learning algorithms have several drawbacks. For example, the set of basis functions usually involves unknown parameters that need to be determined empirically. The optimization problem defined by the learning task depends on a trade-off parameter that requires careful selection. Analytical performance of the existing learning methods is not well studied and the role of the set of basis functions is not yet clear. In addition, currently there is no effective way to select the set of basis functions.<br/><br/>The investigator develops a new framework of sparsity-enforced learning for regression function learning to overcome the drawbacks of existing approaches. This framework includes numerical algorithms for sparse vector estimation, tight bounds for performance analysis, and optimization procedures for dictionary design. A flexible form for the inferred function is a linear combination of basis functions, which are constructed by discretizing the unknown parameters. Algorithms are designed to learn the weight vector by convex sparsity enforcing, hierarchical Bayesian modeling and normalized maximum likelihood principle. The discretization and the sparsity enforcement enable automatic selection of most relevant basis functions with appropriate parameters. The investigator analyzes the performance of the learning framework by deriving tight bounds on the mean-squares error of the learned weights, in particular, the Cramer-Rao bound and Hammersley-Chapman-Rob bins bound. The performance bounds (and their simplifications) are employed to optimally design the overcomplete dictionary. The investigator uses the developed framework to model time series and extract knowledge from images."
6,958578,"CI-P: The ""Poor Quality"" Meetings Corpus",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,08/01/2010,07/19/2010,Adam Janin,CA,International Computer Science Institute,Standard Grant,Tatiana Korelsky,07/31/2013,"$99,308.00",,janin@icsi.berkeley.edu,1947 CENTER ST STE 600,Berkeley,CA,947044115,5106662900,CSE,7359,"9218, HPCC",$0.00,"Go to any meeting or lecture with the younger generation of researchers, business people, or government, and there is a laptop or smartphone at every seat. Each laptop and smartphone is capable not only of recording and transmitting video and audio in real time, but also of advanced analytics on the data (e.g. speech recognition, speaker identification, face detection, etc.). Yet this rich resource goes largely unexploited mostly due to lack of good training data for machine learning algorithms.<br/><br/>The first step in exploiting this resource is to collect a corpus of audio, video, and annotations of ""natural"" meetings using the participants' own laptops and cellphones, allowing both analysis of the meetings and training of machine learning algorithms. This one year planning project involves design of the corpus, including collection protocols, signals, formats, and annotations, collection of a small pilot corpus, and ongoing interaction with the community through mailing lists, forums, wikis, and a workshop hosted at ICSI in Berkeley, California. The annotations include the words spoken, events such as laughter, a telephone ringing, or a new participant entering the room, who is speaking, who appears on which camera, head and hand gestures, the participants' focus of attention, and summaries and topics.<br/><br/>Successful planning for the collection of a significant number natural meetings from a variety of settings using the participants' own laptops and cellphones allows for a new generation of analytic tools for meetings including browsing, search, collaboration tools, and teleremote aids."
7,957742,Collaborative Research:EAGER:Deep Architectures for Speech and Audio Processing,IIS,Robust Intelligence,01/01/2010,09/16/2009,Fei Sha,CA,University of Southern California,Standard Grant,Edwina L. Rissland,12/31/2011,"$50,000.00",,feisha@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,"7495, 7916, 9215, HPCC",$0.00,"Recent studies have demonstrated the powerful abilities of deep <br/>architectures for statistical pattern recognition.  Deep <br/>architectures transform their inputs through multiple layers of <br/>nonlinear processing.  Inspired by the connectivity of biological <br/>neural networks, the hidden layers of deep architectures encode <br/>hierarchical, distributed representations of complex sensory input.  <br/>Theoretical results suggest that such representations are needed to <br/>solve the most difficult problems of artificial intelligence.<br/><br/>Previous applications of deep architectures include visual object <br/>recognition, statistical language modeling, and nonlinear <br/>dimensionality reduction.  Building on these successes, this project <br/>develops new applications of deep architectures for problems in <br/>speech and audio processing.  Current front ends for these problems <br/>are dominated by traditional methods in statistical modeling and <br/>signal processing.  Deep architectures have the potential to <br/>overcome many limitations of current approaches.<br/><br/>This project has two research components with interrelated and <br/>overlapping goals.  The project's first component explores <br/>unsupervised learning in convolutional neural networks.  <br/>The goal of learning in these networks is to discover new <br/>features for audio event detection and automatic speech <br/>recognition.  The project's second component investigates <br/>the possibility of deep learning in kernel machines.  <br/>This possibility is suggested by a recently discovered family <br/>of kernel functions that mimic the computation in large, <br/>multilayer networks.<br/><br/>The project's research components are tightly integrated with <br/>its educational activities.   The project supports two graduate <br/>students, including one female student.  An important goal <br/>is to develop publicly available software for use by other <br/>researchers."
8,957560,Collaborative Research:EAGER:Deep Architectures for Speech and Audio Processing,IIS,Robust Intelligence,01/01/2010,09/16/2009,Lawrence Saul,CA,University of California-San Diego,Standard Grant,Edwina L. Rissland,12/31/2011,"$50,000.00",,saul@cs.ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,7495,"7495, 7916, 9215, HPCC",$0.00,"Recent studies have demonstrated the powerful abilities of deep architectures for statistical pattern recognition. Deep architectures transform their inputs through multiple layers of nonlinear processing. Inspired by the connectivity of biological neural networks, the hidden layers of deep architectures encode hierarchical, distributed representations of complex sensory input. Theoretical results suggest that such representations are needed to solve the most difficult problems of artificial intelligence. <br/><br/>Previous applications of deep architectures include visual object recognition, statistical language modeling, and nonlinear dimensionality reduction. Building on these successes, this project develops new applications of deep architectures for problems in speech and audio processing. Current front ends for these problems are dominated by traditional methods in statistical modeling and signal processing. Deep architectures have the potential to <br/>overcome many limitations of current approaches. <br/><br/>This project has two research components with interrelated and overlapping goals. The project's first component explores unsupervised learning in convolutional neural networks. The goal of learning in these networks is to discover new features for audio event detection and automatic speech <br/>recognition. The project's second component investigates the possibility of deep learning in kernel machines. This possibility is suggested by a recently discovered family of kernel functions that mimic the computation in large, <br/>multilayer networks. <br/><br/>The project's research components are tightly integrated with its educational activities. The project supports two graduate students, including one female student. An important goal is to develop publicly available software for use by other researchers."
10,917417,"AF: Small:  Learnability, Randomness, and Lower Bounds",CCF,COMPLEXITY & CRYPTOGRAPHY,05/15/2010,05/19/2010,John Hitchcock,WY,University of Wyoming,Standard Grant,Tracy J. Kimbrel,04/30/2015,"$300,000.00",,jhitchco@cs.uwyo.edu,1000 E. University Avenue,Laramie,WY,820712000,3077665320,CSE,7927,"9150, 9216, 9217, 9218, HPCC",$0.00,"This project is motivated by new connections between the research fields of computational complexity theory and machine learning theory.  Computational complexity theory aims to understand which problems can be solved efficiently on a computer by determining the amounts of computational resources such as CPU time, memory space, or circuit area that are required to solve problems.  At the center of this field is the famous P vs. NP question which impacts virtually every scientific and engineering discipline, given the thousands of diverse NP-complete problems that have been discovered.  Machine learning theory studies the extent to which computers can learn from data and their ability to make future predictions and classifications based on what has been learned.  Some powerful learning algorithms have been discovered, but whether computers can be programmed to accomplish many learning tasks remains an open question.<br/><br/>Both computational complexity and machine learning aim to understand the capabilities and limitations of computation, but the two fields study different types of problems and use different kinds of techniques.  This research will employ techniques and ideas from each of these two fields to impact the other field, specifically with the goal of proving ""lower bound"" results.  This research will be accomplished by making use of a new vantage point provided by algorithmic randomness to relate complexity and learning problems.  Learning algorithms will be utilized to establish lower bounds on the computational resources required to solve problems in computational complexity.  The converse direction will be investigated to apply techniques and ideas from computational complexity to show that ""attribute-efficient"" learning algorithms do not exist for certain concept classes.  Algorithmic randomness and Kolmogorov complexity will be used to improve our understanding of the capabilities and limitations of learning algorithms.<br/><br/>This research will improve our understanding of computational complexity, which is informative to many areas of science and engineering where computation plays a role.  This project aims to better understand what learning tasks can be accomplished efficiently by computers, which has applications to the foundations of artificial intelligence.  In particular, this research will identify new obstacles that must be overcome in order to design successful automatic learning systems.  A greater synergy will be developed between computational complexity theory and machine learning theory, with the benefit of laying a foundation for future collaboration and interdisciplinary work across these fields."
11,958482,II-EN: A compute cluster and software tools for Monte-Carlo methods in artificial intelligence,CNS,CCRI-CISE Cmnty Rsrch Infrstrc,07/01/2010,03/10/2010,Thomas Dietterich,OR,Oregon State University,Standard Grant,Todd Leen,06/30/2014,"$600,000.00","Prasad Tadepalli, Alan Fern, Weng-Keen Wong, Kagan Tumer",tgd@cs.orst.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7359,"9218, HPCC",$0.00,"The project supports acquisition of a hardware cluster and development of software frameworks to support Monte Carlo methods in articial intelligence, for tasks such as model compilation through machine learning over the results of Monte Carlo simulation, application of Monte Carlo methods to solve single-agent and multi-agent sequential decision making problems, and integration of machine learning methods into Monte Carlo search to improve real-time decision making. These software frameworks will include implementations of baseline and state-of-the-art algorithms for each task, with a goal of release with generic APIs and open-source availability to make it easy for other researchers to add new methods and to connect external simulators to the frameworks.  <br/><br/>The algorithms and tools have many important applications, including (a) optimization of forest management to jointly minimize the risk of catastrophic fires and maximize biological and economic benefits, (b)design and validation of multiagent control methods for reducing congestion in air traffic control, (c) design and validation of multiagent control methods for micro air vehicles, and (d)modeling spatio-temporal distribution of species to support management of endangered and threatened species. The hardware cluster and software frameworks will be integrated into the undergraduate and graduate curriculum at Oregon State University, as well as various outreach beyond Oregon State."
12,963478,RI: Medium: Collaborative Research: Game Theory Pragmatics,IIS,Robust Intelligence,07/15/2010,07/14/2010,Yoav Shoham,CA,Stanford University,Standard Grant,Hector Munoz-Avila,06/30/2014,"$590,272.00",Robert Wilson,shoham@cs.stanford.edu,450 Jane Stanford Way,Stanford,CA,943052004,6507232300,CSE,7495,7924,$0.00,"The past decade has seen unprecedented interaction between artificial intelligence and game theory, with exciting intellectual problems, technical results, and potentially important applications.  However, this thriving interaction has thus far not challenged in a fundamental way some of the basic assumptions of game theory, to include various forms of equilibrium as the fundamental strategic concept. Equilibrium specifies conditions under which the strategic choices of agents are in some sense stable. Equilibria are clever and beautiful constructs, but they embody strong idealized assumptions and as a result their applicability to complex, realistic games (i.e., formalizable 'social' interactions) is limited. Arguably computer science can provide alternative modeling foundations, or at least significantly contribute to them. <br/><br/>This project explores several complementary directions, to include: alternatives to equilibrium as game solution criteria; replacing analysis of large, complex games with analysis of their abbreviated or approximate versions; using machine-learning techniques to model the extent to which agent behavior is strategic, adaptive, or otherwise intelligent; investigating the role of strategic reasoning in controlled but rich environments, such as Computational Billiards, which involves continuous state and actions spaces as well as control uncertainty. One of the outreach and educational components of this project is organizing and participating in an annual Computational Billiards competition. Applications range from electronic commerce to social networks to peer-to-peer systems to online games, and in general all settings in which individual interests intertwine with computational elements."
13,1050168,GV: EAGER: Innovative Analysis and Visualization Approaches for Understanding Model Uncertainty,IIS,GRAPHICS & VISUALIZATION,09/01/2010,12/02/2013,Marie desJardins,MD,University of Maryland Baltimore County,Standard Grant,Maria Zemankova,08/31/2014,"$119,299.00",Penny Rheingans,mariedj@cs.umbc.edu,1000 Hilltop Circle,Baltimore,MD,212500002,4104553140,CSE,7453,"7453, 7916, 9251",$0.00,"This exploratory project strives to develop a new approach to support human understanding of the uncertainty that is inherent in the structure and predictions of complex models.Specifically, the focus in the project is on understanding several types of uncertainty that are associated with model predictions.<br/>Sample uncertainty occurs when regions of the instance space are not well represented in the training data, and predictions are therefore based on sparse information. Model instability occurs when model predictions vary, depending on the training data that was used to construct the model. Prediction variability occurs when a given observation may have noisy attributes, and this input uncertainty leads to uncertainty in the model's predictions. Novel analytical techniques are developed to create meta-models that characterize these three forms of uncertainty. To facilitate user understanding of the nature and distribution of these multiple types of uncertainty across the model space, novel visualization methods represent these meta-models in a display space. Finally, a novel evaluation methodology is used to measure whether, and in what ways, important characteristics of the meta-models are captured in the visualization display space.<br/><br/>This work develops novel techniques in the fields of machine learning and data visualization. Contributions in machine learning include more powerful methods for constructing and analyzing meta-models that characterize multiple types of uncertainty associated with predictive models. Data visualization research focuses on new approaches for representing multi-valued, probabilistic, and complex data, enabling the display of the nature and range of model predictions and uncertainty. An interdisciplinary contribution is the development of a novel methodology for evaluating the quality of model visualizations with respect to the preservation of important model and meta-model characteristics.<br/><br/>The broader impacts of this project may be grouped into three major clusters: a new model building paradigm; fostering scientific collaboration; and integrating research and education. The results are expected to provide foundations for further research is management of uncertainty in deriving models representing a wide range of phenomena. This project lays a technical groundwork that can contribute to new collaborations between the PIs and application domain experts, facilitating broad interdisciplinary collaborations. Project results will be widely disseminated via the project web site (http://maple.cs.umbc.edu/complexmodels/). Finally, through teaching and training activities, this research project is also well suited to include the introduction of undergraduates to the possibilities of research and the incorporation of project topics into the PIs' courses on visualization and artificial intelligence."
14,1018967,RI: Small: Collaborative Research: A Scalable Architecture for Image Interpretation,IIS,Robust Intelligence,09/15/2010,09/13/2010,Melanie Mitchell,OR,Portland State University,Standard Grant,Kenneth Whang,08/31/2014,"$341,269.00",,mm@pdx.edu,1600 SW 4th Ave,Portland,OR,972070751,5037259900,CSE,7495,"7923, 9102",$0.00,"Seamless understanding of the meaning of visual images is a key property of human cognition that is far beyond the abilities of current computer vision programs.  The purpose of this project is to build a computational system that captures the dynamical and interactive aspects of human vision by integrating higher-level concepts with lower-level visual perception.  If successful, this system will be able to interpret visual scenes in a way that scales well with the complexity of the scene. Current computer vision systems typically rely on relatively low-level visual information (e.g., color, texture, shape) to classify objects or determine the overall category of a scene.   Such categorization is typically done in a ""bottom-up"" fashion, in which the vision system extracts lower-level features from all parts of the scene, and subsequently analyzes the extracted features to determine which parts of the scene contain objects of interest and how those objects should be categorized.  Such systems lack the abilities to scale to large numbers of visual categories and to identify more complex visual concepts that involve spatial and abstract relationships among object categories.  Visual perception by humans is known to be a temporal process with feedback, in which lower-level visual features serve to activate higher-level concepts (or knowledge).  These active concepts, in turn, guide the perception of and attention given to lower-level visual features.  Moreover, activated concepts can spread activation to semantically related concepts (e.g., ""wheels"" might activate ""car"" or ""bicycle""; ""bicycle"" might activate ""road"" or ""rider"").    In this way there is a continual interaction between the lower and higher levels of vision, which allows the viewer to focus on and connect important aspects of a complex scene in order to perceive its meaning, without having to pay equal attention to every detail of the scene.   The system proposed here will model these aspects of human visual perception.  <br/><br/>The proposed system, called Petacat, will integrate and build on two existing projects:  the HMAX model of object recognition originally developed by Riesenhuber and Poggio, and the Copycat model of high-level perception and analogy-making, developed by Hofstadter and Mitchell.    HMAX models the ""what"" pathway of mammalian visual cortex via a feed-forward network that extracts increasingly complex textural and shape features from an image. (HMAX has been reimplemented, as the ""Petascale Artificial Neural Network"" or PANN, by the Synthetic Vision Group at Los Alamos to allow for high-performance computing on large numbers of neurons.)  Copycat implements a process of interaction between high-level concepts and lower-level perception, and has been used to model focus of attention, conceptual slippage, and analogy-making in several non-visual domains.  This project will marry the feature extraction abilities of HMAX/PANN with the higher-level interactive perceptual abilities of Copycat to build the Petacat architecture. The image interpretation abilities of Petacat will be evaluated on families of related semantic visual recognition tasks (e.g., recognizing, in a flexible, human-like way, instances of ""walking a dog"").    The evaluation part of the project will involve the creation of image databases for benchmarking semantic image-understanding systems.  The Petacat source code and benchmarking databases will be made publically available via the web."
16,953667,Career: An Adaptive Compiler for Multi-core Environments,CCF,"International Research Collab, COMPILERS, Software & Hardware Foundation, EPSCoR Co-Funding",03/01/2010,07/16/2014,John Cavazos,DE,University of Delaware,Continuing Grant,Almadena Chtchelkanova,02/28/2015,"$484,909.00",,cavazos@cis.udel.edu,210 Hullihen Hall,Newark,DE,197160099,3028312136,CSE,"7298, 7329, 7798, 9150","1045, 1187, 5918, 5980, 7329, 7942, 9150, 9151, 9218, 9251, HPCC",$0.00,"Compilers are a critical component between the software developer and the computer. They translate application written by software developers into machine code that is processed by the computer. An important task of a compiler is to optimize applications so that they run efficiently.  Traditional methods to develop optimizing compilers are ad-hoc, labor-intensive, and ineffective.  As a consequence, optimizing compilers for a new processor often produces code that achieves only a fraction of the machine?s available performance. This is especially true for today's multi-core architectures, which are parallel processors on a single chip.  This research will involve investigating techniques from the artificial intelligence community that will allow a compiler to automatically adapt and tune to new architectures.  In effect, this research will replace hand-tuning with self-tuning compilers that adapt software automatically to match the performance characteristics of each target architecture.<br/><br/>In this project, the PI proposes to explore the viability of developing adaptive compilers for multi-core environments (ACME) to allow application portability while still achieving high performance.  The PI will create a statistical auto-tuning framework to support the probabilistic representation of the following features: the benefit analysis of optimizations, the identification and prediction of the appropriate runtime environment for different optimizations, and the generation of executables that efficiently combine several optimized code versions. He will invent components to measure accurately the characteristics of applications and targeted computing systems. The PI hopes to discover techniques to replace ?traditional? optimization benefit analysis with powerful machine learning models. These models will address the broad spectrum of parallel applications and multi-core environments, and they will be able to analyze and predict benefit under different dynamic contexts."
17,958392,CI-ADDO-EN: Flexible Machine Learning for Natural Language in the MALLET Toolkit,CNS,CCRI-CISE Cmnty Rsrch Infrstrc,06/01/2010,07/17/2013,Andrew McCallum,MA,University of Massachusetts Amherst,Continuing Grant,Aidong Zhang,05/31/2016,"$650,000.00",,mccallum@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7359,"9218, HPCC",$0.00,"Natural language processing, information extraction, information<br/>integration and other text processing solutions are central components<br/>of computer science, and key tools for addressing the ever-increasing<br/>problems in information overload.  Issues of information overload are<br/>not only personal problems, but critical for business productivity,<br/>national defense, and increasingly government decision-making and<br/>transparency.<br/><br/>State-of-the-art natural language processing is increasingly based on<br/>machine learning.  However, the methodologies can be complex, and<br/>software infrastructure necessary for such systems is generally<br/>difficult to develop from scratch.  To address this need we have<br/>created MALLET (MAchine Learning for LanguagE) and FACTORIE (Factor<br/>graphs, Imperative, Extensible), open-source software toolkit that run<br/>in the Java virtual machine.  They provide many modern<br/>state-of-the-art machine learning methods, specially tuned to be<br/>scalable for the idiosyncrasies of natural language data, while also<br/>applying well to many other discrete non- language tasks.<br/><br/>The project will fill three critical gaps: (1) broadening these<br/>toolkits' applicability to new data and tasks (with better end-user<br/>interfaces for labeling, training and diagnostics), (2) greatly<br/>enhancing their research-support capabilities (with infrastructure for<br/>flexibly specifying model structures), and (3) improving their<br/>understandability and support (with new documentation, examples,<br/>online community support).<br/><br/>The project will have a direct positive impact on NLP and other<br/>machine learning research, on teaching, and on collaborative research<br/>activities.  Well-designed toolkits not only help researchers avoid<br/>duplicate implementation effort, but (a) they encourage sharing of<br/>algorithms and code, and thus also cultivate increased collaboration<br/>and intellectual flow of ideas; (b) they foster the communication of<br/>detailed clarity of algorithms and scientific reproducibility; (c)<br/>they help ""level the playing field"" by providing state-of-the-art<br/>implementations of foundational building blocks and recent methods to<br/>top-tier and small institutions alike; (d) they supply a teaching<br/>tool, not only by making it easy for students to experiment with the<br/>supplied research methodologies.  Furthermore, by providing multiple<br/>ready-to-use systems, non-programmers will have access to modern,<br/>scalable implementations of text processing tools that will spread<br/>knowledge and use of these techniques across fields, to the social<br/>sciences, humanities, and bio-medical fields.<br/><br/>For further information see the project web site at the URL:<br/>http://www.cs.umass.edu/~mccallum/nsf-mallet"
18,1018691,Collaborative Research: RI: Small: A Scalable Architecture for Image Interpretation,IIS,ROBUST INTELLIGENCE,09/15/2010,09/13/2010,Garrett Kenyon,NM,New Mexico Consortium,Standard Grant,Kenneth C. Whang,08/31/2013,"$158,946.00",,garkenyon@gmail.com,"4200 West Jemez Road, Suite 301",Los Alamos,NM,875442587,5054124200,CSE,7495,7923,$0.00,"Seamless understanding of the meaning of visual images is a key property of human cognition that is far beyond the abilities of current computer vision programs.  The purpose of this project is to build a computational system that captures the dynamical and interactive aspects of human vision by integrating higher-level concepts with lower-level visual perception.  If successful, this system will be able to interpret visual scenes in a way that scales well with the complexity of the scene. Current computer vision systems typically rely on relatively low-level visual information (e.g., color, texture, shape) to classify objects or determine the overall category of a scene.   Such categorization is typically done in a ""bottom-up"" fashion, in which the vision system extracts lower-level features from all parts of the scene, and subsequently analyzes the extracted features to determine which parts of the scene contain objects of interest and how those objects should be categorized.  Such systems lack the abilities to scale to large numbers of visual categories and to identify more complex visual concepts that involve spatial and abstract relationships among object categories.  Visual perception by humans is known to be a temporal process with feedback, in which lower-level visual features serve to activate higher-level concepts (or knowledge).  These active concepts, in turn, guide the perception of and attention given to lower-level visual features.  Moreover, activated concepts can spread activation to semantically related concepts (e.g., ""wheels"" might activate ""car"" or ""bicycle""; ""bicycle"" might activate ""road"" or ""rider"").    In this way there is a continual interaction between the lower and higher levels of vision, which allows the viewer to focus on and connect important aspects of a complex scene in order to perceive its meaning, without having to pay equal attention to every detail of the scene.   The system proposed here will model these aspects of human visual perception.  <br/><br/>The proposed system, called Petacat, will integrate and build on two existing projects:  the HMAX model of object recognition originally developed by Riesenhuber and Poggio, and the Copycat model of high-level perception and analogy-making, developed by Hofstadter and Mitchell.    HMAX models the ""what"" pathway of mammalian visual cortex via a feed-forward network that extracts increasingly complex textural and shape features from an image. (HMAX has been reimplemented, as the ""Petascale Artificial Neural Network"" or PANN, by the Synthetic Vision Group at Los Alamos to allow for high-performance computing on large numbers of neurons.)  Copycat implements a process of interaction between high-level concepts and lower-level perception, and has been used to model focus of attention, conceptual slippage, and analogy-making in several non-visual domains.  This project will marry the feature extraction abilities of HMAX/PANN with the higher-level interactive perceptual abilities of Copycat to build the Petacat architecture. The image interpretation abilities of Petacat will be evaluated on families of related semantic visual recognition tasks (e.g., recognizing, in a flexible, human-like way, instances of ""walking a dog"").    The evaluation part of the project will involve the creation of image databases for benchmarking semantic image-understanding systems.  The Petacat source code and benchmarking databases will be made publically available via the web."
20,1002507,Pilot:   Assisted Musical Composition through Functional Scaffolding,IIS,CreativeIT,08/15/2010,07/20/2010,Kenneth Stanley,FL,The University of Central Florida Board of Trustees,Standard Grant,Ephraim Glinert,07/31/2015,"$295,229.00",,kstanley@cs.ucf.edu,4000 CNTRL FLORIDA BLVD,Orlando,FL,328168005,4078230387,CSE,7788,7788,$0.00,"As a ubiquitous creative endeavor across all human cultures, musical composition is an effective microcosm for the study of creativity in general.  This project will impact computer science by showing through assisted musical composition how computers can genuinely improve upon the creative capabilities of humans alone.   By introducing an interactive framework that enables even inexperienced users to realize their creative vision, this project also helps pave the way for such systems to amplify our creative potential in other areas in the future, such as in engineering and design.  The technology that will be developed, called Functional Scaffolding for Musical Composition (FSMC), takes the unique approach of computing accompaniment for existing musical tracks (called the ?scaffold?) by generating special functions that take the scaffold as input and output accompanying tracks.  In this way, generated tracks are in effect transformations of the scaffold, allowing them to inherit the global structure and implicit nuance of the preexisting music.  The implication for computational creativity in general is thus to harness the richness of preexisting human-generated content as a seed for further elaboration.   Furthermore, the user will be provided an interactive evolutionary interface that makes it possible to search the space of such transforming functions, in effect allowing the user to continually breed and elaborate new concepts that build upon preexisting incomplete works.<br/><br/>The primary target audience for FSMC as a practical technology will be musicians who lack the resources, collaborators, or expertise to produce complete musical compositions.  For example, while a hobbyist with a keyboard might be able to compose a compelling melody, lack of expertise in other instruments may prohibit adding accompanying guitar or base.  In addition, even more experienced musicians may benefit from the capability to quickly propose accompaniment as a new means of concept generation.  In fact, existing computer programs that aid in musical composition often register millions of downloads online, demonstrating broad public interest in applications that enhance musical creativity.  In addition to dissemination through scientific conferences focusing on computational creativity, the results of this research will be released in a form compatible with such programs, thereby directly impacting the public with a practical utility and consequently raising awareness of the potential for artificial intelligence and machine learning to enhance creativity in general."
22,964681,RI: Medium: Learned Dynamic Prioritization,IIS,ROBUST INTELLIGENCE,08/15/2010,08/13/2012,Jason Eisner,MD,Johns Hopkins University,Continuing grant,Tatiana Korelsky,07/31/2014,"$899,976.00",Hal Daume,jason@cs.jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,7495,7924,$0.00,"This project uses machine learning to accelerate the execution of a class of computer programs relevant to AI.  Given a program and a class of inputs, the new methods automatically seek execution strategies that are fast while still achieving a high level of accuracy.<br/><br/>The project focuses on the main inference algorithms that underlie statistical AI: dynamic programming, belief propagation, Markov chain Monte Carlo, and backtracking search.  Each of these inference algorithms faces an enormous search space, iteratively extending or refining its picture of this space.  Each algorithm must continually choose which computational step to take next.<br/><br/>The opportunity is to learn a strategy for making these choices. Some choices are on the ""critical path"" and help the system find an accurate output, while others lead mainly to wasted work.  The learned strategy for evaluating choices in context may itself be computationally intensive, so the method learns to speed that up as well, within the same framework.<br/><br/>The project will disseminate software and will have broader impact on several fields.  The targeted algorithms are central to natural language processing, speech processing, machine vision, computational biology, health informatics and music processing.  Their ability to form a coherent global analysis of a set of observations is a hallmark of intelligence, and will enable artificial systems that aid human understanding and performance.  Speeding them up is critical as researchers develop increasingly sophisticated statistical models.<br/>Furthermore, the learning methodologies developed will be useful in other settings that attempt to learn computational or behavioral strategies."
23,963668,RI:  Medium:  Collaborative Research:  Unlocking Biologically-Inspired Computer Vision: A High-Throughput Approach,IIS,ROBUST INTELLIGENCE,09/01/2010,08/27/2010,David Cox,MA,Harvard University,Standard Grant,Kenneth C. Whang,08/31/2013,"$410,000.00",,davidcox@fas.harvard.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,CSE,7495,7924,$0.00,"This project exploits advances in parallel computing hardware and a neuroscience-informed perspective to design next-generation computer vision algorithms that aim to match a human's ability to recognize objects.  The human brain has superlative visual object recognition abilities -- humans can effortlessly identify and categorize tens of thousands of objects with high accuracy in a fraction of a second -- and a stronger connection between neuroscience and computer vision has driven new progress on machine algorithms.  However, these models have not yet achieved robust, human-level object recognition in part because the number of possible ""bio-inspired"" model configurations is enormous. Powerful models hidden in this model class have yet to be systematically characterized and the correct biological model is not known.<br/><br/>To break through this barrier, this project will leverage newly available computational tools to undertake a systematic exploration of the bio-inspired model class by using a high-throughput approach in which millions of candidate models are generated and screened for desirable object recognition properties (Objective 1).  To drive this systematic search, the project will create and employ a suite of benchmark vision tasks and performance ""report cards"" that operationally define what constitutes a good visual image representation for object recognition (Objective 2).  The highest performing visual representations harvested from these ongoing high-throughput searches will be used: for applications in other machine vision domains, to generate new experimental predictions, and to determine the underlying computing motifs that enable this high performance (Objective 3).   Preliminary results show that this approach already yields algorithms that exceed state-of-the-art performance in object recognition tasks and generalize to other visual tasks.<br/><br/>As the scale of available computational power continues to expand, this approach holds great potential to rapidly accelerate progress in computer vision, neuroscience, and cognitive science: it will create a large-scale ""laboratory"" for testing neuroscience ideas within the domain of computer vision; it will generate new, testable computational hypotheses to guide neuroscience experiments; it will produce a new kind of multidimensional image challenge suite that will be a rallying point for computer models, neuronal population studies, and behavioral investigations; and it could unleash a host of new applications."
24,1103684,III-CXT-Small: Collaborative Research:  Automatic Geomorphic Mapping and Analysis of Land Surfaces Using Pattern Recognition,IIS,Info Integration & Informatics,09/01/2010,03/07/2011,Tomasz Stepinski,OH,University of Cincinnati Main Campus,Standard Grant,Maria Zemankova,08/31/2012,"$268,523.00",,stepintz@uc.edu,"University Hall, Suite 530",Cincinnati,OH,452210222,5135564358,CSE,7364,"7364, 9216, HPCC",$0.00,"Description<br/><br/>Advances in remote sensing techniques have made available large datasets of topographic measurements pertaining to terrestrial and planetary land surfaces. However, the scientific utilization of these datasets is hampered by a lack of tools for effective automated analysis. This project seeks to develop a system for fast, objective and transparent conversion of topographic data into knowledge about land surfaces. The project has two complementary goals: 1) to develop a tool that autonomously produces geomorphic maps mimicking traditional, manually derived maps in their appearance and content, and 2) to develop a tool that classifies entire topographic scenes into characteristic landscape categories. The mapping tool is based on the object-oriented supervised classification principle. A number of novel solutions, including semi-supervised learning, meta-learning, and a wrapping technique coupling classification and segmentation, are proposed to address challenges posed by the specificity of topographic data. The scene classification tool is based on information-theoretic metrics and incorporates novel solutions to problems posed by the raster character of topographic datasets.<br/><br/>Intellectual Merit<br/><br/>The project employs a novel fusion of machine learning and computer vision techniques to open new possibilities. In the process of constructing the mapping and classifying tools, novel machine learning methodologies will be developed and tested. The products of this research will enable a qualitatively new type of analysis of land surface topography: the large scale statistical comparison of spatial distribution of landforms.<br/><br/>Broad Impact<br/><br/>Successful mapping and classifying tools will have impact beyond the analysis of natural landscapes; they can be also be applied to the study of surface metrology (the numerical characterization of industrial surfaces). The nature of this project will attract interest and collaboration with specialists from diverse disciplines, such as computer science, remote sensing, geomorphology and hydrology. Such links will broaden the base of expertise for each discipline, as well as enrich participants from contributing domains."
25,959454,MRI-R2: Acquisition of a GPU cluster for solving n-body systems in science and engineering,OAC,MAJOR RESEARCH INSTRUMENTATION,04/01/2010,02/09/2012,Greg Walker,TN,Vanderbilt University,Standard Grant,Irene M. Qualters,03/31/2013,"$390,423.00","Jens Meiler, Kelly Holley-Bockelmann, Thomas Palmeri, Robert Weller",greg.walker@vanderbilt.edu,Sponsored Programs Administratio,Nashville,TN,372350002,6153222631,CSE,1189,"6890, 9150, 9215, HPCC","$390,423.00","This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).<br/><br/>Graphics Processors (GPUs) are potentially a cost effective and low power vehicle for science and engineering research that requires high performance computation.  The primary challenge to the use of GPUs more broadly is the difficulty in programming.  Dr. Walker and a team of colleagues representing five different scientific and engineering disciplines propose to pursue research topics in each of the disciplines.  By selecting important research topics which require a fundamentally similar computational algorithm for a class of problems labelled ""n-body problems"", the project offers opportunity for meaningful interdisciplinary collaboration across scientific domains that are normally quite distinct.  Since, solutions to this class of problem are particularly well suited to GPUs, there is likelihood of advances in multiple areas of scientific interest at a fraction of alternative costs and power.  Therefore NSF's Office of Cyberinfrastructure (OCI) is supporting the acquisition of the instrument."
27,1017181,III: Small: Better Sentiment Analysis through Forecasting,IIS,Info Integration & Informatics,09/01/2010,03/16/2011,Steven Skiena,NY,SUNY at Stony Brook,Standard Grant,Maria Zemankova,08/31/2014,"$423,164.00",,skiena@cs.sunysb.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,CSE,7364,"7364, 7923, 9251",$0.00,"The emerging field of sentiment analysis employs algorithmic methods to identify and summarize opinions expressed in text.  Both machine learning and ad-hoc approaches lie at the foundations of contemporary sentiment analysis systems, but progress on improving both precision and recall has been slowed by the expense and complexity of obtaining sufficiently broad, general sentiment training/validation data.<br/><br/>Recent work has established that fundamental economic variables can successfully be forecast by applying sentiment analysis methods to news-oriented text streams.  This project turns this relation on its head, using such forecasting approaches to improve both the precision and recall of general entity-oriented sentiment analysis methods. In particular, this project provides a three-pronged research effort into entity-level sentiment analysis, focusing on improved assessment and algorithms, with applications to the social sciences and forecasting.  In particular: <br/>(1) Developing a complete entity-level, text and language-independent sentiment evaluation environment, both to further the development of the Lydia system and for release to the international sentiment analysis community.<br/>(2) Building on this environment, to develop improved sentiment-detection methods for English news, foreign language news streams, social media such as blogs and Twitter, and historical text corpora.<br/>(3) Finally, applying improved sentiment analysis to a variety of challenges in the social sciences.  <br/><br/>This research promises to substantially improve both the precision and recall of sentiment detection methods, by focusing on the weakest link: rigorous yet domain-, source-, and language-independent assessment of sentiment.  Beyond improvements in natural language processing (NLP), this includes other issues in opinion mining, including article clustering and duplicate detection, entity-domain context, and combining opinions from large numbers of distinct sources.<br/><br/>The sentiment analysis methods and data developed under this research project are expected to have a broad impact, as the results will be directly applicable in a broad range of social sciences, including sociology, economics, political science, and media and communication studies.  The techniques will serve as both an educational and scholarly resource in these fields, empowering students and researchers to conduct their own primary studies on historical trends and social forces.  Results will be disseminated to the community through the project website (http://www.textmap.org/III)."
29,1041411,Support for Student Participation in the Conference International Conference on Multimodal-Machine Learning for Multimodal Interaction (ICMI-MLMI) 2010,IIS,HCC-Human-Centered Computing,11/01/2010,06/23/2010,Louis-Philippe Morency,CA,University of Southern California,Standard Grant,Ephraim Glinert,10/31/2013,"$24,592.00",,morency@cs.cmu.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7367,,$0.00,"This is funding to support participation by about 10 graduate students in a Doctoral Consortium (workshop) to be held in conjunction with the 12th International Conference on Multimodal Interfaces and 7th Workshop on Machine Learning for Multimodal Interaction (ICMI-MLMI 2010), which will be held November 8-12, in Beijing, China, and which is organized by the Association for Computing Machinery (ACM) with co-sponsorship from the Institute of Electrical and Electronics Engineers (IEEE).   The conference will bring together researchers from North America, Europe, and Asia to present and discuss the latest multidisciplinary work on multimodal interfaces, systems, and applications.  Now in its second year, the combined ICMI-MLMI is the foremost international event representing the growing interest in next-generation perceptive, adaptive and multimodal user interfaces.  Such interfaces represent an emerging interdisciplinary research direction, involving spoken and natural language understanding, image processing, computer vision, pattern recognition, experimental psychology, etc.  They aim to promote efficient and natural interaction and communication between computers and human users, and represent a radical departure from previous computing that should ultimately enable users to interact with computers using everyday skills.  The main goals of ICMI-MLMI 20010 are to further scientific research within the broad field of multimodal interaction and systems, to focus on major trends and challenges, and to help identify a roadmap for future research and commercial success.  Topics of interest this year include: multimodal and multimedia processing; multimodal input and output interfaces; multimodal applications; human interaction analysis and modeling; and multimodal data, evaluation, and standards.  The three days of invited talks, panels, and single-track oral and poster presentations will facilitate interaction and discussion among researchers; the conference promises to be an international venue for brainstorming and coming up with creative directions for future research in multimodal interfaces. Participants in the Doctoral Consortium will get to showcase their ongoing thesis work, either orally or in a special ""doctoral spotlight"" poster session during which they will receive feedback from an invited committee composed of senior personnel, and including the Advisory Committee chair and the General and Program chairs.  As a further incentive for high-quality student participation, ICMI-MLMI will be awarding outstanding paper awards, with a special category just for student papers. More information about ICMI-MLMI is available online at http://www.acm.org/icmi/2010.<br/><br/>Broader Impacts: The Doctoral Consortium will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field.  It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors.  With the goal of increasing the breadth of participation at ICMIMLMI, selection of grantees will be done by the PI with oversight from the Advisory Committee Chair and the Conference General Chair; the organizers will make special efforts to encourage participation by a significant number of student researchers from less-well funded institutions, as well as by minority students, female students, and students from geographically under-represented states.  Students funded under this award will all be enrolled at U.S. institutions of higher education."
30,1039741,MRI: Development of a Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children,CNS,"Major Research Instrumentation, Information Technology Researc, Special Projects - CNS, IUCRC-Indust-Univ Coop Res Ctr",10/01/2010,08/22/2018,Nikolaos Papanikolopoulos,MN,University of Minnesota-Twin Cities,Standard Grant,Rita Rodriguez,09/30/2019,"$1,725,730.00","Kelvin Lim, Guillermo Sapiro",npapas@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,"1189, 1640, 1714, 5761","1189, 5761, 9178, 9251",$0.00,"Abstract <br/>Proposal #: 10-39741 <br/>PI(s): Papanikolopoulos, Nikolaos; Lim, Kelvin; Guillermo Sapiro <br/>Institution: University of Minnesota <br/>Title: MRI/Dev.: Video-Based Robotic Instrument for Behavioral Analysis and Diagnosis of At-Risk Children <br/><br/>Project Proposed: <br/>The proposed set of tools constitutes a video-based robotic instrument which targets the domain of early diagnosis for children at risk of developing psychiatric disorders. As such, this proposal is at the disciplinary boundaries between computer science, psychology and psychiatry, and medicine. Proposed is the development of a robotic instrument that could observe and automatically analyze abnormalities in children, thus introducing a novel technology which can help identifying children at risk.  Specific activities include: <br/>- Development and clinical verification of instrumentation and clinical protocols to quantify mental disorders in children; <br/>- Development and usage of computer vision and machine learning methodologies in the instrument; <br/>- Development of statistical models to evaluate the available related data sets; <br/>- Usage of a wide array of passive and active sensors and state-of-the-art 3D camera systems to collect and analyze the monitored data; <br/>- Usage of robots and robot pets as a means to detect and treat mental disorders; and, <br/>- Practical validation of the instrument at the Medical School. <br/><br/>Broader Impacts: <br/>The recent usage of computer vision methodologies/hardware and robotics for detection of mental disorders in children, in itself, constitutes strong broader impacts. Planned are also educational programs (workshops, tutorials, etc.) that will enable training gathering of physicians and psychologists to the aforementioned methods/procedures, which would otherwise not be possible. Moreover, significant planned curriculum development at the participating institutions revolves around the instrument. In addition, outreach activities for middle-school students from underrepresented groups will take place, and so will outreach to various pertinent patient groups. This truly interdisciplinary project also plans to include international partners."
32,1027289,Workshop on NLP and Linguistics: finding the common ground,IIS,"Linguistics, Robust Intelligence",10/01/2010,02/05/2014,Fei Xia,WA,University of Washington,Standard Grant,Tatiana Korelsky,09/30/2014,"$16,996.00",,fxia@u.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"1311, 7495","1311, 7495",$0.00,"Since early 1990s, with the advancement of machine learning methods and the availability of data resources such as treebanks and parallel corpora, data-driven approaches to Natural Language Processing (NLP) have made significant progress. The success of such data-driven approaches has cast doubt on the relevance of linguistics to NLP. Conversely, NLP techniques are rarely used to help linguistics studies. The goal of this NSF-sponsored workshop is to carefully examine the relationship between linguistics and NLP and determine how incorporating linguistic knowledge into NLP systems can advance the state of the art of NLP and how NLP can assist linguistic studies through automatic collection and analysis of linguistic data.<br/><br/> The workshop will bring together researchers from linguistics and NLP with diverse interests in and across both disciplines. The workshop is held in conjunction with ACL on July 16, 2010 in Sweden.  This award provides financial support that allows the workshop to attract top researchers in the US to attend the workshop in Sweden, and the support is crucial especially for linguists who normally do not attend ACL.<br/><br/> This workshop is intended to begin collaboration between linguists and NLP researchers that will continue long after the workshop has finished. The ultimate goals of the workshop and follow-up events are to accelerate work in NLP by bringing in important knowledge and information from linguistics, and to open the eyes of NLP researchers to the challenges within the field of linguistics that could benefit from cutting-edge, state-of-the-art NLP.<br/>The cross pollination between the disciplines can only push both forward and in directions that otherwise would come much later or not at all."
35,952943,CAREER: Learning Models for Scalable Content-Based Image Retrieval,IIS,Robust Intelligence,04/01/2010,03/08/2014,Lorenzo Torresani,NH,Dartmouth College,Continuing Grant,Jie Yang,03/31/2017,"$494,964.00",,lorenzo@cs.dartmouth.edu,OFFICE OF SPONSORED PROJECTS,HANOVER,NH,37551421,6036463007,CSE,7495,"1045, 1187, 9150",$0.00,"This project addresses the design of machine learning algorithms enabling content-based image retrieval in Web-scale collections of photos. This research formulates image retrieval as a binary classification problem: decide which database images are the ""same"" as the user-provided photo. Efficiency and scalability to large collections are achieved by constraining the classifiers to be models supported by traditional text-search engines, which perform real-time search in databases of several billion documents. In order to implement search based on high-level notions of similarity, the research team develops methods to automatically localize the most content-relevant regions in the input photo and to extract from them semantically powerful classifiers combining appearance cues with robust geometric constraints. The algorithms learn from user-provided labels indicating the presence but not the location of similar visual content, thus requiring a minimal amount of human supervision. This research investigates also how this advanced form of similar-image search can be used to organize personal photos, provide semantic annotations, and support content-based clustering of pictures.  Furthermore, this work provides technical advances in a wide range of computer vision problems including object detection, visual saliency, and content-based clustering of photos. Moreover, the research team is collecting an unprecedentedly large image data set to evaluate the developed image retrieval system and to be  available to the community. Research is naturally integrated with education and outreach by means of related courses and out-of-classroom activities aimed at attracting students to this field and at encouraging interdisciplinary collaborations."
36,1015930,RI: Small: Exploratory Data Analysis for Speech Recognition,IIS,ROBUST INTELLIGENCE,08/15/2010,08/20/2010,Steven Wegmann,CA,International Computer Science Institute,Standard Grant,Tatiana D. Korelsky,07/31/2012,"$200,000.00",,swegmann@icsi.berkeley.edu,1947 CENTER ST STE 600,Berkeley,CA,947044115,5106662900,CSE,7495,7923,$0.00,"Hidden Markov models (HMMs) have been successfully applied to automatic <br/>speech recognition for more than 35 years even though a key HMM <br/>assumption - the statistical independence of frames - is obviously <br/>violated by speech data. In fact, this data/model mismatch has inspired <br/>many attempts to modify or replace HMMs with alternative models that are <br/>better able to take into account the statistical dependence of frames. <br/>The scientific goal of this work is to discover predictable regions of <br/>statistical dependence in speech data and quantify their effect on <br/>HMM-based recognition accuracy. In contrast to previous studies of <br/>statistical dependency, this research uses the HMM to explore its <br/>departure from the data via exploratory data analysis (EDA). The <br/>methodology is to first analyze the data and its fit to the model, <br/>searching for regions of predictable statistical dependence - model/data <br/>mismatch. EDA is used again to develop simple models of the effect of <br/>the predictable mismatch on recognition accuracy. A key piece of this <br/>analysis is the development and use of graphical tools to visualize the <br/>statistical dependency, the recognition errors, and their relationship. <br/>The results of this research will provide important clues for the design <br/>of HMM generalizations. The analysis methodology is central to the field <br/>of statistics, but is rarely used in speech recognition research. <br/>Graduate students working on this project will learn its utility and <br/>how to use it on other problems. Open source versions of the software <br/>developed will be made available for free downloading."
38,1016029,"RI:  Small:  Boosting, Optimality and Game Theory",IIS,ROBUST INTELLIGENCE,09/01/2010,07/01/2011,Robert Schapire,NJ,Princeton University,Continuing grant,Todd Leen,08/31/2014,"$450,000.00",,schapire@cs.princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,7495,7923,$0.00,"Boosting is a machine-learning method based on combining many<br/>carefully trained weak prediction rules into a single, highly accurate<br/>classifier.  Boosting has both a rich theory and a record of empirical<br/>success, for instance, to face detection and spoken-dialogue systems.<br/><br/>The theory of boosting is broadly connected to other research fields,<br/>but has only been fully developed for the simplest learning problems.<br/>Nevertheless, in practice, boosting is commonly applied in settings<br/>where the theory lags well behind.  We do not know if such practical<br/>methods are truly best possible; even for binary classification, it is<br/>not clear how to best exploit what is known about how boosting<br/>operates.  New challenges will demand an even greater widening of the<br/>foundations of boosting.<br/><br/>The goal of this project is to develop broad theoretical insights and<br/>versatile algorithmic principles.  The aim is to study<br/>game-theoretically how to design the most efficient and effective<br/>boosting algorithms possible.<br/><br/>Research on boosting is spread over many years. across multiple<br/>publications and disciplines.  To organize this body of work, a<br/>significant activity of this project is the completion of a book on<br/>boosting which will provide a valuable resource for students and<br/>researchers of diverse backgrounds and interests.<br/><br/>Boosting has historically had a major impact on areas outside machine<br/>learning, such as statistics, computer vision, and speech and language<br/>processing.  Thus, there is a strong potential for work at its<br/>foundations to have a broad impact on these other research and<br/>application areas as well."
39,1035913,CPS: Medium: A Novel Human Centric CPS to Improve Motor/Cognitive Assessment and Enable Adaptive Rehabilitation,CNS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CISE, CYBER-PHYSICAL SYSTEMS (CPS)",09/15/2010,05/29/2015,Fillia Makedon,TX,University of Texas at Arlington,Standard Grant,David Corman,02/29/2016,"$730,001.00","Heng Huang, Zhengyi Le, Vassilis Athitsos, Dan Popa",makedon@cse.uta.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,CSE,"1640, 1714, 7918","116E, 7918, 7924, 9102, 9178, 9251",$0.00,"The objective of this research is to develop methods and tools for a multimodal and multi-sensor assessment and rehabilitation game system called CPLAY for children with Cerebral Palsy (CP). CPLAY collects and processes multiple types of stimulation and performance data while a child is playing. Its core has a touch-screen programmable game that has various metrics to measure delay of response, score, stamina/duration, accuracy of motor/hand motion. Optional devices attached to extend CPLAY versions provide additional parallel measurements of level of concentration/participation/engagement that quantify rehabilitation activity. The approach is to model the process as a cyber-physical system (CPS) feedback loop whereby data collected from various physical 3D devices (including fNIR brain imaging) are processed into hierarchical events of low-to-high semantic meaning that impact/ adjust treatment decisions.<br/><br/>Intellectual Merit: The project will produce groundbreaking algorithms for event identification with a multi-level data to knowledge feedback loop approach. New machine learning, computer vision, data mining, multimodal data fusion, device integration and event-driven algorithms will lead towards a new type of cyber- physical rehabilitation science for neurological disorders. It will deliver fundamental advancements to engineering by showing how to integrate physical devices with a computationally quantitative platform for motor and cognitive skills assessment.<br/><br/>Broader Impacts: The project delivers a modular & expandable game system that has huge implications on the future of US healthcare and rehabilitation of chronic neurological disabilities. It brings hope to children with Cerebral Palsy via lower cost and remote rehabilitation alternatives. It brings new directions to human centered computing for intelligent decision-making that supplements evidence-based practices and addresses social and psychological isolation problems."
40,1017256,III: Small: Privacy Preserving Techniques for Speech Processing,CNS,"International Research Collab, Robust Intelligence, TRUSTWORTHY COMPUTING",09/01/2010,01/24/2012,Bhiksha Raj,PA,Carnegie-Mellon University,Standard Grant,Nina Amla,02/28/2015,"$524,931.00",,bhiksha@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"7298, 7495, 7795","5936, 5979, 7495, 7923",$0.00,"Voice-processing systems that perform speaker verification, keyword spotting, speech recognition, etc. need complete access to the speech signal, albeit in parameterized form. These data could potentially be logged for future playback, analysis or even  malicious activities and represent a threat to the privacy and security of users.  This project aims to develop techniques that enable some key voice processing tasks, namely speaker identification or verification and keyword spotting, while preserving the privacy of the speaker?s voice. The techniques will perform their operations without observing any intelligible form of the speech signal from which one could glean any information about the speaker or what they said; yet at the end of the computation the results, which will only be delivered to an authorized party, will be indistinguishable from those that would be obtained if the system were not secured in this manner.<br/><br/>The proposed work draws upon approaches from cryptography and secure multiparty computation. It is explained how these techniques can be used to devise privacy-preserving algorithms for voice processing, and the development of such algorithms for the three problems mentioned, speaker identification and verification and keyword spotting, has been proposed.<br/><br/>For further information see http://mlsp.cs.cmu.edu/projects/secureaudio"
41,964102,RI: Medium: Collaborative Research:  Semi-Supervised Discriminative Training of Language Models,IIS,"COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE",06/01/2010,03/18/2014,Alexander Kain,OR,Oregon Health & Science University,Continuing grant,Tatiana Korelsky,05/31/2015,"$519,050.00","Izhak Shafran, Richard Sproat",kaina@ohsu.edu,3181 S W Sam Jackson Park Rd,Portland,OR,972393098,5034947784,CSE,"7298, 7495","5940, 7495, 7924",$0.00,"This project is conducting fundamental research in statistical language modeling to improve human language technologies, including automatic speech recognition (ASR) and machine translation (MT).<br/><br/>A language model (LM) is conventionally optimized, using text in the target language, to assign high probability to well-formed sentences.  This method has a fundamental shortcoming: the optimization does not explicitly target the kinds of distinctions necessary to accomplish the task at hand, such as discriminating (for ASR) between different words that are acoustically confusable or (for MT) between different target-language words that express the multiple meanings of a polysemous source-language word.<br/><br/>Discriminative optimization of the LM, which would overcome this shortcoming, requires large quantities of paired input-output sequences: speech and its reference transcription for ASR or source-language (e.g. Chinese) sentences and their translations into the target language (say, English) for MT.  Such resources are expensive, and limit the efficacy of discriminative training methods.<br/><br/>In a radical departure from convention, this project is investigating discriminative training using easily available, *unpaired* input and output sequences: un-transcribed speech or monolingual source-language text and unpaired target-language text.  Two key ideas are being pursued: (i) unlabeled input sequences (e.g. speech or Chinese text) are processed to learn likely confusions encountered by the ASR or MT system; (ii) unpaired output sequences (English text) are leveraged to discriminate between these well-formed sentences from the (supposed) ill-formed sentences the system could potentially confuse them with.<br/><br/>This self-supervised discriminative training, if successful, will advance machine intelligence in fundamental ways that impact many other applications."
42,963898,RI:  Medium:  Collaborative Research:  Semi-Supervised Discriminative Training of Language Models,IIS,"COLLABORATIVE RESEARCH, ROBUST INTELLIGENCE",06/01/2010,06/03/2014,Sanjeev Khudanpur,MD,Johns Hopkins University,Continuing grant,Tatiana D. Korelsky,08/31/2015,"$518,250.00","Damianos Karakos, Chris Callison-Burch",khudanpur@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,"7298, 7495","5940, 7495, 7924",$0.00,"This project is conducting fundamental research in statistical language modeling to improve human language technologies, including automatic speech recognition (ASR) and machine translation (MT). <br/><br/>A language model (LM) is conventionally optimized, using text in the target language, to assign high probability to well-formed sentences. This method has a fundamental shortcoming: the optimization does not explicitly target the kinds of distinctions necessary to accomplish the task at hand, such as discriminating (for ASR) between different words that are acoustically confusable or (for MT) between different target-language words that express the multiple meanings of a polysemous source-language word. <br/><br/>Discriminative optimization of the LM, which would overcome this shortcoming, requires large quantities of paired input-output sequences: speech and its reference transcription for ASR or source-language (e.g. Chinese) sentences and their translations into the target language (say, English) for MT. Such resources are expensive, and limit the efficacy of discriminative training methods. <br/><br/>In a radical departure from convention, this project is investigating discriminative training using easily available, *unpaired* input and output sequences: un-transcribed speech or monolingual source-language text and unpaired target-language text. Two key ideas are being pursued: (i) unlabeled input sequences (e.g. speech or Chinese text) are processed to learn likely confusions encountered by the ASR or MT system; (ii) unpaired output sequences (English text) are leveraged to discriminate between these well-formed sentences from the (supposed) ill-formed sentences the system could potentially confuse them with. <br/><br/>This self-supervised discriminative training, if successful, will advance machine intelligence in fundamental ways that impact many other applications."
43,953107,CAREER: Brain-Tongue-Computer Interfacing,IIS,HCC-Human-Centered Computing,03/01/2010,12/01/2016,Maysam Ghovanloo,GA,Georgia Tech Research Corporation,Continuing Grant,Ephraim Glinert,02/28/2018,"$548,298.00",,mgh@getech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"1045, 1187, 7367, 9215, 9251, HPCC",$0.00,"The PI's long-term research plans involve exploring new pathways to the human central nervous system (CNS) in order to expand our knowledge about this highly complex system and understand how it works, and developing innovative technologies and research tools that will enable direct or indirect communication with the CNS through such pathways.  In particular, he is keen to utilize and evaluate new interfacing technologies in devices that will help individuals who suffer from chronic disabilities and neurological diseases, such as blindness, deafness, and paralysis to improve and extend their quality of life.  With these general goals in mind, the PI will in this project focus on exploring the use of voluntary tongue motion as a substitute for some of the functions traditionally performed by the arms and hands in personal environmental control.  This has not been possible in the past absent access to tongue motion without impeding the tongue's key roles in swallowing, respiration, and speech.  The PI has previously developed and successfully tested a new wireless, unobtrusive, and wearable technology he calls the Tongue Drive System (TDS), to indicate tongue position in real time within certain user-defined locations in the oral space.  Building upon the TDS prototype, he will explore whether the inherent characteristics of the tongue and its rich motor capabilities can be harnessed as an intermediary pathway to the human brain.  In other words, he will seek to create a Brain-Tongue-Computer Interface (BTCI) by enhancing the functionality of the TDS hardware, signal processing algorithms, and GUI software to support a large number of choices that will be simultaneously available to users, in addition to the proportional control capability that is currently employed to facilitate navigation and computer access.  The PI will conduct experiments to evaluate the performance, usability, and acceptability of the BCTI platform, and will employ it to achieve a fundamental understanding of human factors associated with voluntary tongue motions.  Finally, the PI will combine his real time 3-D tongue tracking technology with multi-channel wireless neural recording to explore the relationship between unconstrained tongue movements and whole muscle/single motor unit activities in speech, respiration, and swallowing without any bodily restraints.<br/><br/>Broader Impacts:  Individuals who are severely disabled as a result of various causes from spinal cord injuries to stroke, cerebral palsy, and ALS find it extremely difficult to carry out everyday tasks without continuous help.  This research will ultimately transform the lives of many persons with severe disabilities, by helping them live active, self-supportive, and productive lives.  Solutions such as the BTCI may also help reduce healthcare and assisted-living costs by relieving the burden on family members and dedicated caregivers.  Utilization of the tongue's motion as an untapped human motor modality in command, control, and navigation tasks involves costs and benefits which are at present unknown; quantitative analysis of human performance in concurrently conducted sensory, motor, and cognitive tasks, both in the presence and absence of tongue motions, is likely to bring about new scientific discoveries in human system integration.  The PI's 3-D tongue tracking technology will also impact speech/language therapy, as well as the treatment of communication and sleep disorders that involve tongue motion.  The PI will explore use of the BTCI technology in educational settings for children with special needs through programs such as Tools for Life, and will also conduct outreach efforts to expose K-12 students to facts about the CNS, its associated impairments, and different ways to address those problems with engineering solutions."
46,1043341,Computational Dreaming,CNS,Networking Technology and Syst,09/01/2010,05/09/2014,JoAnn Paul,VA,Virginia Polytechnic Institute and State University,Standard Grant,Thyagarajan Nandagopal,08/31/2015,"$191,709.00",,jmpaul@vt.edu,Sponsored Programs 0170,BLACKSBURG,VA,240610001,5402315281,CSE,7363,"7916, 9102",$0.00,"By focusing on a set of the physical-structural foundations of dreaming, this research will investigate: (1) new organizational principles for parallel computation and (2) why dreaming is critical to intelligence. <br/><br/>Seemingly against all survival instincts, all intelligent beings must sleep and dream, even if they are under duress, even if it endangers their very lives because they are in a hostile environment.  Sleep that includes dreaming is strongly related to efficient mental processes.  The thesis of this work is that the need to dream can be inferred from the brain's most striking physical and behavioral characteristics.  <br/><br/>The computer architecture that will be investigated is the DALI (Dream Architecture for Lateral Intelligence)  a true Multiple Instruction, Single Datastream (MISD) architecture in which multiple models process the same input stream in real-time.  While awake, some lateral processors are observers while one or more others are active.  A dream phase of computation resolves divergence between processors in a competitive feedback phase not dominated by a flow of logic. Reality contains multiple views of the same thing, between different individuals and within the same individual, with incongruence resolved over time. The goal of the DALI is to include multiple, lateral models that process what the system observes, and then to model the competitive process of model resolution during a dream phase so that the system may be more effective for the next day's real-time (awake) response. The initial problem which will be investigated is contextual partitioning for speech recognition in pervasive, portable computing devices."
48,1016713,RI: Small: Decision-Theoretic Control of Crowd-Sourced Workflows,IIS,"HCC-Human-Centered Computing, Robust Intelligence",09/15/2010,04/11/2012,Daniel Weld,WA,University of Washington,Standard Grant,Todd Leen,08/31/2014,"$320,669.00",Mausam Mausam,weld@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7367, 7495","7367, 7923, 9251",$0.00,"Crowd-sourcing is a recent framework in which human intelligence tasks are outsourced to a crowd of unknown people as an open request for services. Requesters use crowd-sourcing for a wide variety of jobs like dictation-transcription, content screening, linguistic tasks, user-studies, etc. These requesters often use complex workflows to subdivide a large task into bite-sized pieces (including the management of these tasks), each of which is independently crowd-sourced. These workflows are paramount to the success of crowd-sourcing, still, there has been little attention paid to methods for dynamically optimizing the throughput of a workflow. Controlling and optimizing such a workflow is an excellent application for AI research for two reasons. First, it is challenging in that the agent has to understand the dynamics of an uncertain, real-time environment and reason about distinct choices for a decision. More importantly, the domain has significant economic value -- progress can potentially impact hundreds of thousands of people and spur economic development in a fast growing sector.<br/><br/>This project is investigating complex workflows using a decision-theoretic framework that optimizes for a quality/price trade-off, with aims of (1) building statistical models of worker behavior derived from a large corpus of online behavior, (2) defining a declarative representation language to describe a wide range of workflows, and (3) developing an automated scheme that optimizes a general workflow resulting in an automated controller for making informed decisions at various stages of the process and for monitoring worker accuracies and computing corrections based on them. In the longer term, perhaps beyond the scope of this project, is (4) development of an interface optimizer that automatically learns the best user interface for a task based on user behavior increasing throughput of the workflow, and (5) integrating these ideas in an open-source, software toolkit to directly benefit the various requesters in managing their tasks."
49,1002748,MAJOR:  Assistive Artificial Intelligence to Support Creative Filmmaking in Computer Animation,IIS,"HCC-Human-Centered Computing, CreativeIT",09/01/2010,08/31/2010,Mark Riedl,GA,Georgia Tech Research Corporation,Standard Grant,William Bainbridge,08/31/2014,"$695,485.00",Michael Nitsche,riedl@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,"7367, 7788",7788,$0.00,"This project will explore approaches to artificial intelligence that can support creative digital filmmaking, an extremely rich new form of expression and communication. The most accessible variant of digital filmmaking is ""machinima"" - cinematic movies created by manipulating avatars in 3D computer game worlds. Due to the allure of cheap, quick, and easy movie making, and the accessibility of high-fidelity graphics through video games technologies, machinima has grown into a mainstream form of creative expression and sharing. However, machinima has a high threshold of entry. This is due only partly to technical tools, which are cheap and easily acquired; digital filmmaking also has a high threshold of skill requirements. In general, creativity is collaborative, with creators often seeking feedback and critique from others. Intelligent systems can also participate in the feedback loop of creative practice by suggesting, autonomously creating, and critiquing digital media.<br/><br/>The goal of this research is to reduce the technological and skill barriers to complex, but rich forms of digital expression such as filmmaking, thereby increasing the creative productivity of amateur creators. Its approach is to develop digital media production tools that are instilled with computational models of creative practice and intuitive interfaces informed by empirical studies. The anticipated result is a greater understanding of creative processes involving feedback and critique, models of cognitive and emotive processes in human recipients of creative artifacts, and understanding about the tradeoffs of interface modalities involving intelligent participatory systems. The project is organized around two major, interrelated thrusts: (1) develop cognitive and computational models of feedback and critique as a means toward intelligent systems that participate in creative endeavors; (2) study how the creative abilities of amateur and expert digital filmmakers are affected by production interfaces along dimensions of (a) degree of constraint in cinematic control and (b) modes of intelligent participatory support.<br/><br/>It is anticipated that the resultant models and implementations will serve as next-generation creativity support tools to be adopted by the amateur digital filmmaking and machinima communities. By achieving its research goals, this project will demonstrate a technique for lowing the threshold of entry to a form of digital media creation. Lowering the threshold of machinima production, in particular, will open the practice to populations of users historically underrepresented in computing such as women, who are attracted to storytelling but often discouraged by highly technical ""hacker"" skills. As an expressive form, digital filmmaking is a powerful medium for communication, can be used as a draw to computing, and can be integrated into a wide repertoire of activities including entertainment and education.  Resultant models and implementations may also impact the growing practice of previsualization in the movie and television industries. The approach will result in a model for incorporating intelligent creative assistance into other forms of expressive digital media."
50,963404,Collaborative Research: Measuring and Modeling Collective Intelligence,IIS,HCC-Human-Centered Computing,01/01/2010,02/18/2015,Christopher Chabris,NY,Union College,Standard Grant,Ephraim Glinert,12/31/2015,"$173,908.00",,chabrisc@union.edu,807 Union Street,Schenectady,NY,123083103,5183886101,CSE,7367,"9215, HPCC",$0.00,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research.  But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence.  One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College.  The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems.  For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups.  Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups.  Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups.   A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems.  This research will provide powerful new tools for managing and designing such systems.  Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors.  Imagine that this test could predict the team's future performance on a wide range of important tasks.  And imagine that the test could also help suggest changes to the team that would improve its flexibility.  Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks.  From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently.  This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts:  With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it.  With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems.  The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
51,963285,Collaborative Research:  Measuring Collective Intelligence,IIS,HCC-Human-Centered Computing,01/01/2010,01/11/2010,Thomas Malone,MA,Massachusetts Institute of Technology,Standard Grant,Ephraim Glinert,12/31/2014,"$538,213.00",,malone@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7367,"7924, 9215, HPCC",$0.00,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research.  But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence.  One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College.  The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems.  For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups.  Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups.  Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups.   A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems.  This research will provide powerful new tools for managing and designing such systems.  Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors.  Imagine that this test could predict the team's future performance on a wide range of important tasks.  And imagine that the test could also help suggest changes to the team that would improve its flexibility.  Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks.  From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently.  This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts:  With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it.  With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems.  The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
52,963451,Collaborative Research: Measuring Collective Intelligence,IIS,HCC-Human-Centered Computing,01/01/2010,01/11/2010,Anita Woolley,PA,Carnegie-Mellon University,Standard Grant,Ephraim Glinert,12/31/2012,"$187,633.00",,awoolley@cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7367,"9215, HPCC",$0.00,"The ""holy grail"" of artificial intelligence research for decades has been to design computers with robust, integrated, human-like intelligence. This goal has proven elusive, in spite of a massive amount of research.  But another goal is just now becoming feasible, and so has been the subject of much less research: using vast computer networks to create new kinds of intelligent entities that combine the best of both human and machine intelligence.  One key to designing such human-centered computing systems is better ways of measuring the collective intelligence they exhibit. That is the focus of this research, which represents a collaborative effort among researchers at MIT (lead institution), CMU and Union College.  The PIs will first use analogies with what is already known about measuring individual intelligence to suggest new ways of measuring the collective intelligence of complex human-machine systems.  For instance, they will determine whether the striking pattern of correlations across tasks that characterizes individual human intelligence even exists for human-machine groups.  Next, a series of statistically validated tests will be developed to measure the key components of collective intelligence in human-machine groups.  Then, to better understand the ""active ingredients"" of collective intelligence, the PIs will use what is already known about how groups of people interact effectively to measure micro-level behavior in human-machine groups.   A key goal will be to find critical factors (such as group size, technological support, or individual capabilities) that contribute to a human-machine group's adaptability across a wide range of tasks.<br/><br/>Most people and computers today are parts of larger human-machine systems that must cope with a wide range of problems.  This research will provide powerful new tools for managing and designing such systems.  Imagine, for instance, that one could give a short ""collective intelligence test"" to a top-management team, a product development team, or a collection of Wikipedia contributors.  Imagine that this test could predict the team's future performance on a wide range of important tasks.  And imagine that the test could also help suggest changes to the team that would improve its flexibility.  Or imagine that designers of new collaboration software tools could use a single test to predict how well their tools would improve a group's effectiveness on many different tasks.  From the smallest business work groups to our largest societal challenges, there are now many new opportunities for people and computers to solve problems together, not just more efficiently, but also more intelligently.  This work will help build a firmer scientific foundation for doing this.<br/><br/>Broader Impacts:  With individual humans, it is relatively easy to measure intelligence, but it is difficult to increase that intelligence or to observe the detailed events inside the brain that give rise to it.  With human-computer groups it is much easier to observe and change factors (such as group size, composition, and technological support) that are likely to determine the group's collective intelligence. Thus, there is a profound intellectual opportunity, not just to learn more about how to design intelligent human-computer systems but also to gain new insights into the very nature of intelligence in complex systems.  The results of this research, therefore, will be of interest not only to researchers in computer-supported cooperative work, human-computer interaction, and artificial intelligence, but also more broadly to fields such as cognitive science, social psychology, and organization theory."
53,1016465,RI: Small: Integrating Paradigms for Approximate Stochastic Planning,IIS,Robust Intelligence,08/15/2010,09/09/2013,Mausam Mausam,WA,University of Washington,Standard Grant,Todd Leen,07/31/2014,"$466,508.00",,mausam@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,7495,"7923, 9251",$0.00,"A fundamental challenge for Artificial Intelligence is sequential decision making under uncertainty, a task where automated algorithms lag far behind human-level intelligence. The primary reason for the disparity is curse of dimensionality - the number of states is exponential in the problem features. Recent advances that restrict decision-theoretic computation to a reachable subset of state space have scaled to moderately-sized problems, but proven ineffective in scaling to real problems. On the other hand, probabilistic planners based on deterministic planning might scale up, but with a massive loss in solution quality.<br/><br/>This project is investigating several methods to scale probabilistic planning to real-sized problems. We combine decision-theoretic analysis, basis function approximation and the classical AI planning techniques, to develop a series of highly scalable planners. A common theme in our techniques is the use of deterministic plans to automatically obtain domain abstractions in the form of 'good' or 'bad' properties, or intermediate subgoals. The project introduces and exploits a principled collaboration between decision theory and classical planning techniques, thus retaining the benefits of both - high quality as well as high performance. Experiments show that our new planner solves difficult planning competition problems using orders of magnitude less memory outputting high quality policies.<br/><br/>Our research also proposes effective solutions to long-standing problems of generating a set of basis functions and computing a hierarchical problem decomposition. Both basis function approximation and hierarchical decomposition are popular in existing literature for speeding up planning, but they are not fully automated - a human is required to specify the basis functions and the hierarchy. We provide novel, domain-independent solutions that remove this additional human effort.  <br/><br/>Our research addresses several long standing challenges in AI, like scaling stochastic planning, and automatically generating basis functions and subgoal hierarchies. We expect to produce state-of-the-art planners that will be effective in large and complex real world scenarios, e.g., planetary exploration, military operations planning, and robotic decision making."
54,1036017,The Fourth Northeast Student Colloquium on Artificial Intelligence,IIS,ROBUST INTELLIGENCE,05/15/2010,05/19/2010,Andrew McCallum,MA,University of Massachusetts Amherst,Standard Grant,Sven G. Koenig,04/30/2011,"$16,181.00",Erik Learned-Miller,mccallum@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,7495,$0.00,"This award will help to subsidize the participation of graduate students in the fourth Northeast Student Colloquium on Artificial Intelligence (NESCAI) to be held April 16-18, 2010 at the University of Massachusetts in Amherst. This conference is to include oral and poster presentations by students,invited talks by senior AI researchers, and student-run tutorials. The conference will be largely run by a program committee consisting of doctoral students under the guidance of senior faculty. The program committee will conduct a review process to select the projects chosen for oral and poster presentations. In addition to graduate students, the conference plans to encourage attendance by outstanding senior undergraduates through a special undergraduate track, in the hope that it will increase undergraduate enthusiasm for research and thus the likelihood that they will go on to graduate work. The project integrates research and education and commits to broadening diversity."
56,1037866,Travel Support for 2010 Association for Advancement of Artificial Intelligence (AAAI) Robotics Workshop and Exhibition,IIS,ROBUST INTELLIGENCE,07/01/2010,05/19/2010,Ayanna Howard,CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Richard Voyles,06/30/2011,"$25,000.00",,ah260@gatech.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,7495,$0.00,"The project serves to support team travel to the 2010 AAAI Robotics Exhibition and Workshop.  The exhibition and workshop overlaps with the 2010 AAAI Conference being held in Atlanta July 11-15, 2010.  The Exhibition and Workshop revolves around the theme of manipulation and learning.  Events include robot challenges, demonstrations and presentations.  Funds will be used to support about 40 students and their advisors for team travel."
58,1014092,Student Support for the Tenth International Conference on Intelligent Tutoring Systems,IIS,HCC-Human-Centered Computing,02/01/2010,01/19/2010,David Mostow,PA,Carnegie-Mellon University,Standard Grant,Ephraim Glinert,01/31/2011,"$25,000.00",Carolyn Rose,mostow@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7367,"9215, HPCC",$0.00,"This is funding to support attendance by approximately 25 advanced doctoral students from the United States and abroad at the 10th International Conference on Intelligent Tutoring Systems (ITS 2010), which will take place June 14-18, 2010, in Pittsburgh.  The first ITS conference was held in 1988 in Montreal, and they have continued every two years for the past 12 years in locations that include Brazil, Taiwan, France, and Canada as well as the United States.  The ITS conferences offer a rare professional opportunity for interdisciplinary researchers from around the world to converge and present cutting-edge results from the fields of artificial intelligence, computer science, cognitive and learning sciences, psychology, and educational technology.  The goal is to promote studies in advanced systems in computer science applied to education, cognitive science and human learning for learners of all ages.  To that end, the series provides a forum for the interchange of ideas in all areas of computer science and human learning, a unique environment in which researchers and practitioners exchange ideas, theories, experiments, techniques, applications and evaluations of initiatives supporting new developments relevant for the future.  Comments and feedback from each previous ITS conference indicate that the carefully structured conference format continues to be professionally rewarding and stimulating to all who attend.  ITS conferences are highly refereed international events and serve as reference guidelines for the research community; each paper is generally reviewed by 4 referees so that having a paper published at ITS is a reference of quality for any researcher evaluation.  The conferences operate under the auspices of an independent nonprofit organization and are funded entirely by registration fees.  More information about the conference is available at http://www.cmu.edu/its2010.<br/><br/>Students supported by NSF funds will have the opportunity to attend sessions with papers, posters, tutorials, workshops, and informal interactions with accomplished researchers, the latter within the framework of a Young Researchers Track that includes special sessions for the students to present their research ideas, meet peers who have related interests, and receive feedback and mentoring from senior members of the ITS community.   A structured program will be provided in which each student is matched with a mentor who will be encouraged to offer feedback and support to students as they prepare their presentations, during the doctoral consortium sessions, and in at least one 1-on-1 meeting.  The doctoral consortium will be situated within the main conference program in order to encourage maximal community involvement.  Its structure will facilitate as much discussion and feedback as possible.  With this goal in mind, students will present their work at lunchtime poster sessions open to all attendees.  To avoid competition with other events and to maximize attendance, no other talks will be scheduled at this time and posters will be in the same rooms as the buffet lunch for all conference attendees.  To acquaint attendees with student work, student poster sessions will be immediately preceded by ""fire-hose"" sessions where students summarize their work very briefly.  To enable poster presenters to see and discuss each other's posters, poster presentations will span all 3 days of the main conference so as to give students one day to present their posters and two days to see others.  Space and logistics permitting, presenters will be able to leave their posters up all 3 days of the conference, affording additional opportunities to discuss them with other researchers, for example during coffee breaks. <br/><br/>Broader Impacts:  This activity supports one of NSF's core missions, to train more advanced professionals in Science, Technology, Engineering, and Mathematics (STEM).  Participating in the conference will provide the selected students with a unique opportunity to be exposed to current research directions in different research communities both domestic and foreign.  This is important for the field, because it has been recognized that transformative advances in research tend to derive from the melding of cross-disciplinary knowledge and multinational perspectives.  Participants will be encouraged to create a social network both among themselves and with senior researchers at a critical stage in their professional development, to form collaborative relationships, and to generate new research questions to be addressed during the coming years.  The PI will place high priority on supporting young researchers (intermediate and advanced doctoral students) from degree-granting institutions that lack the funding necessary to support attendance by their students at international conferences such as ITS."
59,1036262,AAAI/SIGART 2010 Doctoral Consortium,IIS,ROBUST INTELLIGENCE,07/01/2010,06/22/2010,Christopher Brooks,CA,Association for the Advancement of Artificial Intelligence,Standard Grant,Edwina L. Rissland,06/30/2011,"$16,817.00",Bradley Clement,cbrooks@cs.usfca.edu,2275 E BAYSHORE RD STE 160,East Palo Alto,CA,943033224,6503283123,CSE,7495,,$0.00,"This award supports participation of doctoral students in the Fourteenth SIGART/AAAI Doctoral Consortium to be held July 11-12, 2010 in Atlanta, Geargia in conjunction with the 2010 AAAI Conference on Artificial Intelligence. The Doctoral Consortium aims to: (1) provide a setting for feedback on participants' current research and guidance on future research directions; (2) develop a supportive community of scholars and a spirit of collaborative research; and (3) support a new generation of researchers. The Doctoral Consortium organizers strive to recruit and include students from underrepresented groups and smaller schools and schools with less established programs in artificial intelligence. Students will give presentations and participate in discussion; there are one-on-one meeting with a faculty mentor. There will also be opportunities to discuss career issues in both academic and other career pathways. A report on the Consortium will be published in the AI Magazine."
60,953756,CAREER: New Directions in Computing Game-Theoretic Solutions: Commitment and Related Topics,IIS,"ROBUST INTELLIGENCE, ALGORITHMIC FOUNDATIONS, COMPUT GAME THEORY & ECON",03/01/2010,02/19/2014,Vincent Conitzer,NC,Duke University,Continuing grant,Hector Munoz-Avila,02/28/2015,"$500,002.00",,conitzer@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,"7495, 7796, 7932",1045,$0.00,"Game Theory occupies an important place in the foundations of multi-agent systems in artificial intelligence. Research under this award focuses on settings where one agent can commit to her (possibly randomized) strategy before the other agent moves. We consider how to compute optimal strategies to commit to in games with a combinatorial structure, extensive-form games, and repeated/stochastic games. Among other topics are connections to learning in games and mechanism/environment design, and the implications of commitment for the efficiency of computing game-theoretic solutions more generally.<br/><br/>The main objective of the research is to make scientific contributions to artificial intelligence, multi-agent systems, and computational game theory, but to also advance real-world applications. For example, other researchers have expanded on the PI's prior theoretical research (with his PhD advisor) to apply the commitment framework to security applications, such as the placement of checkpoints and canine units at Los Angeles International Airport and the scheduling of Federal Air Marshals. The research performed under this award aims to provide a solid scientific foundation for improving and expanding this and related applications. The award also helps to build connections between computer science and economics, the traditional home of Game Theory. This interdisciplinary link can help diversify the computer science community, intellectually and demographically. Research is tightly integrated with the PI's educational efforts, which include the development of courses in Computational Microeconomics and Game Theory and an approved Computational Economics minor."
62,960061,MRI-R2: Development of Common Platform for Unifying Humanoids Research,CNS,Major Research Instrumentation,07/01/2010,04/17/2014,Youngmoo Kim,PA,Drexel University,Standard Grant,Rita Rodriguez,09/30/2015,"$5,999,997.00","Stefan Schaal, Yury Gogotsi, William Regli, Dennis Hong",ykim@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,1189,6890,"$5,999,997.00","""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."" <br/>Proposal #: 09-60061<br/>PI(s):  Kim, Youngmoo E., Gogotsi, Yury, Hong, Dennis H., Regli, William C., Schaal, Stefan<br/>Institution: Drexel University<br/>Title:    Development of Common Platform for Unifying Humanoids Research<br/>Project Proposed: <br/>This project, developing and disseminating HUBO+, a new common humanoid research platform instrument, enables novel and previously infeasible capabilities for future research efforts while working with a common instrument. HUBO will be the first homogeneous, full-sized humanoid to be used as a common research and education platform. Eight universities (Drexel, CMU, MIT, Ohio State, Penn, Purdue, Southern California, and VaTech), representing a critical mass of humanoids research within US, participate in this development of the world's first homogeneous full-sized humanoid team. Building upon unique expertise, the work extends current capabilities, resulting in six identical units, facilitating the following potentially transformative advances in robotics:<br/>- A state-of-the-art, standardized humanoid platform instrument with embedded capabilities for sensing, manipulation, and rapid locomotion, ideal for a broad range of future humanoids research<br/>- The ability, for the first time, to directly compare and across validate algorithms and methodologies and consistently benchmark results across research teams<br/>- Novel energy storage technology for mobile robotics incorporating supercapacitors for operations requiring high power density, far exceeding the capabilities of traditional battery-only power sources<br/>- A widely distributed platform that motivates, recruits, and trains a broad range of students spanning multiple disciplines, including artificial intelligence, digital, signal processing, mechanics, and control<br/>Humanoids, robots engineered to mimic human form and motion, open broad avenues of cross disciplinary research spanning multiple fields, such as mechanical control, artificial intelligence, and power systems. Common humanoids are rarely autonomous and are not-ready for unconstrained interaction with humans. The most compelling demonstrations are meticulously pre-programmed and painstakingly choreographed. A few common platforms have already advanced some research. Hence, having a consistent platform should facilitate rapid progress in areas needed for autonomy and natural interaction, including mobility, manipulation, robot vision, speech communication, and cognition and learning. However, although currently Japan and Korea are considered world leaders in design and construction of humanoids, best practices have not been developed for constructing multiple, identical humanoids. These conditions call for the making of an urgently needed benchmark providing evaluations and cross-validation of results. With this development and the servicing of 6 humanoids, this project aims to create knowledge and best practices contributing to robotics research, possibly leading to the standardization needed for ubiquity.<br/>Broader Impacts: <br/>The instrument enables US researchers to develop expertise in the design and construction of humanoids, while the distribution of the work activities ensures the broad dissemination of the knowledge. Humanoids research, inherently interdisciplinary and integrative, inspires young students. The graduate and undergraduates students participating are likely to receive a world-class training in robotics. Outreach partners, including several high-profile museums will introduce people of all ages to the exciting technologies of robotics, particularly useful in recruiting K-12 students into science, engineering, mathematics, etc. A partnership with the Science Leadership Academy (SLA), a magnet school with more than 63% underrepresented students, assures their involvement. With SLA, the project initiates an annual program modeled on a NASA-style experiment design competition, in which students use simulation tools to propose humanoids projects and activities. Selected winner(s) will have their proposed projects implemented on HUBO."
65,1018954,"RI: Small: A Human-Level, Real-Time, Integrated Agent",IIS,Robust Intelligence,09/01/2010,04/19/2011,Arnav Jhala,CA,University of California-Santa Cruz,Standard Grant,Weng-keen Wong,01/31/2015,"$464,090.00",Michael Mateas,ahjhala@ncsu.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,7495,"7495, 7923, 9251",$0.00,"This project is developing and integrating statistical and symbolic methods of Artificial Intelligence in an agent architecture and evaluating the agent in a competitive domain, notably the real-time strategy game StarCraft. Real-time strategy (RTS) games provide several interesting research challenges including real-time decision making, enormous state spaces and imperfect information. StarCraft is a popular commercial RTS game that has several professional gaming leagues, and therefore ideal for evaluating the performance of AI agents. Professional StarCraft players reason about and react to strategic decisions at multiple levels of abstraction, sometimes executing over 300 game actions per minute, so developing competition-level StarCraft agents presents extraordinary challenges.  <br/><br/>More specifically, the project is using novel supervised and unsupervised learning algorithms to automatically learn domain knowledge from collections of professional gameplay traces; the agent is being implemented within the reactive planning architecture ABL (A Behavior Language). The ABL reactive planner provides the glue for integrating multiple, heterogeneous reasoners within a real-time execution environment. <br/><br/>This work is expected to make significant contributions to the understanding of decision making processes  in a complex, real-time domain. This understanding will contribute to the development of robust, intelligent systems that can be deployed within real-world environments. This work will motivate AI researchers to build integrated agent architectures. As a well-known game with very high-level professional play, research in StarCraft AI has the potential to attract significant attention to AI research. The StarCraft competition being hosted by our lab  has attracted significant interest both within and outside academia, and at the high-school, undergraduate and graduate level. Thus, this work has the potential to raise general public awareness in research in human-level AI, and will encourage high-school students to pursue careers in computer science and game design."
67,1048632,HCC: EAGER:  Authoring Game AIs by Demonstration for Real-Time Strategy Games,IIS,HCC-Human-Centered Computing,09/01/2010,04/14/2011,Ashwin Ram,GA,Georgia Tech Research Corporation,Standard Grant,William Bainbridge,02/29/2012,"$315,898.00",,ashwin.ram@parc.com,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"7367, 7916, 9251",$0.00,"This research will explore novel ""authoring by demonstration"" techniques for real-time strategy (RTS) games. Creating rich artificial intelligence (AI) behavior sets for complex computer games requires significant engineering effort. Developers need to anticipate all imaginable circumstances that the AI may encounter within the game world. The resulting AI is often static and results in predictable behaviors, detracting from the player experience. In addition, it is difficult for average players to create AI behaviors, without significant expertise in both AI and scripting. Modeling human-like goals and behaviors required for multiplayer games with semi-autonomous avatars adds additional complexity. This potentially transformative project will develop novel learning techniques that allow users to create intelligent behaviors simply by demonstrating them. The research will be done within the domain of RTS games, as these domains pose significant challenges that must be tackled in order to scale up the learning techniques to real-world tasks.<br/><br/>Case-based planners, hierarchical task network planners, or industry-standard behavior-tree execution engines require a library of base behaviors or methods in order to generate complete plans, which traditionally are coded by hand. The project will investigate ways to automate the process of generating such behavior libraries based on novel methods for learning strategic plans from user demonstrations. The techniques will be evaluated in the context of a case-based planning system for RTS games. RTS games are complex and involve strategic decision-making, multi-agent coordination, real-time interaction, and partially-observable environments. These properties pose significant challenges to existing AI methods for planning and learning. This research will make fundamental scientific contributions to learning, case-based reasoning, and AI for real-time strategic domains, addressing key problems in goal recognition, plan learning, and authoring support. <br/><br/>This research will enable game designers and other non-programmers to create the behavior sets for RTS games without requiring programming knowledge. This capability has two main consequences: first, it allows game developers to create games with less effort, and second it will enable a new genre of games where players would be able to create their own AIs as part of the game play. Additionally, as RTS games are essentially domain-specific simulations, the research will support authoring of behavior sets for domains such as simulation environments for training, real-time robotic control, organizational modeling for business decision-making, or sophisticated market simulations for economics strategy or public policy. The educational impact of the project is twofold. First, the project will constitute an important advance towards easy authoring of training simulators for educational applications that require environment with complex AI behaviors. This will enable development of new educational technologies with simulators or virtual worlds. Second, the project will involve undergraduate and graduate students in all phases of the work."
68,1023246,Doctoral Consortium Travel Support: International Conference on Automated Planning and Scheduling,IIS,ROBUST INTELLIGENCE,05/01/2010,04/28/2010,Daniel Bryce,UT,Utah State University,Standard Grant,Edwina L. Rissland,04/30/2011,"$18,000.00",,daniel.bryce@usu.edu,Sponsored Programs Office,Logan,UT,843221415,4357971226,CSE,7495,7495,$0.00,"This award gives travel, housing, and registration-cost support to selected doctoral students from U.S. universities for their participation in the Doctoral Consortium of the 20th International Conference on Automated Planning and Scheduling (ICAPS-10) held May 13 in Toronto, Canada. ICAPS is the premier conference for research in artificial intelligence planning and scheduling, with relevance to a wide variety of applications such as software engineering, manufacturing, transportation, and robotics. The ICAPS-10 Doctoral Consortium includes a poster session, where students present their research, and a mentoring program that pairs senior scientists with doctoral students."
69,958298,Collaborative Research:II-NEW: A Digital/VLSI Test and Reliable Computing Research Laboratory,CNS,"Special Projects - CNS, CCRI-CISE Cmnty Rsrch Infrstrc",06/01/2010,04/10/2012,Mohammed Niamat,OH,University of Toledo,Standard Grant,Almadena Chtchelkanova,05/31/2014,"$167,730.00","Mansoor Alam, Rashmi Jha",mniamat@utnet.utoledo.edu,"2801 W Bancroft St., MS 218",TOLEDO,OH,436063390,4195302844,CSE,"1714, 7359","7359, 9218, 9251, HPCC",$0.00,"Testing represents one of the major manufacturing costs in the semiconductor industry. Designing circuits with testability features significantly reduces testing costs and time. Thus, it is important for designers to be exposed to the concepts in testing which can help them design better and reliable products.<br/>In this collaborative project between the University of Toledo (UT) and Ohio Northern University (ONU), a ""Digital/VLSI Test and Reliable Computing Research Laboratory"" is being established for the development of computationally intensive algorithms and use of commercial CAD tools for testing digital, VLSI, and advanced semiconductor devices.<br/><br/>Some of the research projects being carried out include: Novel Testing Techniques for Quantum Cellular Automata (QCA) circuits; Built In Self Test (BIST) for Embedded SRAMS in System on Chips; Testing Look-Up-Table (LUT) Delay Aliasing Faults in SRAM Based FPGAs Using Half-Frequencies;  Analysis and Testing of Electromigration Failures; Testing and Modeling Soft Errors in FPGAs; Reliability Analysis and Device Failures in Advanced Semiconductor Devices; Reliability Issues Related to Power Consumption in VLSI Chips during Test; and Small Delay Defects and Test Generation.<br/><br/>Educational modules developed from the research carried out in this project are integrated into a number of graduate and undergraduate courses at ONU and UT. Since applications of semiconductor chips are far and wide, many different industries including auto, aerospace, defense and healthcare may benefit from this project."
71,1018152,RI:  Small:  Understanding Value-based Multiagent Learning and Its Applications,IIS,ROBUST INTELLIGENCE,08/15/2010,08/01/2010,Michael Littman,NJ,Rutgers University New Brunswick,Standard Grant,James Donlon,03/31/2014,"$450,000.00",,mlittman@cs.brown.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7495,"7923, 9150",$0.00,"This project explores the behavior of value-based learning methods in multi-agent environments. Value-based methods make decisions by using experience to estimate the utility impact of alternatives and choosing those with high predicted value. Because they evaluate components of behavior instead of treating behaviors as atomic units, they are computationally and statistically efficient. While these methods have been used in computational experiments for many years, only recently have researchers begun to formally characterize their behavior. Our own preliminary work is finding that some value-based methods exhibit super-Nash behavior, making them particularly worthy of study.<br/><br/>More specifically, we are analyzing, mathematically and experimentally, how value-based algorithms perform in several classes of simulated games of varying complexity from the artificial intelligence community, multi-agent engineering applications drawn from the wireless networking area, and as models of human and animal decision making in collaboration with cognitive neuroscientists. Where possible, we are refining existing value-based algorithms to work more efficiently, robustly, and generally than existing algorithms. We are also designing educational outreach activities, including creating entertaining instructional videos on how to promote cooperative behavior in real-life social dilemmas."
72,1038216,Million Book Project Partners Meeting 2010,IIS,HCC-Human-Centered Computing,08/01/2010,07/27/2010,Gloriana St. Clair,PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,07/31/2011,"$39,970.00",,gstclair@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7367,,$0.00,"This proposal requests funds for a ""Million Book Project"" partners research and coordination meeting.  Begun in 2000, the Million Book Project has scanned over 1.6 million books in China, India, Egypt and Australia and made great strides in research areas relevant to large-scale, multi-lingual database storage and retrieval. Project partners intend to continue to work together on issues related to human computer interactions, usability, automatic metadata detection and correction using artificial intelligence, intellectual property, machine translation and summarization, improving and providing centralized access to metadata, long term data storage and access issues, diversity and education.  Funding provided by the National Science Foundation has attracted international partners and matching funds exceeding $100 million U.S. dollars."
74,1059577,EAGER:  Modeling and Visualization of Latent Communities,IIS,,09/15/2010,09/14/2010,Peter Brusilovsky,PA,University of Pittsburgh,Standard Grant,Sylvia Spengler,12/31/2011,"$155,882.00",,peterb@mail.sis.pitt.edu,300 Murdoch Building,Pittsburgh,PA,152603203,4126247400,CSE,J394,"7484, 7916",$0.00,"In many areas of human professional and social life, people tend to form more or less clearly defined communities.   The main problem of these hidden or latent communities is that they are really hard to discover since the borders of these communities cut through various professional and organizational borders. The modern social Web, however, provides a huge volume of alternative data sources for discovering latent communities.  The goal of this proposal is to explore a range of promising approaches that can be used to elicit latent communities from various kinds of data about individuals available in the modern social Web and deliver the results for human thinking and interactive exploration through interactive visualizations. The visualization provided will allow humans explore and manipulate the results delivered by the new algorithms.  This will deliver results that are produced by the joint power of human and artificial intelligence. In the course of the project, the team will build several data sets combining data of several social Web systems and use these data sets to develop, evaluate, and compare several elicitation and visualization approaches.  The work will advance the research on latent communities, community and user modeling, and interactive social visualization. At the same time, the work will constitute one of the first attempts to use a variety of social Web data and a variety of approaches for community modeling. To increase the broader impact of the project, the researcher will apply the latent community knowledge to several practical tasks, such as identifying proper academic mentors and forming coherent collaboration groups.  They will also engage a number of students in the research advancing their training into this emerging field."
75,957438,Collaborative  Research: CI-ADDO-NEW: *-EXEC: A Cross-Community Solver Execution Service,CNS,CCRI-CISE Cmnty Rsrch Infrstrc,05/01/2010,05/05/2010,Geoffrey Sutcliffe,FL,University of Miami,Standard Grant,Edwina L. Rissland,04/30/2012,"$15,750.00",,geoff@cs.miami.edu,1320 S. Dixie Highway Suite 650,CORAL GABLES,FL,331462926,3052843924,CSE,7359,"9218, HPCC",$0.00,"Ongoing breakthroughs in nationally important research areas like Verification and Artificial Intelligence depend on continuing advances in high-performance automated theorem proving tools. The typical use of these tools is as backends: application problems are translated by an application tool into (typically very large and complex) logic formulas, which are then handed off to a logic solver. Different tradeoffs between linguistic expressiveness and the difficulty of solving the resulting problems give rise to different logics. Solver communities, formed around these different logics, have developed their own community research infrastructures to encourage innovation and ease adoption of their solver technology. Such infrastructure includes standard formats for logic formulas, libraries of benchmark formulas, and regular solver competitions to spur solver advances. <br/><br/>Currently, these different infrastructures are all developed separately, at significant cost in equipment and support. These costs are paid again and again for the different services, since there is currently no global piece of computing infrastructure suitable for the logic solving domain, which all these communities can use. This project is building a simplified proof-of-concept of a single piece of shared computing infrastructure, which could eventually be used by many different logic solver communities. The award also provides other support for soliciting research community feedback on the prototype and the design of a comprehensive infrastructure."
78,1025682,VOSS: Culture and Coordination in Global Engineering Teams,OAC,"ENGINEERING EDUCATION, INNOVATION & ORG SCIENCES(IOS), VIRTUAL ORGANIZATIONS",09/01/2010,07/07/2015,Catherine Cramton,VA,George Mason University,Standard Grant,Rajiv Ramnath,08/31/2016,"$400,000.00","Tine Koehler, Raymond Levitt",ccramton@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,"1340, 5376, 7642","110E, 7969",$0.00,"Construction engineering provides the foundation for society: the buildings, bridges, roads and other infrastructure we use every day. Engineering work has become increasingly complex, and big engineering projects are almost always undertaken by teams of engineers whose members are multicultural and distributed around the globe.  Effective coordination is crucial for success, yet recent research suggests that team coordination practices vary with national culture. Experts have warned that engineering education fails to prepare engineers for these differences.<br/><br/>We will use scripts theory, which lies at the intersection of the fields of social psychology and artificial intelligence, to characterize the culturally-specific coordination practices of engineering teams, introducing the notion of ""cultural coordination scripts."" We will 1) characterize and understand the coordination scripts of several specific cultures, 2) show how cultural coordination scripts are intertwined with technical training and technical tasks and 3) determine how differences in cultural coordination scripts in multi-cultural globally-distributed teams affect their capacity to coordinate highly precise work and achieve innovative, safe, timely and cost-effective outcomes. We seek to predict likely points of coordination failure. Data collection will include unobtrusive longitudinal observation of the coordination activities of mono-cultural and multi-cultural collocated and distributed engineering design teams.<br/><br/>This research program will help engineers -- and others who work in multicultural, multi-national project teams -- become more adept in anticipating and working across different cultural expectations related to project coordination. Recommendations will be developed for engineering education and practice. Cultural differences in coordination practices are understudied across domains of application, so our work will provide new knowledge concerning this central team process. We also offer a new approach to capturing the complexity of teamwork ""an approach grounded in scripts theory"" that has the potential to influence research across disciplines."
79,953495,CAREER: Evolutionary Computation and Bioinformatics,IIS,"Info Integration & Informatics, EPSCoR Co-Funding",06/01/2010,07/18/2014,Clare Congdon,ME,University of Southern Maine,Continuing grant,Sylvia Spengler,05/31/2016,"$496,000.00",,congdon@gmail.com,96 Falmouth St,Portland,ME,41049300,2072288536,CSE,"7364, 9150","1045, 1187, 7364, 9102, 9150, 9215, 9251, HPCC",$0.00,"The research focus of this project is to develop a novel evolutionary computation-based approach for identifying candidate modules in non-coding DNA that respond to environmental toxins (such as arsenic) and that alter gene expression. These modules are composed of short pieces of DNA that are binding sites for proteins; the cooperative and combinatorial interactions are believed to contribute to the inducibility and specificity of environmentally responsive genes. Since each gene has an enormous number of possible modules, searching for them in the laboratory is untenable; even an exhaustive computational search for candidate modules is impractical, given the large space. Thus, the development of artificial intelligence techniques is called for.<br/><br/>This is an interdisciplinary proposal that makes contributions in both computer science and biology. The computational contributions include designing an effective search through the large and complex space of possible modules. While a few existing tools have been designed to search the thousand base pair region immediately upstream of the gene, the work here is designed to search significantly longer sections, 1 million base pairs and longer in length. The existing approaches cannot be expected to scale to the larger search, requiring the development of a novel approach.<br/><br/>The PI has plans for introducing undergraduates to research, both through coursework and in supervised research projects. This proposal will support and encourage the creation of a new upper-level course in informatics as well as the development of informatics-themed exercises to be incorporated at the introductory level. The project will further directly support undergraduate researchers who will contribute to the core research project.<br/>This project will result in a well integrated program of research and teaching for the PI, contribute to the available tools and our understanding of evolutionary computation approaches for informatics work, and introduce scores of students to this work."
82,954138,CAREER: Reasoning under Uncertainty in Cybersecurity,CNS,"TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace, EPSCoR Co-Funding",03/01/2010,03/10/2014,Xinming Ou,KS,Kansas State University,Continuing grant,Sylvia J. Spengler,03/31/2016,"$457,373.00",,xou@usf.edu,2 FAIRCHILD HALL,Manhattan,KS,665061100,7855326804,CSE,"7795, 8060, 9150","1045, 7434, 7923, 9150, 9168, 9178, 9251",$0.00,"Cyber security, like security in the physical world, relies upon investigation methodologies that piece together dispersed evidence spread across multiple places, and come to a conclusion on what security breaches have happened and how they happened. While effective evidential reasoning based on manual analysis are used in the physical world by law-enforcement agencies, in the cyber world we need automated reasoning methodologies to handle the automated cyber attacks against our nation's information infrastructures every day. This research aims at discovering and developing such automated reasoning methodologies. The problem is  difficult due to the uncertain nature of such reasoning, which is compounded by the characteristics of cyber attacks.<br/><br/>The uncertainty in cyber security comes from two sources. The first is the uncertainty from not knowing the attacker's actions and choices. Since hackers are essentially invisible in the cyberworld, we have to rely upon various types of sensors that report symptoms of potential attacks. The second source of uncertainty comes from these sensors. Since in most cases the symptoms of cyber<br/>attacks significantly overlap with symptoms from benign network activities, it is not possible to rely on a single sensor to give an absolutely correct judgment on whether an attack has happened and succeeded. A key question is how to use these imperfect sensors to conduct reasoning so that one can come up with almost certain conclusions regarding a system's security status. <br/><br/>This challenge of reasoning under uncertainty is not new. In the past four decades computer science researchers have developed an array of reasoning models and methods for uncertainty, especially in the area of artificial intelligence. However, the emergence of cyber threats poses a new<br/>challenge to this problem. The existing methodologies typically require a knowledge-engineering process to build a knowledge model for the problem domain. This has worked reasonably well with the more static and well-behaved problem domains such as disease diagnosis. A key difference between these problem domains and cyber security is that the latter has to deal with an active<br/>malicious attacker who will try to break whatever assumptions made in the reasoning model. For this reason, the knowledge model for cyber security cannot be static because then they can be easily evaded. What will be an effective and practical knowledge engineering approach to handle the uncertainty in cyber security is the biggest open problem that needs to be answered from the<br/>research.<br/><br/>This research adopts an empirical, bottom-up approach to tackle the above challenges. Instead of starting from the existing theories, the PI will start from empirical study on how a human security analysts would reason about cyber events and try to capture the essence of the reasoning in the process. Then, the PI will carry out this empirical study by running intrusion detection sensors on production networks and work with system administrators to understand and reason about the alerts. The next step is to develop a reasoning model that simulates the human reasoning process, and apply the automated reasoning engine on fresh new data to see how it fares. In this spiral theory development process the PI can always make sure that the methodologies are applicable to real cyber-security analysis and constantly find gaps in the model that reveal what will be the most appropriate theories and how to apply them in this problem. The eventual goal is to find the right theoretical framework for reasoning under uncertainty in cyber-security, and validate such theories through repeatable experiments on data from production systems.<br/><br/>This research is tightly integrated into the PI?s education efforts both for students and targeted at the society at large. The empirical nature of the research provides a valuable venue for dialogue between security practitioners and researchers, which will result in a two-way education process: students working on the project can acquire the essential skills of applying advanced knowledge to a practical problem; and security practitioners like system administrators can learn the state-of-the art in cyber security technology through collaborative work with the research team. The empirical study carried out from the research will provide endless data and examples to refresh the materials of the cyber-security courses taught by the PI. New courses with a focus on uncertainty in cyber security defense will be developed. There will be a number of undergraduate students who take part in the research efforts, which will provide a unique education experience for them. Moreover, the test-bed infrastructure produced from the research will also be used as an education platform for the general public about cyber-security problems, with the help of the out-reach programs already established at Kansas State University."
84,958160,Collaborative  Research: CI-ADDO-NEW: *-EXEC: A Cross-Community Solver Execution Service,CNS,CCRI-CISE Cmnty Rsrch Infrstrc,05/01/2010,05/05/2010,Aaron Stump,IA,University of Iowa,Standard Grant,Todd Leen,04/30/2012,"$84,197.00",Cesare Tinelli,aaron-stump@uiowa.edu,2 GILMORE HALL,IOWA CITY,IA,522421320,3193352123,CSE,7359,"9218, HPCC",$0.00,"Ongoing breakthroughs in nationally important research areas like Verification and Artificial Intelligence depend on continuing advances in high-performance automated theorem proving tools. The typical use of these tools is as backends: application problems are translated by an application tool into (typically very large and complex) logic formulas, which are then handed off to a logic solver. Different tradeoffs between linguistic expressiveness and the difficulty of solving the resulting problems give rise to different logics. Solver communities, formed around these different logics, have developed their own community research infrastructures to encourage innovation and ease adoption of their solver technology. Such infrastructure includes standard formats for logic formulas, libraries of benchmark formulas, and regular solver competitions to spur solver advances.<br/><br/>Currently, these different infrastructures are all developed separately, at significant cost in equipment and support. These costs are paid again and again for the different services, since there is currently no global piece of computing infrastructure suitable for the logic solving domain, which all these communities can use. This project is building a simplified proof-of-concept of a single piece of shared computing infrastructure, which could eventually be used by many different logic solver communities. The award also provides other support for soliciting research community feedback on the prototype and the design of a comprehensive infrastructure."
85,1016509,"AF:  Small:  Beyond Worst-Case Analysis in Approximation Algorithms, Algorithmic Mechanism Design and Online Algorithms",CCF,"ALGORITHMS, COMPUT GAME THEORY & ECON",08/01/2010,07/23/2010,Anna Karlin,WA,University of Washington,Standard Grant,Balasubramanian Kalyanasundaram,07/31/2014,"$499,847.00",,karlin@cs.washington.edu,4333 Brooklyn Ave NE,Seattle,WA,981950001,2065434043,CSE,"7926, 7932","9218, HPCC",$0.00,"In theoretical computer science, algorithms are usually evaluated with respect to their worst-case performance, whereas in other areas, average-case analysis is often used. Both of these approaches have drawbacks: worst-case analysis is overly pessimistic and average-case analysis often rests on unrealistic assumptions. To address these issues, a number of other analysis frameworks have been proposed including self-improving algorithms, smoothed analysis, instance-optimality, and algorithmic design based on a variety of data models. The objective of the project is to continue this line of research and develop techniques that go beyond worst-case analysis in the areas of approximation algorithms, algorithmic mechanism design and online algorithms.  In the area of approximation algorithms for NP-hard problems, the project focuses on the development of approximation algorithms that achieve a kind of instance optimality. In the area of algorithmic mechanism design, the PI will continue to study the design and analysis of profit maximizing auctions in single-parameter environments and beyond. In the area of online algorithms, the PI will work to develop effective online algorithms for a fundamental and practical self-organizing data structure problem.<br/><br/>Through the development of more effective and practical algorithms and a deeper understanding of the performance of these algorithms in practice, this research has the potential to impact a variety of subfields of computer science including artificial intelligence, systems and networking, data mining, and electronic commerce."
91,1048366,EAGER: Persuasive Sensing Networks: A New Frontier to Changing Human Behavior,CNS,Networking Technology and Syst,08/01/2010,07/23/2010,Samir Chatterjee,CA,Claremont Graduate University,Standard Grant,Thyagarajan Nandagopal,06/30/2012,"$149,619.00",,samir.chatterjee@cgu.edu,150 East Tenth Street,Claremont,CA,917115909,9096079296,CSE,7363,7916,$0.00,"This project explores a new frontier called Persuasive Sensing that brings together advances happening in two fields, namely sensor networks and persuasive technology. Today, advances in sensor networks are making it possible to capture, detect, and analyze data. However what is missing is to present relevant information mined from sensor data to subjects about their daily life and activity rhythms and using feedback mechanisms to alter human behavior. It is now demonstrated that human beings normally follow an approximately 24-hour fluctuating rhythm known as circadian activity rhythm. This is an exploratory research project to design and engineer such a prototype system. The data obtained from environmental sensors as well as body-wearable sensors are fused together to generate meaningful feedback to persuade end-users.<br/><br/>This research project is novel in several ways. First, the idea to fuse environmental sensor data that detects activity in space (or location) along with body-wearable sensors that collects physiological health data and utilize both to detect circadian activity rhythms has not be done before. Second, while sensor networks have been used in healthcare applications before, our persuasive feedback based on mining the data and benchmarking it against normal activity and the ability to detect patterns that identify onset of diseases or pathologies is novel. Third, the artificial neural network data mining algorithms that can identify patterns from circadian activity rhythms and then match those against a database of known rhythms will be a significant novel contribution. Finally, people are very different when taking suggestions. In order to achieve effectiveness, the system needs to monitor and learn from human reactions from previous suggestions and adapt. Broader impact includes the use of wireless sensor networks along with persuasive technology design that will open up new possibilities for prevention and help address chronic diseases such as obesity and diabetes. Employing post docs and graduate students, this project will train and educate the next generation of workforce in Healthcare IT and integrate research findings into classroom. Findings from the research will be incorporated into a graduate level course at Claremont Graduate University."
95,1018786,NeTS: Small: Dynamic Spectrum Access for Mission Critical Wireless Networks,CNS,Networking Technology and Syst,08/01/2010,07/20/2010,Dennis Roberson,IL,Illinois Institute of Technology,Standard Grant,Thyagarajan Nandagopal,07/31/2014,"$450,000.00",,dennis.roberson@iit.edu,10 West 35th Street,Chicago,IL,606163717,3125673035,CSE,7363,"7923, 9150",$0.00,"Public safety first responders have a need for increased access to radio spectrum to improve interoperability between agencies in natural and human-caused emergencies, and to accommodate bandwidth intensive applications such as mission critical video surveillance. Dynamic Spectrum Access, a new paradigm that promises improved RF spectrum access and efficiency, has been hindered in its application to mission critical networks by a lack of the detailed understanding of the spectrum utilization characteristics necessary to drive system development.  This project is generating the fundamental long-term and high-resolution spectrum measurements needed to characterize the time, frequency, energy, and spatial dynamics of mission critical wireless networks in a dense urban environment (Chicago). Empirical and analytical models that characterize public safety spectrum utilization are being created from these measurements.  The empirical and analytical models are being used in turn as inputs to discrete-event simulations of candidate mission critical Dynamic Spectrum Access approaches in order to assess the ability of these approaches to improve capacity, while maintaining the necessary performance as measured by access delay and interference tolerance. Results in the form of the RF measurements, empirical and analytical models of mission critical spectral utilization, and system models are being disseminated via a secure download server linked to the Illinois Institute of Technology website. This research will impact Public Safety stakeholders including government agencies, public safety standards bodies, the Federal Communications Commission, and equipment providers by assessing the feasibility of applying to mission critical public safety wireless networks and facilitating system development."
96,1010172,CRCNS: Long Term Reactivations in Cortex and Hippocampus,IIS,"CRCNS-Computation Neuroscience, Robust Intelligence",09/15/2010,06/16/2013,Jean-Marc Fellous,AZ,University of Arizona,Continuing Grant,Kenneth Whang,08/31/2015,"$468,334.00",Masami Tatsuno,fellous@email.arizona.edu,888 N Euclid Ave,Tucson,AZ,857194824,5206266000,CSE,"7327, 7495","7327, 7495, 9251",$0.00,"Understanding how memory is encoded and maintained in our brain is paramount to understanding cognitive functions. Unlike in a computer, human memories are continuously consolidated, reconsolidated, and integrated within the context of what has already been learned. This process is thought to involve exchanges of information between the cortex and the hippocampus during sleep. The investigators will study the ability of small groups of cells in the rodent hippocampus and medial prefrontal cortex (mPFC) to become transiently co-active during sleep periods occurring many hours after learning has taken place. Rats will be engaged in learning tasks aimed at selectively activating one or both of these areas. It is expected that the activity recorded during post-task sleep will be correlated with the activity of the same cells during the task in a manner compatible with the nature of the task and the specifics of the learning. This type of reactivation is considered to be a basic mechanism for memory consolidation.<br/><br/>The investigators have developed new analytical tools based on fuzzy clustering and information geometry. Preliminary data show that short episodes of reactivation occur with different time courses in these two structures, as is often proposed on theoretical grounds. In this project, the investigators will study how this reactivation is coordinated across two connected brain areas (CA3-CA1, CA1-mPFC) on very long time scales, and how single neurons contribute to single reactivating episodes.<br/><br/>These studies will yield insights into the long-term temporal and spatial dynamics of reactivation in the adult rodent. They will also contribute to a better understanding of the neural basis of memory consolidation and reconsolidation in cortex and hippocampus, and the relationship between memory consolidation and sleep."
97,953870,CAREER:  Rational Language Processing with Uncertain and Noisy Input,IIS,"PERCEPTION, ACTION & COGNITION, ROBUST INTELLIGENCE",04/15/2010,08/21/2012,Roger Levy,CA,University of California-San Diego,Continuing grant,Tatiana D. Korelsky,03/31/2016,"$501,529.00",,rplevy@mit.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,"7252, 7495","1045, 1187, 7495, 9215, HPCC",$0.00,"This CAREER award investigates how humans integrate a wide variety of  <br/>information sources to achieve rapid, accurate natural language  <br/>comprehension subject to the physical and cognitive constraints under  <br/>which it takes place.  The project's primary empirical focus is on  <br/>reading, a mode of information exchange of unexceeded importance in  <br/>literate societies.  Reading involves a rapid sequence of targeted eye  <br/>movements throughout a text -- recordable through modern eye-tracking  <br/>technology -- from which noisy sensory input are obtained and  <br/>integrated with prior knowledge to resolve perceptual and linguistic  <br/>uncertainty.  The central goal of this project is thus to develop,  <br/>implement, and test a computational model of language comprehension  <br/>and eye movement control in reading built on principles of  <br/>probabilistic inference and rational action, using the tools of  <br/>natural language processing (NLP) technology, reinforcement learning,  <br/>and behavioral psycholinguistic experimentation.<br/><br/>The success of this project is likely to have major impact in the  <br/>field of human sentence processing, bringing a new level of nuance and  <br/>detail to both theory and data analysis, and will bear on broad  <br/>current debates in cognitive science regarding rationality in  <br/>cognition. Additionally, the results of this basic research project  <br/>have a wide range of potential applications ranging from intelligent  <br/>tutoring technology to language-impairment diagnosis to cognitive  <br/>ergonomics. Together with this research program, the project involves  <br/>an educational program including a new textbook on probabilistic  <br/>models in the study of language, new undergraduate and graduate  <br/>courses, and tutorials and courses on computational psycholinguistics  <br/>at major conferences and summer institutes.<br/><br/>This CAREER award is co-funded by two directorates:: CISE/IIS and SBE/BCS."
98,1017143,"SHF: Small: Fusion of Quantum Dot/Nanowire Based Sensors and Processors in Ultra-low-energy, Distributed-Intelligence Sensing Network",CCF,NANOCOMPUTING,09/01/2010,07/09/2015,Pinaki Mazumder,MI,Regents of the University of Michigan - Ann Arbor,Standard Grant,Sankar Basu,08/31/2016,"$400,281.00",,mazum@eecs.umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,7947,"9150, 9218, HPCC",$0.00,"The purpose of the award is to develop a new nano-circuit architecture, novel circuit realization using quantum-electronic devices, and a comprehensive, vertically integrated design methodology for real-time electronic vision applications.  The architecture integrates nano-optical sensors and active quantum dot processing elements into hybrid, ultra efficient, distributed intelligence systems with meta-level decision making agents.  This is in contrast with conventional electronic vision systems where all decision related processing is done by an algorithmic agent only after digitization of the input from nanowire sensors.  The approach employs a smooth analog-to-digital processing transition to allow en-route, hierarchical transformation of the input into simpler, digital representations of multidimensional, abstract input characteristics while the signal is on its way to the central decision making agent.  A more rapid decision-making can be achieved because the agent can now directly correlate just the key features without first identifying and extracting these features or filtering out extraneous details.  Such close-to-source processing also includes all other desirable benefits like high energy-efficiency, low signal degradation and small area requirement for chip implementation, in addition to high speed. Specifically, fanning-out the input to a cellular-neural-network-like architecture of active quantum-electronic analog functional units will extract and encode the key features that can then be fanned in to one or more decision agents. These units include spatio-temporal filters, velocity estimators, and image processing elements. <br/><br/>The intellectual merits of this research include the construction of nanoscale quantum dots based cellular logic arrays capable of performing neuromorphic computation like spatiotemporal signal processing, video and image processing; and the design of a new CAD tool for optimizing the 3D nanostructures of quantum tunneling devices while performing the system-level optimization in an augmented circuit simulator developed by the principal investigator's research group.  The broader impacts include development of pedagogical interdisciplinary training to the next generation of circuit engineers and supplementary didactic material---two new, definitive textbooks on nanoelectronics."
101,953837,CAREER:  Investigating the Ultimate Mechanisms of Embodied Cognition,IIS,ROBUST INTELLIGENCE,05/15/2010,04/16/2014,Joshua Bongard,VT,University of Vermont & State Agricultural College,Continuing grant,Kenneth C. Whang,04/30/2017,"$499,999.00",,jbongard@uvm.edu,85 South Prospect Street,Burlington,VT,54050160,8026563660,CSE,7495,"1045, 1187, 9150",$0.00,"To date, relatively little success has been achieved in realizing machines that continually perform simple yet adaptive behaviors in unstructured environments (compared to a structured environment such as a factory). The prevailing approach to create such machines is to copy physiological and neurological systems observed in animals, and build them into robots. This raises the issue however of what from among the infinitude of existing biological structures should be copied. Research under this award is pursuing an alternative approach: rather than copy existing biological systems, evolutionary dynamics are copied and connected in a virtual space. The resulting evolutionary algorithm optimize virtual robots' neurological structures that control behavior and their body plans. Importantly, evolution in these studies is task and behavior specific.<br/><br/>The research is intended to make important contributions to robotics and biology. For roboticists, this work will enable computers to automatically design the body plans and neural controllers for robots that are more adaptive and robust than robots designed manually. Automatically-designed virtual robots can then be built as physical devices and deployed into real-world environments, to include those that are dangerous to humans. For biologists, our studies will provide insight into why and how particular structures evolved in nature. For example, if legged robots originally evolved for locomotion are then selected to locomote and grasp objects, computational evolution may re-purpose the robot's front legs into arms and grippers; or, it may add manipulatory appendages onto the existing body plan. Either outcome would be of great interest to evolutionary biologists.<br/><br/>Finally, experiments are being housed in online tools that will allow graduate, undergraduate and K-12 students to run evolutionary simulations passively on their own machines, as well as actively participate in the process: they may design novel virtual environments in which the robots must evolve. This active participation is intended to motivate students to understand the physics, biology, engineering and computational processes underlying evolution."
105,1034594,"Workshop on Applications of Computer Vision in Archaeology ACVA?10 -- Vision, Visualization, and Computational  Methods to Cultural Heritage Needs.",IIS,HCC-Human-Centered Computing,06/01/2010,06/10/2010,Fernand Cohen,PA,Drexel University,Standard Grant,William Bainbridge,05/31/2012,"$31,576.00",,fscohen@coe.drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,7367,"9150, 9215",$0.00,"This proposal is to support a workshop on Applications of Computer Vision in Archaeology.  The workshop will bring together about 100 archaeologists, cultural heritage preservationists, computer vision, visualization, graphics, and new media research and practitioners to discuss the state-of-the art in current research.  The event will also provide a forum for planning and coordination of future efforts. Since the first workshop on Applications of Computer Vision in Archaeology was held in June 2003 the domain of research interest has broadened significantly to include research in graphics and visualization.  At present, nearly all phases of archaeological practice, from discovery in the field, through artifact analysis and conservation, to the presentation of new findings to the public are in a period of radical change.  Computer vision research combined with graphics, visualization and computational methods have made available to archaeology and other interdisciplinary research dealing visual artifacts a rich set of tools and methods to extend research capabilities.   New efforts range from the creation of virtual libraries (digital publishing of field records) to computer-assisted artifact mending technologies to 3D presentations of historical site interpretations."
107,959985,MRI-R2: Development of an Instrument for Information Science and  Computing  in Neuroscience,CNS,Major Research Instrumentation,06/01/2010,03/05/2014,Malek Adjouadi,FL,Florida International University,Standard Grant,Rita Rodriguez,09/30/2015,"$2,939,515.00","Naphtali Rishe, Armando Barreto, Prasanna Jayakar, William Gaillard",adjouadi@fiu.edu,11200 SW 8TH ST,Miami,FL,331990001,3053482494,CSE,1189,6890,"$2,939,515.00","""This award is funded under the American Recovery and Reinvestment Act of 2009(Public Law 111-5).""<br/>Proposal #: 09-59985<br/>PI(s):  Adjouadi, Malek; Barreto, Armando B.; Gaillard,William; Jayakar,Prasanna; Rishe, Naphtali D.<br/>Institution: Florida International University <br/>Title:          MRI-R2/Dev: Instrument for Information Science and Computing in Neuroscience<br/>This project, developing an instrument for information processing and computing that enables cohesive study of the brain, involves the new concept of a 5-D brain processing platform while addressing the challenge of finding the best way to put together five dimensions to provide a complete picture of brain dynamics. This unified approach brings together fields of Computer Engineering, Computer Science, Electrical Engineering, and Bioengineering to create an instrument for precisely measuring and visualizing significant information and results across the five dimensions, three from spatial data, time, and an imaging modality that serves as the fifth dimension. Accomplishing this mission involves advanced designs, hardware-software integration mechanisms, and novel interfaces that bring competing, and sometimes diverging, technologies into a unified brain research platform. Combining a Multi-site Data Repository, Modality Integration and Computational, Visualization, and Operation Support Units, this new instrument is expected to bring:<br/>- New insights into brain structure, functional correlations and dynamics, both in its normal state and under specific pathological conditions,<br/>- Far improved mapping of patterns of brain activity,<br/>- Integration of multimodal technologies in order to augment their capabilities with new insights while consolidating high spatial resolution with high temporal resolution,<br/>- Database design and management augmented with mechanisms for fast user interaction and visualization to meet the challenge of managing complex spatio-temporal datasets, posing complex queries, and establishing effective methods for data representation and visualization, and<br/>- Resolution of those paradigms that confront heavy computational requirements and compatibility problems that arise from the use of different recording modalities and diverse software platforms.<br/>The project aims to collectively overcome the primary barriers in identifying the different factors that influence the functional organization of the brain and its underlying pathology. As an example, it delves in the epileptic seizure that can be mapped over time as it moves along specific fiber tracts that may enable better identification of specific areas of treatment and consequently protect functionally important parts of the brain during surgery that may lead to better and safer outcomes.<br/>Broader Impacts: <br/>Fostering an environment that supports cross disciplinary initiatives, joint collaboration and programs, the instrument establishes a research platform that enables academic institutions and hospitals to investigate multi-site collaborative studies in accordance to systematically administered standardize protocols to a database of common assessments and measures. The project extends the breadth and depth of multidisciplinary efforts including new paradigms and findings. Moreover, the project advances the education, research, and training of many students in a minority serving university."
108,1053105,WORKSHOP: Froniers in Computer Vision,IIS,Robust Intelligence,09/01/2010,08/22/2010,Aude Oliva,MA,Massachusetts Institute of Technology,Standard Grant,Jie Yang,08/31/2012,"$50,000.00",,oliva@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,7495,$0.00,"Computer vision started with the goal of building machines that can see like humans. Nowadays, computer vision has expended to numerous applications such as image database search in the world wide web, computational photography, reconstruction of three-dimensional scenes, surveillance, assistive systems, vision for graphics and nanotechnology, etc. More domains and applications keep arising as computer vision technology develops. <br/><br/> The goal of the workshop in Frontiers in Computer Vision is to bring together national and international experts, from academia and industry, to identify the future impact of computer vision on the economic, social, educational and security needs of the nation and outline the scientific and technological challenges to address the issues: how can computer vision build on the success and enthusiasm of its growing participants? how can the academic community make connections to industry? how to better foster scholarship and improve communication both within computer vision itself and to related disciplines and application areas? How can computer vision best interact with related fields? how can the importance and promise of computer vision be communicated to the general public? <br/><br/>The deliverables of the event  include, among others, videos of the presentations available on the Frontiers in Computer Vision website, together with a roadmap to outline the scientific and technological challenges to address."
109,964269,RI:  Medium:  Collaborative Research:  Unlocking Biologically-Inspired Computer Vision:  A High-Throughput Approach,IIS,ROBUST INTELLIGENCE,09/01/2010,08/27/2010,James DiCarlo,MA,Massachusetts Institute of Technology,Standard Grant,Kenneth C. Whang,08/31/2013,"$410,000.00",David Cox,dicarlo@MIT.EDU,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,"7495, 7924",$0.00,"This project exploits advances in parallel computing hardware and a neuroscience-informed perspective to design next-generation computer vision algorithms that aim to match a human's ability to recognize objects.  The human brain has superlative visual object recognition abilities -- humans can effortlessly identify and categorize tens of thousands of objects with high accuracy in a fraction of a second -- and a stronger connection between neuroscience and computer vision has driven new progress on machine algorithms.  However, these models have not yet achieved robust, human-level object recognition in part because the number of possible ""bio-inspired"" model configurations is enormous. Powerful models hidden in this model class have yet to be systematically characterized and the correct biological model is not known.<br/><br/>To break through this barrier, this project will leverage newly available computational tools to undertake a systematic exploration of the bio-inspired model class by using a high-throughput approach in which millions of candidate models are generated and screened for desirable object recognition properties (Objective 1).  To drive this systematic search, the project will create and employ a suite of benchmark vision tasks and performance ""report cards"" that operationally define what constitutes a good visual image representation for object recognition (Objective 2).  The highest performing visual representations harvested from these ongoing high-throughput searches will be used: for applications in other machine vision domains, to generate new experimental predictions, and to determine the underlying computing motifs that enable this high performance (Objective 3).   Preliminary results show that this approach already yields algorithms that exceed state-of-the-art performance in object recognition tasks and generalize to other visual tasks.<br/><br/>As the scale of available computational power continues to expand, this approach holds great potential to rapidly accelerate progress in computer vision, neuroscience, and cognitive science: it will create a large-scale ""laboratory"" for testing neuroscience ideas within the domain of computer vision; it will generate new, testable computational hypotheses to guide neuroscience experiments; it will produce a new kind of multidimensional image challenge suite that will be a rallying point for computer models, neuronal population studies, and behavioral investigations; and it could unleash a host of new applications."
110,1010463,CRCNS: US-German Collaboration: Auditory and Spatial Sequence Encoding in the Hippocampus,IIS,"COLLABORATIVE RESEARCH, CRCNS",09/15/2010,09/04/2012,Stefan Leutgeb,CA,University of California-San Diego,Continuing grant,Kenneth C. Whang,08/31/2014,"$349,982.00",,sleutgeb@ucsd.edu,Office of Contract & Grant Admin,La Jolla,CA,920930621,8585344896,CSE,"7298, 7327","5936, 5979, 7327",$0.00,"Complex cognitive functions such as spatial cognition, language development, and episodic memory require associations between multiple sensory experiences, such as images and sound, and require that associations are remembered in sequence. The rodent hippocampus has been one of the leading models for understanding neuronal mechanisms for remembering a sequence of spatial locations. Yet, it remains unknown whether the mechanisms that are used for encoding a path through space are the same as those that are used for encoding sequences that contain multiple modalities. To address this question, the auditory modality is of particular interest since it provides a mean to present a sequence of stimuli with high temporal precision and thus a mean to investigate time constraints for sequence learning. The proposed research investigates auditory sequence learning in a rodent species that is a hearing-specialist and tests whether the hippocampus of Mongolian gerbils can encode sequences of auditory stimuli with mechanisms similar to those used for spatial sequences. <br/><br/>It will be tested whether place fields and theta phase precession exist in Mongolian gerbils, whether complex sound stimuli are encoded in the gerbil hippocampus in a spatially-independent manner or in association with the location of the animal, and whether sound sequences are encoded with network mechanisms related to those that are used for encoding spatial sequences. These questions will be addressed with single-unit recording from hippocampal principal cell populations of behaving animals, and experiments will be conducted in a virtual reality setup that allows for the precise delivery of auditory stimuli. Performing these experiments in a rodent species with an auditory specialization might result in important advances in addressing how the hippocampus encodes multimodal sequences. This research can provide important insight into neural network mechanisms for sequence coding and can lead to a better understanding of the contribution of the hippocampus to language development in humans.<br/><br/>This project is jointly funded by Collaborative Research in Computational Neuroscience and the Office of International Science and Engineering.  A companion project is being funded by the German Ministry of Education and Research (BMBF)."
111,1011778,EAGER: Phylo: Phylogenetic Reconstruction of Textual Histories,IIS,ROBUST INTELLIGENCE,02/01/2010,01/22/2010,David Chiang,CA,University of Southern California,Standard Grant,Tatiana D. Korelsky,01/31/2012,"$75,000.00",,dchiang@nd.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,7495,7495,$0.00,"This project, supported by an EArly-concept Grant for Exploratory Research (EAGER), is developing computational models of how manuscripts of premodern texts changed over time due to copying with errors, intentional editing, and translation into different languages. The purpose of these models is to reconstruct the original texts and to better understand the forces that shaped them. We are building on work applying ideas from computational evolutionary biology to the task, but the main focus of the project is to explore whether cutting-edge ideas from computational linguistics and natural language processing are better suited for modeling the evolution of natural-language texts. In particular we are exploring the use of techniques from nonprojective dependency parsing to model the tree of relationships among manuscripts and statistical machine translation to model the relationship between pairs of manuscripts.<br/><br/>The tools that result from the project will be made publicly available in order to foster cross-disciplinary research. These tools will enable scholars of ancient and medieval literature to use our models to analyze collections of manuscripts that may not have been possible to analyze by hand before. The techniques explored will shed light on computationally hard learning and search problems such as those that frequently arise in natural language processing."
112,1017190,HCC: Small: Collaborative Research:  Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children,IIS,HCC-Human-Centered Computing,09/01/2010,08/19/2010,Yang Liu,TX,University of Texas at Dallas,Standard Grant,Ephraim Glinert,08/31/2015,"$195,726.00",,yangl@hlt.utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,7367,"7923, 9102, 9150",$0.00,"It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development.  Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds.  Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills.  These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions.  Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced.  Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones.  At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task   In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children.   With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts.  Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country).  Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities.   Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children.  <br/><br/>Broader Impacts:  This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date.  Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general.  Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains.  In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used."
113,1018124,HCC: Small: Collaborative Research:  Analysis of Language Samples for Detecting Language Impairment in Monolingual and Bilingual Children,IIS,"HCC-Human-Centered Computing, EPSCoR Co-Funding",09/01/2010,08/19/2010,Thamar Solorio,AL,University of Alabama at Birmingham,Standard Grant,Ephraim Glinert,10/31/2014,"$301,055.00",,thamar.solorio@gmail.com,AB 1170,Birmingham,AL,352940001,2059345266,CSE,"7367, 9150","7923, 9102, 9150",$0.00,"It is widely recognized that language impairment can have a negative effect on literacy skills, and that children suffering language impairment are at a higher risk of academic under-achievement and lower overall social development.  Hence, early and accurate language assessment for children is critical, especially for those with non-mainstream linguistic backgrounds.  Spontaneous language samples are commonly used in communication disorders to measure the speaker's competence across a range of complementary language skills.  These elicitation tasks allow clinicians and clinical researchers to analyze speech fluency by looking at the patterns of disfluencies and other speech disruptions.  Language productivity can be gauged by computing mean length of utterance, along with measures of vocabulary and total utterances produced.  Morpho-syntactic skills can also be analyzed from these data, by manually coding for specific grammatical constructions that are known to signal developmental milestones.  At present, use of the information contained in these language samples is restricted to the capacity of human experts to manually analyze the data, since little has been done to use computational models for this task   In this collaborative effort by PIs in the University of Alabama at Birmingham and the University of Texas at Dallas, the objective is to address this problem by developing computational approaches for scoring samples from children along different language dimensions, including speech fluency, syntactic structure, content, and coherence, with the long term goal of building robust computational linguistic approaches for identifying language impairments in children.   With these ends in mind, the PIs will investigate a number of core research questions, including measuring syntactic complexity in children's language, evaluating content in story retelling and play sessions, and detecting disfluencies in children's transcripts.  Moreover, this research will focus on analyzing samples from children with three different language backgrounds: English monolinguals, Spanish monolinguals, and Spanish-English bilinguals of Mexican descent (the latter representing the fastest growing minority in this country).  Since their models will be data driven, the PIs expect to be able to evaluate empirically the differences in developmental patterns of speech in children across these linguistic diversities.   Addressing the bilingual population involves modeling code-switching behavior; thus, additional core research questions include measuring syntactic complexity in code-switched data, and identification and categorization of code-switching patterns in bilingual children.  <br/><br/>Broader Impacts:  This research will contribute to developing more accurate and practical tools for assessing language development in children, a field to which little attention has been paid to date.  Addressing the challenges involved in the automated analysis of children's speech will also advance the field of Natural Language Processing (NLP) in general.  Moreover, since the project involves children with three different linguistic backgrounds, the new technology will have low language dependency and so should be easily portable to other languages and domains.  In the field of communication disorders, applying corpus-based approaches to language assessment is still in its infancy; project outcomes will have a direct impact on this field, by providing new metrics for scoring spontaneous language samples of children that can complement the battery of assessment tools currently used."
114,1002634,Student Research Workshop in Computational Linguistics at the ACL 2010 Conference,IIS,Robust Intelligence,02/01/2010,01/08/2010,Tomasz Strzalkowski,NY,SUNY at Albany,Standard Grant,Tatiana Korelsky,01/31/2012,"$17,700.00",,tomek@rpi.edu,1400 WASHINGTON AVE MSC 100A,Albany,NY,122220100,5184374974,CSE,7495,7495,$0.00,"The Association for Computational Linguistics (ACL) is the primary international organization in the field of natural language processing. The ACL's annual conference is the major international conference in this field. This project is to subsidize travel, conference, and housing expenses of students selected to participate in the Association for Computational Linguistics (ACL) Student Research Workshop, which is part of the ACL conference on July 11-16, 2010 in Uppsala, Sweden. The workshop consists of two tracks: paper presentations and poster presentations. Each paper presentation is followed by a discussion chaired by respected researchers in the field. The poster session provides a further opportunity for extended one-on-one interaction with the members of the CL research community. All selected work has only student authors and the workshop is organized and run by students.<br/><br/>The Student Research Workshop provides a valuable opportunity for the next generation of natural language processing researchers to enter the computational linguistics community. It allows the best students in the field to take their first important step toward becoming professional computational linguists by receiving critical feedback on their work from external experts, and by making contacts with other students and senior researchers in their field. The students who are involved in running and selecting papers for the workshop also gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference. The workshop contributes to the maintenance and development of a skilled and diverse computational linguistics and natural language processing research community."
115,1022697,Student Research Workshop in Computational Linguistics at the NAACL HLT 2010 Conference,IIS,Robust Intelligence,05/01/2010,03/10/2010,Diane Litman,PA,University of Pittsburgh,Standard Grant,Tatiana Korelsky,04/30/2011,"$18,000.00",,litman@cs.pitt.edu,300 Murdoch Building,Pittsburgh,PA,152603203,4126247400,CSE,7495,"7495, 9102",$0.00,"The NAACL HLT conference is the major international conference in North America in the field of natural language processing. This project is to subsidize travel, conference, and housing expenses of students selected to participate in the NAACL HLT Student Research Workshop which will be held during the conference June 1-6, 2010 in Los Angeles, California. The workshop consists of two tracks: full paper presentations and poster presentations. All selected work has only student primary authors. The full paper sessions are composed of paper presentations followed by a discussion panel led by respected researchers in the field. The workshop is organized and run by students.<br/><br/>The Student Research Workshop provides a valuable opportunity for the next generation of natural language processing researchers to enter the computational linguistics community. It allows the best students in the field to take their first important step toward becoming professional computational linguists by receiving critical feedback on their work from external experts, and by making contacts with other students and senior researchers in their field. The students who are involved in running and selecting papers for the workshop also gain valuable opportunities for professional growth and interaction with the researchers on the organizing committee of the main conference. The workshop contributes to the maintenance and development of a skilled and diverse computational linguistics and natural language processing research community."
117,1040711,Workshop/Tutorial/Competition:  Computational Symmetry in Computer Vision,IIS,ROBUST INTELLIGENCE,06/15/2010,06/10/2010,Yanxi Liu,PA,Pennsylvania State Univ University Park,Standard Grant,Jie Yang,05/31/2012,"$28,517.00",,yanxi@cse.psu.edu,110 Technology Center Building,UNIVERSITY PARK,PA,168027000,8148651372,CSE,7495,7495,$0.00,"Humans, animals and insects have an innate ability to perceive and take <br/>advantage of symmetry, which is a pervasive phenomenon presenting itself <br/>in all forms and scales in natural and man-made environments. Although <br/>our understanding of repeated patterns is generalized by the mathematical concept of symmetries and group theory, perception and recognition of symmetry has yet to be fully explored in machine intelligence and computer vision, and few effective computational methods are available today. <br/><br/>In response to a resurging interest in computational symmetry with the vision community, this timely and unique workshop/tutorial/competition is organized to investigate this potentially powerful intermediate level tool.<br/><br/>The event has three main parts:<br/>(1) a multidisciplinary perspective on the importance and lasting impact of symmetry, presented by a worldwide group of distinguished speakers;<br/><br/>(2) a detailed summary of the mathematical theory, state of the art algorithms and a diverse set of applications (successes and failures); and<br/><br/>(3) the algorithms and the outcome of the symmetry detection competition, presented by the top three performers on the benchmarked symmetry detection algorithm competition.<br/><br/>Active participations by computer vision researchers, especially graduate students, in this event are expected, leading to broadened understanding and appreciation of symmetry in all participants, as well as an acute and lasting impact to their research and their use of computational symmetry tools. A website with the content of the workshop/tutorial, the competition process and final results is set up before and augmented after the workshop, for public access."
118,1049032,EAGER: A New Framework for Balancing Deformability and Discriminability in Computer Vision,IIS,Robust Intelligence,09/01/2010,08/22/2010,Haibin Ling,PA,Temple University,Standard Grant,Jie Yang,08/31/2012,"$68,863.00",,hling@cs.stonybrook.edu,1801 N. Broad Street,Philadelphia,PA,191226003,2157077547,CSE,7495,"7495, 7916",$0.00,"Deformability and discriminability are often two ""conflicting"" factors in computer vision problems such as shape matching and object recognition. For example, it has been observed that strong deformation invariant descriptors often suffer from low discriminative powers for category recognition. This EAGER project explores a new framework for balancing deformability and discriminability for computer vision tasks. The framework uniformly embeds an object, which can be a 2D shape, a point set, an image, a 3D volume or a surface, in a high dimensional space named aspect space. The embedding parameter is then used to control the degree of deformation insensitivity. Both the theoretic and application sides of the proposed framework are investigated. Based on the framework, the project aims to develop three additional research goals: robust shape matching methods by selecting deformability adaptively, robust point set registration methods by dealing with articulation in the framework, and robust image matching by extracting features in the embedded aspect space. These goals are planned to be evaluated on real applications including silhouette-based foliage data retrieval, 3D marker matching in computer-based physical therapy, and image-based disease screening. <br/>The project aims to bridge the two main problems, handling deformation and improving discriminability, which relate to many subfields inside and outside computer vision. The interdisciplinary applications are expected to generate significant contributions to various fields including biodiversity studies, biomedical study, etc. The research results, including code and data, are made public available through the project website."
120,1118355,"II-NEW: Collaborative Research: Spam Processing, Archiving, and Monitoring Community Facility (SPAM Commons)",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,12/01/2010,03/11/2011,Brent Kang,VA,George Mason University,Standard Grant,Marilyn McClure,08/31/2012,"$50,391.00",,bkang5@gmu.edu,4400 UNIVERSITY DR,FAIRFAX,VA,220304422,7039932295,CSE,7359,"7359, 9218, HPCC",$0.00,"In this project, the PIs propose to construct and develop a shared infrastructure to support the collection and maintenance of realistic, large scale spam data sets, <br/>referred as SPAM Commons.<br/><br/>Spam is a problem in many important communications media such as email and web. A sub-problem of spam, phishing (a form of online pretexting), caused an estimated $3.2B in damages in 2007. The broad impact of effective spam filtering methods can be estimated in billions of dollars in several communications media such as email and web.<br/><br/>Spam has also invaded other media, with concrete attack examples in social networks, blogosphere, Internet telephony (VoIP), instant messaging, and click fraud. <br/><br/>Unfortunately, spam research has been hampered by the lack of published real world data sets due to concerns with privacy and company intellectual property. This project team develops a shared infrastructure to support the collection and maintenance of realistic, large scale spam data sets, called Spam Processing, Archiving, and Monitoring Community Facility (SPAM Commons). <br/><br/>The main goals of SPAM Commons are: <br/>(1) to facilitate remedial research that will stem the wastes and losses caused by spam, and <br/>(2) enable revolutionary research that aim for stopping certain kinds of spam attacks altogether. <br/><br/>SPAM Commons is divided into a Public Partition and a Protected Partition.<br/><br/>The Public Partition is a direct analog of standard corpora for speech and image recognition research, consisting of a systematic and regular collection of both spam and legitimate data in the various communications media, starting from email and web spam, and expanding into other communications media as spam becomes a serious threat in each area and data become available. <br/><br/>The Protected Partition consists of a combined data and processing facility that makes private data or near real-time spam data available for experimental evaluation of spam defense mechanisms in a protected testbed. Access to such protected data will enable new spam research on real-time evolving spam and real world data sets that is infeasible today. <br/><br/>The intellectual challenges of the SPAM Commons project extend beyond the new research on various abovementioned spam areas enabled by the availability of data sets. The construction of both partitions of SPAM Commons includes significant intellectual challenges of their own. First, the isolation of Protected Partition addresses partially the concerns of privacy, which remains a general research problem. Second, useful spam and legitimate data sets require automated distinction of spam from legitimate documents with certainty, which remains an open research question in email, web, and other media. Third, the adversarial and mutual evolution of spam producers and defenders require continuous collection of fresh data for further study. Finally, the collection and streaming of near-real-time spam data represent research resources currently unavailable to spam researchers. Advances in these areas will spur the growth and evolution of SPAM Commons that will enable new research on the evolving and growing spam problem.<br/><br/>The impact of SPAM Commons data sets on experimental spam research may be similar to the impact of large corpora in disciplines such as speech/image recognition and natural language processing, which achieved a level of scientific result reproducibility and comparativeness after the use of such corpora became standard requirements. The proposed data repository will be supported and used by 9 university partners (Clayton State, Emory, Georgia Tech, NC A&T, Northwestern, Texas A&M, UC Davis, U. Georgia, UNC Charlotte), and several industry partners (IBM, PureWire, Secure Computing)."
123,968583,SoCS:  Collaborative Research:  Leveraging Others' Insights to Improve Collaborative Analysis,IIS,"Information Technology Researc, SOCIAL-COMPUTATIONAL SYSTEMS",07/01/2010,04/06/2011,Sara Kiesler,PA,Carnegie-Mellon University,Standard Grant,Tatiana Korelsky,06/30/2015,"$265,915.00",,kiesler@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"1640, 7953","7953, 9215, 9251",$0.00,"This research seeks to improve collaborative analysis in fields such as criminal justice, intelligence, and epidemiology by developing tools that capture and represent essential elements of analytic conversations. The work has three major aims: (a) understanding how team hypotheses, insights, and problem orientation are reflected in their conversations; (b) developing and testing natural language processing (NLP) techniques to detect teams? hypotheses, insights, and problem orientation; and (c) developing and testing methods to communicate the results of NLP analyses to provide teams with feedback on their own and other teams? reasoning processes. These goals are addressed through behavioral studies, NLP research, and tool development and evaluation.<br/>Intellectual merit: The project provides unique contributions in four areas: (a) understanding how team analytical processes are evidenced in team communication; (b) advancing the state-of-the art in NLP by developing discourse analysis techniques for use in collaborative analysis applications; (c) applying NLP techniques to the support of team analytical processes; and (d) designing interfaces to provide feedback within and across teams. The research also furthers the training and education of undergraduate and graduate students. <br/>Broader impact: The project has the potential to improve collaborative investigative analysis in many fields of critical importance to society, including criminal justice, intelligence, science, and epidemiology. The results will provide new tools for analysts, recommendations for organizational practices to improve the quality of collaborative analysis, new methods for training professional analysts, and new learning tools for graduate programs in fields such as epidemiological analysis and criminal justice."
125,1018590,III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications,IIS,Info Integration & Informatics,09/15/2010,09/13/2010,Razvan Bunescu,OH,Ohio University,Standard Grant,Sylvia Spengler,08/31/2014,"$224,540.00",,bunescu@ohio.edu,108 CUTLER HL,ATHENS,OH,457012979,7405932857,CSE,7364,7923,$0.00,"This project is devoted to building a large multilingual semantic network<br/>through the application of novel techniques for semantic analysis<br/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br/>the project is that the structure of Wikipedia can be effectively used to<br/>create a highly structured graph of world knowledge in which nodes<br/>correspond to entities and concepts described in Wikipedia, while edges<br/>capture ontological relations such as hypernymy and meronymy. Special<br/>emphasis is given to exploiting the multilingual information available in<br/>Wikipedia in order to improve the performance of each semantic analysis<br/>tool. Significant research effort is therefore aimed at developing tools<br/>for word sense disambiguation, reference resolution and the extraction of<br/>ontological relations that use multilingual reinforcement and the<br/>consistent structure and focused content of Wikipedia to solve these tasks<br/>accurately. An additional research challenge is the effective integration<br/>of inherently noisy evidence from multiple Wikipedia articles in order to<br/>increase the reliability of the overall knowledge encoded in the global<br/>Wikipedia graph. Computing probabilistic confidence values for every piece<br/>of structural information added to the network is an important step in<br/>this integration, and it is also meant to provide increased utility for<br/>downstream applications. The proposed highly structured semantic network<br/>complements existing semantic resources and is expected to have a broad<br/>impact on a wide range of natural language processing applications in need<br/>of large scale world knowledge.<br/><br/>For further information, please see the project website:<br/>http://lit.csci.unt.edu/index.php/Mu.Se.Net"
126,968450,SoCS:  Collaborative Research:  Leveraging Others' Insights to Improve Collaborative Analysis,IIS,"INFORMATION TECHNOLOGY RESEARC, SOCIAL-COMPUTATIONAL SYSTEMS",07/01/2010,06/06/2012,Claire Cardie,NY,Cornell University,Standard Grant,Tatiana D. Korelsky,06/30/2014,"$519,471.00",Claire Cardie,cardie@cs.cornell.edu,373 Pine Tree Road,Ithaca,NY,148502820,6072555014,CSE,"1640, 7953","7953, 9215, 9251",$0.00,"This research seeks to improve collaborative analysis in fields such as criminal justice, intelligence, and epidemiology by developing tools that capture and represent essential elements of analytic conversations. The work has three major aims: (a) understanding how team hypotheses, insights, and problem orientation are reflected in their conversations; (b) developing and testing natural language processing (NLP) techniques to detect teams? hypotheses, insights, and problem orientation; and (c) developing and testing methods to communicate the results of NLP analyses to provide teams with feedback on their own and other teams? reasoning processes. These goals are addressed through behavioral studies, NLP research, and tool development and evaluation.<br/>Intellectual merit: The project provides unique contributions in four areas: (a) understanding how team analytical processes are evidenced in team communication; (b) advancing the state-of-the art in NLP by developing discourse analysis techniques for use in collaborative analysis applications; (c) applying NLP techniques to the support of team analytical processes; and (d) designing interfaces to provide feedback within and across teams. The research also furthers the training and education of undergraduate and graduate students. <br/>Broader impact: The project has the potential to improve collaborative investigative analysis in many fields of critical importance to society, including criminal justice, intelligence, science, and epidemiology. The results will provide new tools for analysts, recommendations for organizational practices to improve the quality of collaborative analysis, new methods for training professional analysts, and new learning tools for graduate programs in fields such as epidemiological analysis and criminal justice."
127,1018314,RI:  Small:  Acquiring Domain Knowledge from Text through Cooperative Bootstrapping,IIS,"Info Integration & Informatics, Robust Intelligence",07/01/2010,05/06/2011,Ellen Riloff,UT,University of Utah,Continuing grant,Tatiana Korelsky,06/30/2015,"$391,845.00",,riloff@cs.utah.edu,75 S 2000 E,SALT LAKE CITY,UT,841128930,8015816903,CSE,"7364, 7495","7923, 9150, 9251",$0.00,"Some of the most pressing needs for natural language processing (NLP) technology come from specialized domains where broad-coverage solutions are not sufficient, such as clinical medicine and molecular biology.  This project focuses on the development of bootstrapped learning techniques to rapidly create domain-specific semantic analyzers, and the automatic harvesting of domain knowledge from unstructured text.<br/><br/>This project establishes a new cooperative bootstrapping paradigm to learn semantic analyzers for different tasks simultaneously by allowing classifiers for different tasks to learn from each other.<br/>These analyzers then populate a domain event graph with semantic information extracted from a domain-specific text collection. New knowledge harvesting algorithms acquire domain-specific facts and inference rules from the graph. This project explores the domain of veterinary medicine using message board posts by veterinarians to acquire real-world knowledge for the purposes of animal health surveillance.<br/><br/>This work will advance the state-of-the-art in natural language technology by developing a new bootstrapping framework to rapidly create semantic analysis tools for specialized domains.  This technology will impact many NLP applications, including information extraction, question answering, and summarization.  The knowledge harvesting tools will be made publicly available to allow for direct impact across many disciplines that have a need to extract knowledge from unstructured text collections.  This project will also benefit society by creating new tools for animal health surveillance, which could provide early warning signs of zoonotic disease outbreaks (such as bird flu and mad cow disease), exposures to toxic substances, and contamination in the food chain."
128,1037944,"Collaborative Research:  Sino-USA Summer School in Vision, Learning, Pattern Recognition VLPR 2010",IIS,"Catalyzing New Intl Collab, Robust Intelligence",07/15/2010,07/15/2010,Ying Wu,IL,Northwestern University,Standard Grant,Jie Yang,09/30/2012,"$25,000.00",,yingwu@eecs.northwestern.edu,750 N. Lake Shore Drive,Chicago,IL,606114579,3125037955,CSE,"7299, 7495","5978, 7299, 7495, 9200",$0.00,"The recent decade has witnessed rapid advances in computer vision research, not only in its fundamental studies but also its emerging applications. This Sino-USA summer school in Vision, Learning and Pattern Recognition (VLPR 2010) is held in Xi'an City, China. It brings together a high-quality team of leading American and Chinese researchers in computer vision to offer a one-week educational program to students and junior scholars from both US and China. This education program provides an important opportunity to discuss recent advance in Perception, Motion and Events, and allows technical and culture exchanges between researchers from two countries. Such interactions are important for fostering new understanding and new collaborations in science, education, and culture. <br/><br/>Summer School web site: http://vlpr2010.eecs.northwestern.edu/"
129,1037845,"Collaborative Research:  Sino-USA Summer School in Vision, Learning, Pattern Recognition VLPR 2010",IIS,"Catalyzing New Intl Collab, ROBUST INTELLIGENCE",07/15/2010,07/15/2010,James Rehg,GA,Georgia Tech Research Corporation,Standard Grant,Jie Yang,06/30/2011,"$25,000.00",,rehg@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,"7299, 7495","5978, 7299, 7495, 9200",$0.00,"The recent decade has witnessed rapid advances in computer vision research, not only in its fundamental studies but also its emerging applications. This Sino-USA summer school in Vision, Learning and Pattern Recognition (VLPR 2010) is held in Xi'an City, China. It brings together a high-quality team of leading American and Chinese researchers in computer vision to offer a one-week educational program to students and junior scholars from both US and China. This education program provides an important opportunity to discuss recent advance in Perception, Motion and Events, and allows technical and culture exchanges between researchers from two countries. Such interactions are important for fostering new understanding and new collaborations in science, education, and culture. <br/><br/>Summer School web site: http://vlpr2010.eecs.northwestern.edu/"
130,1018613,III: Small: Collaborative Research: Building a Large Multilingual Semantic Network for Text Processing Applications,IIS,Info Integration & Informatics,09/15/2010,09/11/2013,Rada Mihalcea,TX,University of North Texas,Standard Grant,Sylvia Spengler,08/31/2014,"$275,336.00",,mihalcea@umich.edu,1155 Union Circle #305250,Denton,TX,762035017,9405653940,CSE,7364,7923,$0.00,"This project is devoted to building a large multilingual semantic network<br/>through the application of novel techniques for semantic analysis<br/>specifically targeted at the Wikipedia corpus. The driving hypothesis of<br/>the project is that the structure of Wikipedia can be effectively used to<br/>create a highly structured graph of world knowledge in which nodes<br/>correspond to entities and concepts described in Wikipedia, while edges<br/>capture ontological relations such as hypernymy and meronymy. Special<br/>emphasis is given to exploiting the multilingual information available in<br/>Wikipedia in order to improve the performance of each semantic analysis<br/>tool. Significant research effort is therefore aimed at developing tools<br/>for word sense disambiguation, reference resolution and the extraction of<br/>ontological relations that use multilingual reinforcement and the<br/>consistent structure and focused content of Wikipedia to solve these tasks<br/>accurately. An additional research challenge is the effective integration<br/>of inherently noisy evidence from multiple Wikipedia articles in order to<br/>increase the reliability of the overall knowledge encoded in the global<br/>Wikipedia graph. Computing probabilistic confidence values for every piece<br/>of structural information added to the network is an important step in<br/>this integration, and it is also meant to provide increased utility for<br/>downstream applications. The proposed highly structured semantic network<br/>complements existing semantic resources and is expected to have a broad<br/>impact on a wide range of natural language processing applications in need<br/>of large scale world knowledge.<br/><br/>For further information, please see the project website:<br/>http://lit.csci.unt.edu/index.php/Mu.Se.Net"
133,1036868,Collaborative Research:  Workshop for Women in Machine Learning,IIS,"Info Integration & Informatics, Robust Intelligence",09/01/2010,06/28/2010,Jennifer Vaughan,CA,University of California-Los Angeles,Standard Grant,Todd Leen,08/31/2014,"$41,824.00",,jenn@cs.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,"7364, 7495",7495,$0.00,"Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br/>learning community to exchange research ideas and build mentoring and networking relationships. The<br/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br/>environment in which to present their research (in many cases, for the first time) and enabling them to<br/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br/>within the machine learning community. As invited speakers, established researchers at top universities<br/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br/>machine learning. Students will present their own research and receive valuable feedback from both<br/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br/>exchange research ideas and form new relationships, we expect that new connections and research<br/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br/>Bringing together women from different stages of their careers gives established researchers the<br/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination."
135,1037002,Collaborative Research:  Workshop for Women in Machine Learning,IIS,ROBUST INTELLIGENCE,09/01/2010,06/28/2010,Hanna Wallach,MA,University of Massachusetts Amherst,Standard Grant,Todd Leen,08/31/2014,"$6,330.00",,wallach@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7495,7495,$0.00,"Since 2006, the annual workshop for Women in Machine Learning (WiML) has brought together female<br/>researchers in industry and academia, postdoctoral fellows, and graduate students from the machine<br/>learning community to exchange research ideas and build mentoring and networking relationships. The<br/>one-day workshop has been especially beneficial for junior graduate students, giving them a supportive<br/>environment in which to present their research (in many cases, for the first time) and enabling them to<br/>meet peers and more senior researchers in the field of machine learning. The networking opportunities<br/>provided by the workshop have also helped senior graduate students find jobs following graduation.<br/>Intellectual Merit: This workshop will advance machine learning knowledge and foster collaboration<br/>within the machine learning community. As invited speakers, established researchers at top universities<br/>and research labs will teach workshop participants about cutting-edge ideas from diverse areas of<br/>machine learning. Students will present their own research and receive valuable feedback from both<br/>senior researchers and their peers. By enabling women at all stages of their careers in machine learning to<br/>exchange research ideas and form new relationships, we expect that new connections and research<br/>collaborations will be established, thereby advancing the state-of-the-art of the field.<br/>Broader Impact: This workshop will provide a forum for female graduate students, postdoctoral fellows,<br/>junior and senior faculty, and industry and government research scientists to exchange research ideas and<br/>establish networking and mentoring relationships. Undergraduates, particularly those who are interested<br/>in pursuing graduate school or industry positions in machine learning, are also welcome to attend.<br/>Bringing together women from different stages of their careers gives established researchers the<br/>opportunity to act as mentors, and enables junior women to find female role models working in the field<br/>of machine learning. The workshop will also benefit the wider machine learning community: Firstly, the<br/>WiML website, which lists all previous workshop presenters, serves as a useful resource for organizations<br/>looking for female invited speakers. Secondly, co-locating with a major machine learning conference<br/>enhances the visibility of female researchers among the wider machine learning community. Thirdly,<br/>travel funding provided to workshop participants also facilitates their travel to the co-located conference,<br/>which for some participants would otherwise not be possible. Finally, all workshop materials (slides,<br/>abstracts, etc.) will be made available on the workshop website in order to ensure broad dissemination."
140,953181,CAREER: Socially Guided Machine Learning,IIS,HCC-Human-Centered Computing,01/01/2010,02/07/2014,Andrea Thomaz,GA,Georgia Tech Research Corporation,Continuing Grant,Ephraim Glinert,12/31/2015,"$551,063.00",,athomaz@ece.utexas.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7367,"1045, 1187, 7218, 7367, 9102, 9215, HPCC",$0.00,"There is currently a surge of interest in service robotics, a desire to have robots leave the labs and factory floors to help solve issues facing society.  But if robots are to play a useful role in domains ranging from eldercare to education, they will need the ability to interact with ordinary people and to acquire new relevant skills after they are deployed; we cannot pre-program these robots with every skill they might conceivably need.  The PI's approach to solving this critical issue is Socially Guided Machine Learning (SG-ML).  In this project she will explore ways in which machine learning agents can exploit principles of human social learning.  An important question for SG-ML is ""What is the right level of human involvement?""  Previous efforts in machine learning systems that use human input have tended to hold this level constant (e.g., guidance oriented approaches that are completely dependent on human instruction in order to learn, and exploration oriented approaches with limited input from a human partner).  The PI, taking her inspiration from human learning and from her prior work in robot learning, posits that a robot should be able to explore and learn on its own, while also taking full advantage of a human partner's guidance when available.  The PI's goal in this work is to successfully incorporate self and social learning within a single SG-ML framework, enabling a robot learner to dynamically adjust to varying levels of human involvement in the learning process.  To this end, the PI will seek to make progress toward four main objectives:<br/><br/>1) Motivations for learning: Typically machines learn because they are programmed to do so, unlike children and animals who learn because they are motivated to master their environment.  A key component of this work is computational motivations that drive a robot to good learning opportunities.<br/><br/>2) Multiple learning strategies: As mentioned above, an SG-ML framework should have a repertoire of self and social learning mechanisms working together. A central issue of this research is how the robot should best arbitrate and manage the use of multiple strategies.<br/><br/>3) Transparency devices: Learning is a collaborative activity. The learner's behavior has to be understandable, and has to express a certain level of internal state to help the teacher guide the learning process.  Transparency is a fundamental issue of this work, developing robot behaviors that successfully communicate the progress of the learning process.<br/><br/>4) Engagement mechanisms: In human social learning, teaching is a rewarding process for both the learner and the teacher.  This is a positive feedback loop from which a machine learner could benefit.  A primary component of this work is to develop mechanisms that make the teaching process rewarding.<br/><br/>Broader Impacts:  The long-term promise of this research is robots in society able to adapt and learn from everyday people.  The core principles developed in this work will one day enable robots to adapt and learn about the changing needs of people in their homes, or staff in a hospital.  The lessons learned about social learning with robots will be relevant both to computational devices and to human-computer interaction in general.  The PI will exploit the fact that social robot projects like this one generate particular interest in the community to conduct outreach programs in local area high schools, to raise awareness about the work of women in science, and to stimulate the American public's interest in science."
141,953219,CAREER: Using Machine Learning to Understand and Enhance Human Learning Capacity,IIS,Robust Intelligence,06/01/2010,05/05/2014,Xiaojin Zhu,WI,University of Wisconsin-Madison,Continuing grant,Weng-keen Wong,05/31/2017,"$465,586.00",,jerryzhu@cs.wisc.edu,21 North Park Street,MADISON,WI,537151218,6082623822,CSE,7495,"1045, 1187",$0.00,"Understanding and enhancing human learning are important challenges in the 21st century.  Existing human category learning models cannot quantify important capacities such as people's (in)ability to generalize from training to test, to learn from imperfect data, or to learn by actively asking questions.  <br/><br/>This research project studies human learning using machine learning.  It first develops machine learning theory and algorithms to quantify these human learning capacities: It establishes learning-theoretic error bounds on human generalization performance; It models human learning from an imperfect teacher with non-parametric Bayesian methods; It models human's ability to ask informative questions with active learning theory.  The project then studies computational approaches to enhance human learning: It develops ""machine teaching"" algorithms when the computer knows the target concept, and selects the optimal training examples to teach a human learner; It develops ""human machine co-learning"" algorithms when the computer does not know the target concept, but instead learns alongside the human and suggests better learning strategies to her.  Each topic is verified by human experiments.<br/><br/>The project advances machine learning with new learning theory and algorithms on tasks where humans excel.  It advances cognitive psychology with new models of human learning.  It has broader impacts in understanding human intelligence, and in benefiting students with new educational tools.  This research project is integrated with an educational plan that incorporates undergraduate and graduate teaching and mentoring, developing a new course and a book on machine and human learning, organizing seminars, tutorials and workshops, and sharing all results on a website."
142,964037,AF:  Medium:  Collaborative Research:  Solutions to Planar Optimization Problems,CCF,"Algorithmic Foundations, ALGORITHMS",08/01/2010,03/06/2015,Philip Klein,RI,Brown University,Standard Grant,jack snoeyink,06/30/2015,"$636,988.00",Claire Kenyon-Mathieu,klein@brown.edu,BOX 1929,Providence,RI,29129002,4018632777,CSE,"7796, 7926","7924, 7926, 9216, 9218, 9251, HPCC",$0.00,"The aim of this research is to develop new algorithms and algorithmic<br/>techniques for solving fundamental optimization problems on planar<br/>networks.  Many optimization problems in networks are considered<br/>computationally difficult; some are even difficult to solve<br/>approximately.  However, problems often become easier when the input<br/>network is restricted to be planar, i.e. when it can be drawn on the<br/>plane so that no edges cross each other.  Such planar instances of<br/>optimization problems arise in several application areas, including<br/>logistics and route planning in road maps, image processing and<br/>computer vision, and VLSI chip design.  <br/><br/>The investigators plan to develop algorithms that achieve faster<br/>running times or better approximations by exploiting the planarity of<br/>the input networks.  In addition, in order to address the use of<br/>optimization in the discovery of some ground truth, the investigators<br/>will develop algorithms not just for the traditional worst-case input<br/>model but also for models in which there is an unusually good planted<br/>solution; for a model of this kind, the investigators expect to find<br/>algorithms that produce even more accurate answers.<br/><br/>The research will likely uncover new computational techniques whose<br/>applicability goes beyond planar networks.  In the recent past, once a<br/>technique has been developed and understood in the context of planar<br/>networks, it has been generalized to apply to broader families of<br/>networks.<br/><br/>In addition, new algorithms and techniques resulting from this<br/>research might enable people to quickly compute better solutions to<br/>problems arising in diverse application areas.  For example, research<br/>in this area has already had an impact in the computer vision<br/>community.  Further research has the potential to be useful, for<br/>example, in the design of networks, the planning of routes in road<br/>maps, the processing of images."
143,1004447,Montclair REU Site in Imaging and Computer Vision  (iMagine),IIS,"RSCH EXPER FOR UNDERGRAD SITES, , , ",04/01/2010,03/26/2012,Stefan Robila,NJ,Montclair State University,Continuing grant,Maria Zemankova,03/31/2014,"$287,760.00",Jing Peng,robilas@mail.montclair.edu,1 Normal Avenue,Montclair,NJ,70431624,9736556923,CSE,"1139, J103, J243, k629","7736, 9218, 9250, HPCC",$0.00,"The aims of this renewal REU project are to improve the understanding and processing of imaging data and to develop of computer- based solutions to current imaging and vision problems.  Student research projects will include: spectral data processing, perceptual, ubiquitous, and mobile user interfaces, content based media retrieval, multi- approach integration of image processing, and inverse problems using scattering theories. While designed for undergraduate research, the projects are relevant to current problems in the imaging field and thus seek to contribute to its advancement in a real way.<br/><br/>This site is supported by the Department of Defense in partnership with the NSF REU program."
144,959979,MRI-R2: Development of an Immersive Giga-pixel Display,CNS,Major Research Instrumentation,05/01/2010,02/09/2012,Arie Kaufman,NY,SUNY at Stony Brook,Standard Grant,Rita Rodriguez,04/30/2014,"$1,400,000.00","Amitabh Varshney, Hong Qin, Dimitrios Samaras, Klaus Mueller",ari@cs.stonybrook.edu,WEST 5510 FRK MEL LIB,Stony Brook,NY,117940001,6316329949,CSE,1189,6890,"$1,400,000.00","""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5)."" <br/>Proposal #: 09-59979<br/>PI(s):  Kaufman, Arie E., Mueller, Klaus, Qin, Hong, Samaras, Dimitrios, Varshney, Amitabh<br/>Institution: SUNY at Stony Brook<br/>Title:    MRI-R2: Development of an Immersive Giga-pixel Display<br/>Project Proposed: <br/>This project, developing a next generation of immersive display instrument (called 'Reality Deck'), aims to explore and visualize data from many fields. To satisfy the need driven by the explosive growth of data size and environments already at the institution, the work builds on the existing experience with immersive environments (e.g., the 'Immersive Cabin' a current generation device using projectors). This unique project generates a one-of-a-kind exploration theater, using 308 high-resolution 30 LCD display monitors, by contributing an environment whose visual resolution is at the limit of the human eye's acuity. Within this environment investigators can interact with the data/information displayed.  <br/>The instrument services many groups, including visual computing, virtual and augmented reality, human computer interfaces, computer vision and image processing, data mining, physics, scientific computing, chemistry, marine and atmospheric sciences, climate and weather modeling, material science, etc.<br/>Collaborating scientist's applications will be ported to the RealityDeck, including applications in nanoelectronics, climate and weather modeling, biotoxin simulations, microtomography, astronomy, atmospheric science, G-pixel camera for intelligence gathering, architectural design and disaster simulations, smart energy grid, and many others.<br/>A unique assembly of displays, GPU cluster, sensors, communication/networking, computer vision and human computer interaction technologies, RealityDeck is an engineering feat with user studies to deliver a holistic system with a significant societal and research value. It is a one-of-a-kind pioneering G-pixel display approaching the limits of visual cognition that provides functionalities to a diverse user base. Its resolution at the eye's visual acuity and its field of view will always exceed that of a human user (wherever a human chooses to look), satisfying visual queries into the data in a very intuitive way. This visual interaction is tightly coupled with physical navigation.<br/>This surround virtual environment consists of inertial sensors and six cameras mounted around the top corners of the RealityDeck room to allow interaction with the displays. The display system is driven by a cluster of about 80 high-end computer nodes, each equipped with two high end GPUs. A small-scale video-wall has already been constructed as an experimental platform for the RealityDeck consisting of 9 high-resolution 30 LCD panels in a 3×3 configuration. <br/>Broader Impacts: <br/>The instrument will be used for research, education, and outreach across many departments at the institution, the University of Maryland, and Brookhaven National Laboratory (BNL). It fosters collaborations across disciplines attracting faculty, researchers, and students. RealityDeck significantly enriches the quality of visual thinking and data exploration. It substantially enhances the infrastructure of research and education and has the potential to alter the way computer graphicists, engineers, and scientists work and/or conduct scientific discoveries."
145,963921,AF:  Medium:  Collaborative Research:  Solutions to Planar Optimization Problems,CCF,ALGORITHMS,08/01/2010,07/26/2010,Glencora Borradaile,OR,Oregon State University,Standard Grant,Balasubramanian Kalyanasundaram,07/31/2014,"$175,008.00",,glencora@eecs.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7926,"9218, HPCC",$0.00,"The aim of this research is to develop new algorithms and algorithmic<br/>techniques for solving fundamental optimization problems on planar<br/>networks. Many optimization problems in networks are considered<br/>computationally difficult; some are even difficult to solve<br/>approximately. However, problems often become easier when the input<br/>network is restricted to be planar, i.e. when it can be drawn on the<br/>plane so that no edges cross each other. Such planar instances of<br/>optimization problems arise in several application areas, including<br/>logistics and route planning in road maps, image processing and<br/>computer vision, and VLSI chip design.<br/><br/>The investigators plan to develop algorithms that achieve faster<br/>running times or better approximations by exploiting the planarity of<br/>the input networks. In addition, in order to address the use of<br/>optimization in the discovery of some ground truth, the investigators<br/>will develop algorithms not just for the traditional worst-case input<br/>model but also for models in which there is an unusually good planted<br/>solution; for a model of this kind, the investigators expect to find<br/>algorithms that produce even more accurate answers.<br/><br/>The research will likely uncover new computational techniques whose<br/>applicability goes beyond planar networks. In the recent past, once a<br/>technique has been developed and understood in the context of planar<br/>networks, it has been generalized to apply to broader families of<br/>networks.<br/><br/>In addition, new algorithms and techniques resulting from this<br/>research might enable people to quickly compute better solutions to<br/>problems arising in diverse application areas. For example, research<br/>in this area has already had an impact in the computer vision<br/>community. Further research has the potential to be useful, for<br/>example, in the design of networks, the planning of routes in road<br/>maps, the processing of images."
146,953373,CAREER: A New Statistical Framework for Natural Images with Applications in Vision,IIS,ROBUST INTELLIGENCE,06/01/2010,03/12/2014,Siwei Lyu,NY,SUNY at Albany,Continuing grant,Jie Yang,09/30/2016,"$499,596.00",,lsw@cs.albany.edu,1400 WASHINGTON AVE MSC 100A,Albany,NY,122220100,5184374974,CSE,7495,1045,$0.00,"This project studies natural image statistics, and their applications in diverse fields such as computational neuroscience, image processing, computer vision, and graphics. The centerpiece of this project is a new image representation based on a simple nonlinear transform that is statistically justified and biologically inspired. This representation provides a new language to describe image signals, and forms the basis to build statistical models to more effectively capture statistical properties of natural image. Built upon this new image representation, this project explores new paradigms to model and interpret visual neural responses and high-level perceptual properties, and provides new tools for image restoration, analysis and synthesis. On the other hand, by applying natural image statistics to the forensic analysis of digital images, this project facilitates forensic practitioners in criminal investigations, and contributes to national security and public safety. Moreover, this project contributes to education by making the learning of Computer Science fun and useful for undergraduate students, promoting the participation of women and undergraduate students in research, and improving the early learning of mathematics and sciences for local high school students."
147,1018771,CSR: Small: Learning-Assisted Parallelization,CNS,"SPECIAL PROJECTS - CISE, Computer Systems Research (CSR",08/01/2010,03/09/2012,Ronald Barnes,OK,University of Oklahoma Norman Campus,Continuing grant,M. Mimi McClure,07/31/2015,"$515,882.00",Amy McGovern,ron@ou.edu,201 Stephenson Parkway,NORMAN,OK,730199705,4053254757,CSE,"1714, 7354","7923, 9150, 9178, 9251",$0.00,"The number of processing cores in everyday computer systems is quickly outpacing programmers' and compilers' ability to create many-threaded applications capable of taking advantage of the cores.  Instead of requiring applications to be rewritten to take advantage of the many-core architectures, this project aims to create automated parallelization approaches that utilize machine learning to improve traditional parallelization methods to create more effective (and often speculative) threads.  These techniques will be applied to the arrangement of the parallel execution of tasks (whether coarse- or fine-grained), yielding a systematic learning approach that will outperform static parallelization attempts.   This approach assists both programmer identified parallelism as well as that exposed by the compiler.  This project is not limited to applications with regular loop-level parallelism, but targets irregular integer applications which have proven difficult to statically parallelize.  <br/><br/>This project will result in the development of a high performance dynamic parallelization system based on critical information gathered from machine learning and related approaches.  By creating intelligent parallelization approaches, we enable the multicore machines of the future to be used to their full advantage by both scientists and the general public.  Although many of today's applications may not require the full computational power of a many-core machine, the effective utilization of such machines will enable new, more-powerful applications than are currently possible."
148,1004902,REU Site: Applied Computing Research in Wireless Sensing of Marine Data,CNS,"RSCH EXPER FOR UNDERGRAD SITES, CPATH",06/01/2010,09/16/2010,Dulal Kar,TX,Texas A&M University Corpus Christi,Continuing grant,Harriet Taylor,05/31/2014,"$269,293.00","Long-zhuang Li, Ahmed Mahdy",dulal.kar@tamucc.edu,"6300 Ocean Drive, Unit 5844",Corpus Christi,TX,784125844,3618253882,CSE,"1139, 7640",9250,$0.00,"This CISE REU Site award provides funding to Texas A&M University-Corpus Christi, a Hispanic Serving Institution on the Texas Gulf Coast, to offer research experience in applied computing to 24 undergraduate students of primarily Hispanic descent.   The students will participate in deriving solutions for technological challenges faced by researchers in the collection, storage, and analysis of data from marine and aquatic environments of the coastal region. The primary objective of the program is to provide participants unique research experiences in a stimulating environment that will involve designing, developing, adapting, and testing wireless sensor networks for data gathering operations from marine and aquatic environments.  Activities include training sessions and social events designed to enhance group cohesiveness and to hone technical writing, communication, and leadership skills. Primary research activities will occur in the areas of design of marine sensor networks, reliability and security of marine sensor networks, and integration of marine sensor data from a variety of domains on the Gulf of Mexico. The participants will write and present research papers on their work in local, regional, and national symposiums. <br/><br/>The intellectual merit comes from student participation in a unique marine-based research program that seeks solutions for survivable, secured, and reliable design of sensor networks for marine environment; energy-efficient sensor data gathering for marine applications; and integration of marine sensor data from a variety of domains on the Gulf of Mexico. The students participate in projects that have the potential to impact the field and to make a contribution to the university's efforts to become a global leader in research on the Gulf of Mexico and its resources. <br/><br/>The broader impacts of the proposed program will extend beyond the project in a number of ways.  These experiences should instill in the students a passion for research in applied computing for environmental applications and should motivate them for further learning and discovery in the computing disciplines. The project has the potential to increase retention rates of science, technology, engineering, and mathematics (STEM) majors. The project should also broaden inter-institutional collaboration, particularly among Hispanic serving institutions nationwide and will advance science and technical knowledge on sustainable marine resource utilization and preservation globally."
149,964481,"AF: Medium:Smoothed Analysis in Multi-Objective Optimization, Machine Learning, and Algorithmic Game Theory",CCF,"Algorithmic Foundations, ALGORITHMS, COMPUT GAME THEORY & ECON",03/01/2010,01/17/2012,Shanghua Teng,CA,University of Southern California,Continuing grant,Balasubramanian Kalyanasundaram,02/28/2015,"$1,099,858.00",,shanghua@usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,"7796, 7926, 7932","9218, HPCC",$0.00,"Technical description of the project:<br/><br/>Smoothed analysis has been introduced to study the behavior of algorithms when their good practical performance cannot be predicted by the traditional frameworks such as the worst-case and average-case analyses. In the original paper that introduced smoothed analysis, Spielman and Teng proved that the simplex method, which was one of the amazingly practical heuristics known to have poor worst-case performance, had good smoothed complexity. Since its introduction, smoothed analysis has been applied to heuristics in areas that include mathematical programming, numerical analysis, and combinatorial optimization.<br/><br/>To follow up on this breakthrough in linear programming, whose primary concern is to optimize a single linear objective function, the goal of this project is to extend smoothed analysis to optimization problems involving multiple objective functions and multiple agents, as often considered in Computational Game and Economics Theory. The plan of the project will also include the design and analysis of machine learning algorithms in the smoothed setting.<br/><br/>The plan for multiobjective optimization is to improve the recent work which show that the Pareto set of any binary linear optimization problem with a constant number of objective functions has a polynomial size in the smoothed model. In game theory, the research will focus on the smoothed complexity of several potential games for resource allocation and scheduling. For both of these problems, a new analytical approach for the performance of an iterative process is needed.  In machine learning, the goal is to extend the results on the smoothed analysis of PAC and agnostic learning from product distributions to other more practical distributions.<br/><br/><br/>The broader significance and importance of the project:<br/><br/>This research will provide insight into why heuristics in multi-objective optimization, local search, and machine learning are successful and allow researchers in Theoretical Computer Science to incorporate these heuristics into the canon of Algorithms. It will also provide algorithmic insights into the differences between game-theoretic problems involving multiple agents and multi-objective optimization problems concerning only a single agent. By developing a theory that better predicts the performance of algorithms in practice, this research has the promise to allow researchers to develop more powerful algorithms. When one designs an algorithm, one does so with some reason in mind as to why it should work. By providing a new analytical notion of what it means for an algorithm to ""work in practice,"" this research can shape the intuition of algorithm designers to include algorithms that might otherwise have been discarded for being ""bad in the worst-case.""<br/><br/>A primary objective of this project is to build bridges between the discipline of Theoretical Computer Science (TCS) and communities within the disciplines of Operations Research, Game Theory, and Mathematical Economics. If successful, the project will help to provide a framework within which researchers in TCS can understand some of the great practical achievements of these disciplines. In turn, by providing analyses that respect the sensibilities of researchers in these disciplines as to what constitutes a ""practical input,"" this project will increase the value of theoretical analyses to researchers in these fields. As this project combines ideas from many disciplines within one coherent research effort, lectures and tutorials presented on the fruits of the project will help cross-fertilize the disciplines within its scope. The development of theoretical explanations for the success of the heuristics examined in this project should simplify education in algorithms and allow discussion of practically important heuristics at earlier stages of a computer scientist's education. These explanations also simplify the task of designing easily digestible lectures on these topics, and such lecture notes inspired by this research will be made available by the PI and collaborators on the internet."
150,1029035,"Collaborative Research:  Computational Behavioral Science:  Modeling, Analysis, and Visualization of Social and Communicative Behavior",IIS,INFORMATION TECHNOLOGY RESEARC,09/01/2010,09/11/2012,David Forsyth,IL,University of Illinois at Urbana-Champaign,Continuing grant,Ephraim P. Glinert,08/31/2017,"$1,500,000.00",Karrie Karahalios,daf@cs.uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,1640,"1640, 7723, 7969, 9218, HPCC",$0.00,"Computational Behavioral Science: Modeling, Analysis, and Visualization of Social and <br/>Communicative Behavior<br/>Lead PI/Institution: James M. Rehg, Georgia Institute of Technology<br/>This Expedition will develop novel computational methods for measuring and analyzing the behavior of children and adults during face-to-face social interactions. Social behavior plays a key role in the acquisition of social and communicative skills during childhood. Children with developmental disorders, such as autism, face great challenges in acquiring these skills, resulting in substantial lifetime risks. Current best practices for evaluating behavior and assessing risk are based on direct observation by highly-trained specialists, and cannot be easily scaled to the large number of individuals who need evaluation and treatment. For example, autism affects 1 in 110 children in the U.S., with a lifetime cost of care of $3.2 million per person. By developing methods to automatically collect fine-grained behavioral data, this project will enable large-scale objective screening and more effective delivery and assessment of therapy. Going beyond the treatment of disorders, this technology will make it possible to automatically measure behavior over long periods of time for large numbers of individuals in a wide range of settings. Many disciplines, such as education, advertising, and customer relations, could benefit from a quantitative, data-drive approach to behavioral analysis. <br/>Human behavior is inherently multi-modal, and individuals use eye gaze, hand gestures, facial expressions, body posture, and tone of voice along with speech to convey engagement and regulate social interactions.  This project will develop multiple sensing technologies, including vision, speech, and wearable sensors, to obtain a comprehensive, integrated portrait of expressed behavior. Cameras and microphones provide an inexpensive, noninvasive means for measuring eye, face, and body movements along with speech and nonspeech utterances. Wearable sensors can measure physiological variables such as heart-rate and skin conductivity, which contain important cues about levels of internal stress and arousal that are linked to expressed behavior. This project is developing unique capabilities for synchronizing multiple sensor streams, correlating these streams to measure behavioral variables such as affect and attention, and modeling extended interactions between two or more individuals. In addition, novel behavior visualization methods are being developed to enable real-time decision support for interventions and the effective use of repositories of behavioral data. Methods are also under development for reflecting the capture and analysis process to users of the technology.<br/>The long-term goal of this project is the creation of a new scientific discipline of computational behavioral science, which draws equally from computer science and psychology in order to transform the study of human behavior. A comprehensive education plan supports this goal through the creation of an interdisciplinary summer school for young researchers and the development of new courses in computational behavior. Outreach activities include significant and on-going collaborations with major autism research centers in Atlanta, Boston, Pittsburgh, Urbana-Champaign, and Los Angeles."
151,953330,CAREER: Machine Learning and Event Detection for the Public Good,IIS,"Info Integration & Informatics, SciSIP-Sci of Sci Innov Policy",07/01/2010,03/31/2010,Daniel Neill,PA,Carnegie-Mellon University,Standard Grant,Maria Zemankova,06/30/2016,"$529,962.00",,daniel.neill@nyu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"7364, 7626","0000, 1045, 1187, 7364, 7626, 9215, HPCC, OTHR",$0.00,"The goal of this research is to create and explore novel methods for detection of emerging events in massive, complex real-world datasets.  The approach consists of new algorithms to efficiently and exactly find the most anomalous subsets of a large, high-dimensional dataset, as well as methodological advances to incorporate incremental model learning from user feedback into event detection, incorporate society-scale data from emerging, transformative technologies such as cellular phones and user-generated web content, and augment event detection by creating methods and tools for event characterization, explanation, visualization, investigation and response.  <br/><br/>The experimental research is integrated with a multi-pronged educational initiative to incorporate machine learning into the public policy curriculum through development of courses and seminars, workshops in machine learning and policy research and education, and establishment of a new Joint Ph.D. Program in Machine Learning and Policy.  The results of this project will be incorporated into deployed event surveillance systems and applied to the public health, law enforcement, and health care domains, enabling more timely and accurate detection of emerging outbreaks of disease, prediction of emerging hot-spots of violent crime, and identification of anomalous patterns of patient care.  Project results, including publications, software, and datasets, will be disseminated via project web site (http://www.cs.cmu.edu/~neill/CAREER)."
152,1017199,RI: Small: 3D Nonrigid Object Reconstruction from Large-Scale Unorganized 2D Images,IIS,ROBUST INTELLIGENCE,09/01/2010,02/18/2011,Song Wang,SC,University South Carolina Research Foundation,Standard Grant,Jie Yang,08/31/2015,"$216,000.00",,songwang@cec.sc.edu,1600 Hampton Street,COLUMBIA,SC,292080001,8037777093,CSE,7495,"7923, 9251",$0.00,"Reconstructing the 3D shape of an object from multiple 2D images is a fundamental problem in computer vision. Prior work on this problem usually requires the object of interest to be rigid or the available 2D images to be well organized, such as consecutive frames in a video. This project investigates the challenging problem of reconstructing a nonrigid 3D object from a large number of unorganized 2D images, which may be taken at different times, with different backgrounds, from different perspectives, under different lighting conditions, and/or using different cameras.<br/><br/>The research team develops new algorithms of combining object localization, feature matching, and partial shape matching across the images to segment the 2D object of interest from the input images. The segmented 2D objects are organized into clusters to recover the underlying 3D nonrigid deformation. Pieces of the 3D object are reconstructed from these clusters and finally assembled to obtain the complete 3D object by removing the in-between nonrigid deformations. An image database with 2D images of selected nonrigid objects is constructed for performance evaluation.<br/><br/>This research benefits many applications in computer vision, computer graphics, computer gaming, zoology, microbiology, marine science, and medical research, which all involve the modeling of 3D norigid objects. Progress made on object localization, feature matching and partial shape matching has immediate applications in object detection, object recognition, image search, surveillance, tracking, and segmentation. This research also provides an excellent setting for the training of both undergraduate and graduate students."
153,1016395,RI: Small:Differential Ray Geometry for Surface Reconstruction and Modeling,IIS,GRAPHICS & VISUALIZATION,09/01/2010,08/26/2010,Jingyi Yu,DE,University of Delaware,Standard Grant,Jie Yang,08/31/2014,"$370,940.00",,yu@cis.udel.edu,210 Hullihen Hall,Newark,DE,197160099,3028312136,CSE,7453,"7923, 9150",$0.00,"This project focuses on developing the theoretical foundation of differential ray geometry. The PI first derives a comprehensive ray geometry framework including the ray-distortion, ray-caustics, and ray-curvature theories as well as ray differential operators. This new framework is widely applicable to real-world problems. On the computer vision front, the PI explores robust and efficient schemes to infer ray structures from distortions or from caustics patterns and then recover surface geometry from ray differential attributes. This leads to a new class of specular (reflective and refractive) surface reconstruction algorithms. On the computer graphics front, the PI employs a novel normal-ray representation that converts a smooth 3D surface into a 2D ray manifold so that surface differential attributes can be directly derived from normal-ray geometry. The PI further develops new subdivision, re-meshing, and mesh simplification schemes for generating surfaces consistent with the underlying normal ray structures. <br/><br/>This research benefits many computer vision and graphics applications by providing a differential ray geometry model for cameras, light sources, and surfaces. It also benefits shape designs in aircraft, automobile, and many other industries, where higher-order shape consistencies are required. This project contributes to education through the development of new differential geometry courses and seminars and by involving women and under-represented students in mathematical and computer science research. The PI further seeks to build strong connections with the fields of mathematics and physics, optical engineering, and mechanical engineering through the project."
155,1027965,CDI-Type II: Collaborative Research: Joint Image-Text Parsing and Reasoning for Analyzing Social and Political News Events,CNS,CDI TYPE II,10/01/2010,09/09/2010,ChengXiang Zhai,IL,University of Illinois at Urbana-Champaign,Standard Grant,Fahmida N. Chowdhury,09/30/2015,"$500,001.00",,czhai@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,7751,7721,$0.00,"Summary: Rapidly changing technologies of multi-modal communication, from the global reach of international satellite TV, the proliferation of Internet news outlets, to YouTube, are transforming the news industry. In parallel, ?citizen journalism? is on the rise, enabled by smart phones, social networks, and blogs. The Internet is becoming a vast information ecosystem driven by mediated events ? elections, social movements, natural disasters, disease epidemics ? with rich heterogeneous data: text, image, and video. Meanwhile, the tools and methodologies for users and researchers are not keeping pace: it remains prohibitively labor-intensive to systematically access and study the vast amount of emerging news data. <br/><br/>Leveraging UCLA's ongoing digital collection of 85,000 hours of news videos, including 8.1 billion image frames and 530 million words of closed captioning, the research team is developing a new computational paradigm for analyzing massive datasets of social and political news events: (i) Studying joint image-text parsing to categorize news by topics and events, and analyzing selection and presentation biases across networks and media spheres in a statistical and quantitative manner never before possible; (ii) Studying by joint image-text mining to reason the persuasion intents, and modeling the techniques of verbal and visual persuasions; (iii) Discovering spatio-temporal patterns in the interactions of multiple mediated events, and analyzing agenda setting patterns; and (iv) Developing an interactive multi-perspective news interface, vrNewsScape, for visualizing and interacting with our computational and statistical results. <br/><br/>Intellectual merit: This interdisciplinary project makes innovative contributions to three disciplines. Transforming social science research. The project develops a data-driven paradigm for transforming communication research in the social sciences. By enabling quantitative studies of massive visual datasets, the research team identifies and characterizes large-scale patterns of news mediation and persuasion currently inaccessible to researchers, due to the prohibitive cost of manual analysis. The research team goes beyond traditional object detection, segmentation, and recognition by studying framing and persuasion techniques in images, an untouched topic in computer vision. The team studies semantic associations and meanings for object and scene categories in their social context. Also, the team is studying image parsing to fill the semantic gap ? a long standing technical barrier in image retrieval, and will generate narrative text descriptions from the parse trees so that they can be fused with the input text and closed captioning for topic mining. <br/><br/>The research goes beyond conventional topic mining from text to perform integrative text-image mining, bias detection, and pattern discovery in the spatio-temporal evolution of mediated news events. The research detects and summarizes controversy and mine user-generated content for analyzing communicative intent and persuasive effects. <br/><br/>Broader impacts: vrNewsScape is being made publicly available to researchers and graduate students. Because the news media report on events in multiple different expert domains ? including congressional and presidential politics, international relations, war and public uprisings, natural disasters and humanitarian aid missions, disease epidemics and health initiatives, criminal activity and court cases, celebrities and cultural events ? the analytical tools in development are not limited to a particular research domain in social, political and computer sciences, but permit for the first time a systematic and quantitative examination of the massive datasets required to understand today?s mediated society. <br/><br/>In education, the project extends UCLA?s Digital Civic Learning initiative (dcl.sscnet.ucla.edu), a program involving college and high-school students in the analysis of news, thus delivering education benefits to potentially a huge number of students nationwide in Communication Studies (in 2004, 433,000 college students were enrolled in Communication and Journalism and 209,000 in Political Science[153]), exposing them to a new generation of high-level tools for handling multimodal data and inspiring them to pursue computational thinking, in line with the NSF?s objectives."
156,1016018,CIF: Small: Visual Recognition and Restoration In Concert,CCF,"COMM & INFORMATION FOUNDATIONS, SIGNAL PROCESSING",08/01/2010,05/14/2012,Peyman Milanfar,CA,University of California-Santa Cruz,Continuing grant,John Cozzens,07/31/2013,"$443,957.00",,milanfar@ee.ucsc.edu,1156 High Street,Santa Cruz,CA,950641077,8314595278,CSE,"7797, 7936","9218, ",$0.00,"Project Abstract for NSF Proposal 1016018<br/> Visual Recognition and Restoration In Concert<br/> Peyman Milanfar<br/> Electrical Engineering Department<br/> University of California at Santa Cruz<br/><br/>In this research effort a central challenge in computer vision is addressed: Namely, to recognize and enhance objects in complex visual scenes given imperfect images, and more generally, video data. This effort strengthens the theoretical and practical foundations for generic visual object recognition systems that can deal with significant variations in visual appearance, a large number of categories, and stochastically and systematically degraded data. Data imperfections can include random noise, blur, and environmental degradations. The approach has transformative potential for a broad range of practical applications such as scalable image search and retrieval, automatic annotation, surveillance and security, video forensics, and medical image analysis for computer-aided<br/>diagnosis.<br/><br/>The research advances the state-of-the-art in two important ways: (a) a unified and robust framework is derived for both (2-D) object and (3-D) action recognition, even when the data is subject to significant distortions, and (b) recognition and restoration from degraded data are treated in a common, statistically optimal setting. Traditionally, recognition and restoration have been addressed with limited awareness of each other?s techniques and of potential commonalities in approach. By improving, generalizing, and refining previously separate approaches to recognition with degraded data in an adaptive, non-parametric setting, for both 2-D and 3-D, this project contributes to the technical foundations and toolkits that can connect computer vision and image processing<br/>intelligently."
157,1028163,"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach",IIS,CDI TYPE II,09/15/2010,09/16/2010,John Reilly,MA,Massachusetts Institute of Technology,Standard Grant,Kenneth C. Whang,08/31/2015,"$150,000.00",,jreilly@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7751,"7721, 7722, 7751",$0.00,"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques.  The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure.  These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking.  The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making.   <br/><br/><br/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change.  Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S.   Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling).  This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment."
158,1028291,"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach",IIS,CDI TYPE II,09/15/2010,09/16/2010,Qianlai Zhuang,IN,Purdue University,Standard Grant,Kenneth C. Whang,08/31/2016,"$1,591,428.00","Hao Zhang, Jian Zhang, Melba Crawford, Dongbin Xiu",qzhuang@purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,7751,"7721, 7722, 7751",$0.00,"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques.  The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure.  These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking.  The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making.   <br/><br/><br/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change.  Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S.   Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling).  This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment."
160,1005117,REU Site: Computational Science Training at Marshall University for Undergraduates in the Mathematical and Physical Sciences,OAC,RSCH EXPER FOR UNDERGRAD SITES,04/01/2010,05/24/2011,Howard Richards,WV,Marshall University Research Corporation,Standard Grant,Almadena Chtchelkanova,03/31/2013,"$326,484.00",Maria Babiuc Hamilton,howard.richards@marshall.edu,One John Marshall Dr.,Huntington,WV,257550002,3046964837,CSE,1139,"9150, 9250",$0.00,"Over the summers of 2010-2012, the Departments of Mathematics, Physics, and Chemistry at Marshall University will jointly host twelve students for ten weeks of instruction and research in computational science. Each student will extend a carefully selected and delimited aspect of his or her mentor's research. Research fields include: 1) the characterization of beta-compounded statistical distributions; 2) computer vision with gray-scale images; 3) visualizations of general relativity; 4) potential energy surfaces for van der Waals interactions; 5) ion-molecule complexation in the zero pressure limit; and 6) the dynamics of metastable decay for the Ising model on tree-like networks. <br/><br/>In addition to performing research in a specific area, students will be instructed in practices and issues that are common to all areas of computational science. They will also receive the equivalent of a one semester hour course in ethics for scientists and engineers. Experts will be brought in to discuss computational science from the more applied perspective of industry and government service, as well as potential career trajectories. <br/><br/>This program will focus on students in the EPSCoR states of West Virginia and Kentucky, as well as students from historically black colleges and universities. Students will present the results of their research in a symposium to conclude the summer program and at a professional conference as appropriate. Students will emerge from the program with skills and confidence that can carry them into postgraduate studies, as well as an awareness of possible careers using computational science."
162,1028381,CDI-Type II: Collaborative Research: Joint Image-Text Parsing and Reasoning for Analyzing Social and Political News Events,CNS,CDI TYPE II,10/01/2010,09/09/2010,Song-Chun Zhu,CA,University of California-Los Angeles,Standard Grant,Fahmida N. Chowdhury,09/30/2016,"$1,299,998.00","Tim Groeling, Francis Steen",sczhu@stat.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7751,7721,$0.00,"Summary: Rapidly changing technologies of multi-modal communication, from the global reach of international satellite TV, the proliferation of Internet news outlets, to YouTube, are transforming the news industry. In parallel, ?citizen journalism? is on the rise, enabled by smart phones, social networks, and blogs. The Internet is becoming a vast information ecosystem driven by mediated events ? elections, social movements, natural disasters, disease epidemics ? with rich heterogeneous data: text, image, and video. Meanwhile, the tools and methodologies for users and researchers are not keeping pace: it remains prohibitively labor-intensive to systematically access and study the vast amount of emerging news data.<br/><br/>Leveraging UCLA's ongoing digital collection of 85,000 hours of news videos, including 8.1 billion image frames and 530 million words of closed captioning, the research team is developing a new computational paradigm for analyzing massive datasets of social and political news events: (i) Studying joint image-text parsing to categorize news by topics and events, and analyzing selection and presentation biases across networks and media spheres in a statistical and quantitative manner never before possible; (ii) Studying by joint image-text mining to reason the persuasion intents, and modeling the techniques of verbal and visual persuasions; (iii) Discovering spatio-temporal patterns in the interactions of multiple mediated events, and analyzing agenda setting patterns; and (iv) Developing an interactive multi-perspective news interface, vrNewsScape, for visualizing and interacting with our computational and statistical results.<br/><br/>Intellectual merit: This interdisciplinary project makes innovative contributions to three disciplines. Transforming social science research. The project develops a data-driven paradigm for transforming communication research in the social sciences. By enabling quantitative studies of massive visual datasets, the research team identifies and characterizes large-scale patterns of news mediation and persuasion currently inaccessible to researchers, due to the prohibitive cost of manual analysis. The research team goes beyond traditional object detection, segmentation, and recognition by studying framing and persuasion techniques in images, an untouched topic in computer vision. The team studies semantic associations and meanings for object and scene categories in their social context. Also, the team is studying image parsing to fill the semantic gap ? a long standing technical barrier in image retrieval, and will generate narrative text descriptions from the parse trees so that they can be fused with the input text and closed captioning for topic mining.<br/><br/>The research goes beyond conventional topic mining from text to perform integrative text-image mining, bias detection, and pattern discovery in the spatio-temporal evolution of mediated news events. The research detects and summarizes controversy and mine user-generated content for analyzing communicative intent and persuasive effects.<br/><br/>Broader impacts: vrNewsScape is being made publicly available to researchers and graduate students. Because the news media report on events in multiple different expert domains ? including congressional and presidential politics, international relations, war and public uprisings, natural disasters and humanitarian aid missions, disease epidemics and health initiatives, criminal activity and court cases, celebrities and cultural events ? the analytical tools in development are not limited to a particular research domain in social, political and computer sciences, but permit for the first time a systematic and quantitative examination of the massive datasets required to understand today?s mediated society.<br/><br/>In education, the project extends UCLA?s Digital Civic Learning initiative (dcl.sscnet.ucla.edu), a program involving college and high-school students in the analysis of news, thus delivering education benefits to potentially a huge number of students nationwide in Communication Studies (in 2004, 433,000 college students were enrolled in Communication and Journalism and 209,000 in Political Science[153]), exposing them to a new generation of high-level tools for handling multimodal data and inspiring them to pursue computational thinking, in line with the NSF?s objectives."
163,1016862,RI:  Small:  Hierarchical Visual Scene Understanding,IIS,ROBUST INTELLIGENCE,09/01/2010,08/27/2010,Aude Oliva,MA,Massachusetts Institute of Technology,Standard Grant,Jie Yang,08/31/2014,"$449,184.00",,oliva@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7495,"7923, 9102",$0.00,"Intelligent systems, both artificial and biological, must find effective ways to organize a complex visual world. The cross-disciplinary field of scene understanding is in need of a comprehensive framework in which to integrate cognitive, computational and neural approaches to the organization of knowledge. <br/><br/>This research program aims to create a framework for organizing knowledge of visual environments that human and artificial systems encounter when navigating in the world or browsing visual databases. The aim is to determine which taxonomies are best suited for solving different visual tasks, and use computer vision algorithms to organize visual environments as humans do. For example, semantic relationships between scenes are well captured by a hierarchical tree (e.g. a basilica is a type of church, which is a type of building) but functional similarities between different environments may be best represented as clusters  (e.g. restaurants, kitchens and picnic areas clustered as places to eat; offices and internet cafés as places to work). <br/><br/>Because hierarchies and taxonomies provide a way of formalizing many types of contextual information (spatial, temporal, and semantic), they can be used to enhance the performance of computer vision systems at object and scene recognition, and aid in the development of smarter image search algorithms. <br/><br/>Besides serving as a unified benchmark for comparing different models and theories, this enterprise offers new teaching and applied tools for research and courses, which will be made available through websites and symposia."
164,1027955,"CDI-Type II: Collaborative Research: A Paradigm Shift in Ecosystem and Environmental Modeling: An Integrated Stochastic, Deterministic, and Machine Learning Approach",IIS,CDI TYPE II,09/15/2010,09/16/2010,Jerry Melillo,MA,Marine Biological Laboratory,Standard Grant,Kenneth Whang,08/31/2015,"$199,996.00",David Kicklighter,jmelillo@mbl.edu,7 M B L ST,WOODS HOLE,MA,25431015,5082897243,CSE,7751,"7721, 7722, 7751",$0.00,"This project will advance systems modeling approaches by developing a suite of stochastic modeling approaches, coupled with geostatistical and machine learning techniques.  The new system modeling approach will utilize both in situ and satellite remotely sensed data to improve system model parameters and model structure.  These novel developments, together with observed data, will advance ecosystem and environmental sciences through computational thinking.  The proposed approach will be used to develop a cyber-enabled stochastic carbon-weather system to provide more adequate quantification of regional carbon exchanges, which is critical to better understanding carbon-climate-atmosphere feedbacks and facilitating climate-policy making.   <br/><br/><br/>The proposed approach will transform the current system modeling approach by (1) developing a stochastic version of the deterministic differential equation models of ecosystems and environmental systems; (2) developing geospatial statistical techniques to fully exploit multifaceted observational data to improve model parameterization; (3) developing advanced statistical and machine learning techniques to further utilize observational data to improve model structure; and (4) applying the improved model to examine the societal and biogeochemical impacts of land use change.  Advantages of the proposed cyber-enabled terrestrial ecosystem model will include: (1) Efficiently quantifying regional net carbon exchanges and associated uncertainty and (2) Improving system model parameters and structure using advanced statistical and machine learning techniques and spatiotemporal data acquired over the U.S.   Project deliverables include: (1) An innovative, cyber-enabled carbon-weather system that can quantify net carbon exchanges and associated probabilistic information at high spatial and temporal resolution for the continental U.S. and (2) a suite of transformative advanced mathematical, statistical and system modeling techniques that could be applied to other complex modeling fields (e.g., hydrological modeling).  This project will significantly advance ecosystem sciences with computational thinking and will provide a unique opportunity to train a new generation of scientists in a highly interdisciplinary research environment."
166,1018433,IIS: RI:  Small: Nonlinear Dynamical System Theory for Machine Learning,IIS,ROBUST INTELLIGENCE,09/01/2010,08/18/2010,Max Welling,CA,University of California-Irvine,Standard Grant,Todd Leen,08/31/2014,"$450,000.00",Anton Gorodetski,welling@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,7923,$0.00,"Learning complex statistical models from data is intractable for many models of interest. The PIs are studying a new approach to learning from data that formulates learning as a weakly chaotic nonlinear dynamical system. They show that this dynamical system, which they call ?herding?, combines learning and inference into one tractable forward mapping. They study the abstract mathematical properties of this nonlinear mapping, such as the properties of its attractor set and the topological and metric entropy of the mapping. They then relate these to properties of learning systems. <br/><br/>The PIs apply herding systems to a wide range of applications in machine learning. In supervised learning they show that herding suggests a natural extension to the ?voted perceptron algorithm? by including hidden variables. In unsupervised learning, herding is used to train Markov random field models from data. Herding is also extended to Hilbert spaces where it naturally leads to a deterministic sampling algorithm. Due to negative autocorrelations, this ?kernel herding? generates samples that have superior convergence properties than random sampling. They also apply herding to active learning problems. <br/><br/>Herding has the potential to radically transform the way we view learning systems. It connects learning to the vast field of nonlinear dynamical systems and chaos theory. As such the impact on machine learning is significant. Scientific results will be disseminated through journal publications and conference proceedings. The PIs also introduce a new course on learning, chaos and fractals to expose students to the intriguing connections between these fields."
168,963835,CIF: Medium:  Collaborative Research:  Advances in the Theory and Practice of Low-Rank Matrix Recovery and Modeling,CCF,"Comm & Information Foundations, SIGNAL PROCESSING",05/01/2010,08/13/2013,Emmanuel Candes,CA,Stanford University,Continuing Grant,John Cozzens,04/30/2016,"$490,324.00",,candes@stanford.edu,450 Jane Stanford Way,Stanford,CA,943052004,6507232300,CSE,"7797, 7936","9218, HPCC",$0.00,"This project concerns one of the fundamental challenges facing<br/>contemporary science and engineering today, namely, the efficient<br/>processing and analysis of massive amounts of high-dimensional data,<br/>such as images, videos, web pages, and bioinformatics data. In short,<br/>data now routinely lie in thousands or even billions of dimensions. On<br/>the one hand, massive data collection is motivated by 1) scientific<br/>discovery and 2) the need for better engineering systems. On the other<br/>hand, the difficult task now is to conduct meaningful inference in<br/>such high dimensions, and draw correct conclusions from limited<br/>amounts of sample data and with limited computational<br/>resources. Fortunately, scientific or engineering data often have very<br/>low intrinsic complexity and dimensionality.  This project addresses<br/>the opportunities offered by this common situation, establishes<br/>conditions under which reliable inference is actually possible, and<br/>develops computational tools for extracting key information from huge<br/>data sets.<br/><br/>This interdisciplinary project is expected to have three outcomes: 1)<br/>the development of innovative mathematics needed to study the recovery<br/>of data matrices from partial and corrupted information 2) the<br/>development of effective algorithms for recovering low-rank matrices<br/>and performing accurate dimensionality reduction with corrupted data<br/>and 3) the development of novel applications in which these techniques<br/>are expected to considerably advance the state-of-the-art.  With these<br/>new tools, scientists and engineers will be able to efficiently<br/>extract correct information from data, which was previously<br/>inaccessible or intractable by conventional techniques. This will<br/>enable the development of far better computer vision systems for face<br/>recognition, better compression schemes of video sequences, a better<br/>understanding of gene expression data, or better search engines for<br/>web documents and images."
170,964215,CIF: Medium: Collaborative Research:  Advances in the Theory and Practice of Low-Rank Matrix Recovery and Modeling,CCF,"COMM & INFORMATION FOUNDATIONS, SIGNAL PROCESSING",05/01/2010,06/05/2013,Minh Do,IL,University of Illinois at Urbana-Champaign,Continuing grant,John Cozzens,12/31/2014,"$368,875.00",,minhdo@illinois.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,"7797, 7936","9218, HPCC",$0.00,"This project concerns one of the fundamental challenges facing<br/>contemporary science and engineering today, namely, the efficient<br/>processing and analysis of massive amounts of high-dimensional data,<br/>such as images, videos, web pages, and bioinformatics data. In short,<br/>data now routinely lie in thousands or even billions of dimensions. On<br/>the one hand, massive data collection is motivated by 1) scientific<br/>discovery and 2) the need for better engineering systems. On the other<br/>hand, the difficult task now is to conduct meaningful inference in<br/>such high dimensions, and draw correct conclusions from limited<br/>amounts of sample data and with limited computational<br/>resources. Fortunately, scientific or engineering data often have very<br/>low intrinsic complexity and dimensionality.  This project addresses<br/>the opportunities offered by this common situation, establishes<br/>conditions under which reliable inference is actually possible, and<br/>develops computational tools for extracting key information from huge<br/>data sets.<br/><br/>This interdisciplinary project is expected to have three outcomes: 1)<br/>the development of innovative mathematics needed to study the recovery<br/>of data matrices from partial and corrupted information 2) the<br/>development of effective algorithms for recovering low-rank matrices<br/>and performing accurate dimensionality reduction with corrupted data<br/>and 3) the development of novel applications in which these techniques<br/>are expected to considerably advance the state-of-the-art.  With these<br/>new tools, scientists and engineers will be able to efficiently<br/>extract correct information from data, which was previously<br/>inaccessible or intractable by conventional techniques. This will<br/>enable the development of far better computer vision systems for face<br/>recognition, better compression schemes of video sequences, a better<br/>understanding of gene expression data, or better search engines for<br/>web documents and images."
172,1017156,NeTS: Small: Distributed Solutions to Smart Camera Networks,CNS,"Special Projects - CNS, Networking Technology and Syst",07/01/2010,06/07/2011,Hairong Qi,TN,University of Tennessee Knoxville,Standard Grant,Thyagarajan Nandagopal,06/30/2014,"$411,000.00",Qing Cao,hqi@utk.edu,1331 CIR PARK DR,Knoxville,TN,379163801,8659743466,CSE,"1714, 7363","7363, 7923, 9150, 9251",$0.00,"Smart camera networks (SCNs) merge computer vision, distributed<br/>processing, and sensor network disciplines to solve problems in<br/>multi-camera applications by providing valuable information through<br/>distributed sensing and collaborative in-network processing.<br/>Collaboration in sensor networks is necessary not only to compensate<br/>for the processing, sensing, energy, and bandwidth limitations of each<br/>sensor node but also to improve the accuracy and robustness of the<br/>network. Collaborative processing in SCNs is more challenging than in<br/>conventional scalar sensor networks (SSNs) because of three unique<br/>features of cameras, including the extremely higher data rate, the<br/>directional sensing characteristics with limited field of view (FOV),<br/>and the existence of visual occlusion. An integrated research is<br/>carried out to tackle the unique challenges presented by SCNs where<br/>collaboration is the key. Three aspects of collaborative processing<br/>are investigated, 1) coverage estimation in the presence of visual<br/>occlusions to provide adequate redundancy in sensing coverage, and to<br/>enable collaboration where the statistics of visual coverage blends<br/>the statistics of camera nodes and targets, 2) clustering to<br/>schedule an efficient sleep-wakeup pattern among neighbor nodes formed<br/>by image comparison-based semantic neighbor selection algorithm for<br/>more efficient collaboration, and 3) distributed optimization, for<br/>in-network data processing that concerns how to effectively obtain<br/>robust and accurate integration results from multiple distributed<br/>sensors for challenging vision tasks like target detection,<br/>localization, and tracking in crowds."
174,958442,"Collaborative Research:  II-EN:  Development of Publicly Available, Easily Searchable, Linguistically Analyzed, Video Corpora for Sign Language and Gesture Research",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,04/01/2010,03/31/2010,Carol Neidle,MA,Trustees of Boston University,Standard Grant,Ephraim Glinert,03/31/2012,"$70,000.00",Stan Sclaroff,carol@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,CSE,7359,"9102, 9218, HPCC",$0.00,"American Sign Language (ASL) is used by as many as two million people in the United States, with additional users elsewhere in North America.  The purpose of this ""planning grant"" is to enable the PI and her multi-institutional team to explore the case for a possible future NSF investment in an annotated, publicly available, and easily searchable corpus consisting of terabytes of ASL video data (deriving in part from prior work by the PI and her colleagues), including diverse types of content such as dialogues, narratives, elicited sentences illustrating specific grammatical constructions, and isolated signs.  The PI contends such a resource would constitute an important infrastructure that would be exploited by a broad research community to advance the fields of linguistics (the structure of ASL), computer vision (machine recognition of gestures), indexing of visual information (through the expansion of mark up vocabularies), and education.  The PI notes that the potential value of the existing corpora remains largely untapped, notwithstanding their extensive and productive use by her team and others, due to hardware and software limitations that make it cumbersome to search, identify, and share data of interest.  <br/><br/>Broader Impacts:  The new resource would be easily accessible by the research community and the broader public, via a user-friendly Web-based interface.  Availability of the resource online would allow ASL teachers and users, and others, to access the data directly.  Users would be able to look up an unknown sign by submitting a video example of that sign.  Students of ASL would be able to retrieve video showing examples of a specific sign used in actual sentences, or examples of a grammatical construction.  ASL instructors and teachers of the Deaf would have easy access to video examples of lexical items and grammatical constructions as used by a variety of native signers, for use in language instruction and evaluation."
175,1017017,RI: Small: The Shape of Visual Motion,IIS,ROBUST INTELLIGENCE,08/15/2010,05/31/2011,Carlo Tomasi,NC,Duke University,Continuing grant,Jie Yang,07/31/2015,"$457,499.00",,tomasi@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,7495,"7923, 9251",$0.00,"This project studies methods for describing motion in video. All visible points in the world are tagged by their identity, and trajectories of their projections on the image plane are tracked through space and time.  This computation is performed globally, both in space and time, and motion discontinuities are explicitly delineated in the output. In contrast with previous techniques, which estimate motion primarily from the bottom up, starting with two frames at a time, the box of data from a video camera is carved up into tube-like regions whose shapes capture information about the motion and deformation of the objects visible in the scene. Novel methods include the projection of all visual motion onto a sparse basis of point trajectories through low-rank matrix data imputation; the use of L1 regularization in a function space that preserves boundaries; the generalization of robust estimation methods from variational calculus and quadratic programming for the efficient computation of tubes and occlusions in the multi-frame case; and several domain-specific techniques for initializing general but local optimization methods close to the global solution. The resulting descriptors enable video retrieval, medical diagnosis of heart rhythm anomalies, assessment of performance in sports, sign language recognition, traffic monitoring, surveillance, and more. The project also forms the basis for a new class on experimental methods for computer vision, the materials of which are made available online."
176,1049694,III: EAGER: Learning Evaluation Metrics for Information Retrieval,IIS,Info Integration & Informatics,09/01/2010,03/01/2012,Hongyuan Zha,GA,Georgia Tech Research Corporation,Standard Grant,Maria Zemankova,08/31/2013,"$206,000.00",,zha@cc.gatech.edu,Office of Sponsored Programs,Atlanta,GA,303320420,4048944819,CSE,7364,"7364, 7916, 9251",$0.00,"Information retrieval (IR) performance is typically measured in terms of relevancy: every document is known to be either relevant or non-relevant to a particular query. Furthermore, more relevant documents are expected to receive a higher rank than lower less relevant documents. However, determination of relevance and rank by users is not practical. Therefore, it is crucial to develop evaluation metrics and ranking functions that can be derived automatically from judgment data and user behavior data, rather than ad-hoc heuristics. This exploratory project investigates machine learning approaches for constructing evaluation metrics for Web search and information retrieval that consider along important directions other than relevance such as diversity, balance and coverage. <br/><br/>The approach is based on fundamentally extending the popular evaluation metric Discounted Cumulated Gains (DCG). Research focuses on developing optimization methods for learning DCG that can incorporate the degree of difference in pair-wise comparison of ranking lists. Machine learning methods that can learn DCG for the more realistic scenarios where the relevance grades are not readily available are explored, and nonlinear utility functions as evaluation metrics that can accurately capture the quality of search result sets in terms of relevance, diversity, coverage, balance and novelty are investigated.<br/><br/>The project has a number of broad impacts. Research results are expected to provide foundations for further research in evaluation metrics. Active collaborations with industry leaders in Web search will enable the resulting methods to have real impacts on search engine as well as large IR system performance improvements. Improving the quality of search results will have significant impacts on satisfying people's information needs as well as their quality of life in general. The set of research topics lies at the interface between information retrieval and machine learning applications and it provides an ideal setting for training undergraduate and graduate students in the emerging interdisciplinary field of Web of science and engineering research. The project Web site (http://www.cc.gatech.edu/~zha/metrics.html) will be used for results dissemination."
177,1018470,HCC: Small: Sketching Architectural Designs in Context,IIS,HCC-Human-Centered Computing,08/15/2010,03/21/2011,Julie Dorsey,CT,Yale University,Standard Grant,Ephraim Glinert,07/31/2014,"$516,000.00",,dorsey@cs.yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,7367,"7367, 7923, 9251",$0.00,"In this research the fusion of data from different sources will be used to describe an existing site. The fused data will be incorporated into a lightweight interactive design system that facilitates conceptual design. A method for making the transition from the output of the conceptual design phase to a full 3D model suitable for a CAD system used for construction documentation will also be developed.  The work will introduce new methods for gathering and fusing data at an appropriate level of detail for design, rather than following a more traditional approach of creating detailed models and simplifying them for use in an interactive system. The proposed work can have a direct impact on the creative design process by offering a novel approach for creating and editing 3D form. This work is interdisciplinary and brings together research from computer graphics and architecture, computer vision, cognitive science, psychology and design and engineering."
178,1049080,EAGER:   VizWiz - Enabling Blind People to Answer Visual Questions On-the-Go with Remote Automatic and Human-Powered Services,IIS,"Information Technology Researc, HCC-Human-Centered Computing",09/01/2010,07/19/2010,Jeffrey Bigham,NY,University of Rochester,Standard Grant,Ephraim Glinert,08/31/2011,"$49,999.00",,jbigham@cmu.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,"1640, 7367",7916,$0.00,"The lack of access to visual information like text labels, icons, and colors frustrates blind people and severely decreases their independence.  Current access technology uses fully-automatic approaches to address some problems in this space but is error-prone, limited in scope, and expensive.  Blind people who can afford to do so must carry multiple special-purpose portable devices with different audio and tactile interfaces in order to access critical data about their environment such as product information from bar codes and location information via GPS.  These devices would likely be used more often if they had greater functionality and failed less often.  Providing a fallback by making it easy to consult a human assistant could be part of the solution.  The PI's talking VizWiz application for mobile phones is one such prototype that connects blind people to remote human workers who answer general questions about the users' visual environments.  VizWiz currently allows blind users to take a picture, speak a question, and receive answers back quickly.  Preliminary findings have demonstrated the potential advantages of including humans in the loop to help overcome visual problems that are still too difficult to be solved by automatic approaches alone, but questions remain about the efficacy, privacy, speed, and cost of these approaches.  In this project the PI will seek answers to some of these questions, by conducting a longitudinal study of VizWiz with blind people to better understand how the application might fit into their everyday lives.  He will endeavor to determine how users' existing social networks might be employed as a source of answers using applications for Facebook and Twitter.  And he will seek to define new services with appropriate interfaces that let users mediate between automatic and human-powered remote sources for answers.  A mobile accessibility solution using both automated and human Web services represents a significant advance in accessibility but presents challenging user interface questions.  Understanding issues such as those enumerated above is necessary for human-powered services to be accepted as part of assistive technology.  <br/><br/>Broader Impacts:  This exploratory research represents a new paradigm in human-computer interaction in which humans are both clients and providers.  VizWiz has the potential to improve the independence of blind people, and may be both less expensive and more sustainable than current accessibility solutions.  This project will improve our understanding of the types of tools that would be useful for blind people regardless of what is possible today with automatic computer vision, and will help us better understand how to recruit people to answer questions while respecting the asker's values.  The research will involve blind people throughout; the resulting interfaces and functionality will be evaluated by blind people in the world going about their everyday lives.   The interfaces, applications, and framework created and improved as part of this project will be released as open source so other researchers may build on the PI's results.  Project outcomes will be broadly applicable to other problems where automated solutions may occasionally need human intervention."
179,958247,"Collaborative Research:  II-EN:  Development of Publicly Available, Easily Searchable, Linguistically Analyzed, video Corpora for Sign Language and Gesture Research",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,04/01/2010,03/31/2010,Dimitris Metaxas,NJ,Rutgers University New Brunswick,Standard Grant,Ephraim Glinert,03/31/2011,"$20,000.00",,dnm@cs.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7359,"9218, HPCC",$0.00,"American Sign Language (ASL) is used by as many as two million people in the United States, with additional users elsewhere in North America.  The purpose of this ""planning grant"" is to enable the PI and her multi-institutional team to explore the case for a possible future NSF investment in an annotated, publicly available, and easily searchable corpus consisting of terabytes of ASL video data (deriving in part from prior work by the PI and her colleagues), including diverse types of content such as dialogues, narratives, elicited sentences illustrating specific grammatical constructions, and isolated signs.  The PI contends such a resource would constitute an important infrastructure that would be exploited by a broad research community to advance the fields of linguistics (the structure of ASL), computer vision (machine recognition of gestures), indexing of visual information (through the expansion of mark up vocabularies), and education.  The PI notes that the potential value of the existing corpora remains largely untapped, notwithstanding their extensive and productive use by her team and others, due to hardware and software limitations that make it cumbersome to search, identify, and share data of interest.  <br/><br/>Broader Impacts:  The new resource would be easily accessible by the research community and the broader public, via a user-friendly Web-based interface.  Availability of the resource online would allow ASL teachers and users, and others, to access the data directly.  Users would be able to look up an unknown sign by submitting a video example of that sign.  Students of ASL would be able to retrieve video showing examples of a specific sign used in actual sentences, or examples of a grammatical construction.  ASL instructors and teachers of the Deaf would have easy access to video examples of lexical items and grammatical constructions as used by a variety of native signers, for use in language instruction and evaluation."
180,1036462,Frontiers of Activity Recognition,IIS,ROBUST INTELLIGENCE,05/15/2010,05/19/2010,Stefano Soatto,CA,University of California-Los Angeles,Standard Grant,Jie Yang,04/30/2011,"$20,000.00",,soatto@ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,7495,$0.00,"This award is made in support of a collaborative project called ""Frontiers in Activity Recognition"" whereby a group of experts from different fields of computer science, engineering, mathematics and statistics convene in a workshop to be held in the vicinity of UCLA.  <br/>One component of the workshop consists in interactive break-out sessions where different approaches to activity representation (descriptors) and recognition will be analyzed. A second component consists in a competition, announced to the broad public ahead of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), whereby an extensive dataset provided by a third party will be released, with benchmarks, and contestants will be invited to submit their best results in the detection of a number of action categories. The proposers of high-ranking approaches will be invited to the workshop to present their results and discuss it in the context of the analysis of the state of the art to be performed as part of the field assessment. The workshop can have broad impact to many applications ranging from security (surveillance, monitoring) to environmental science (habitat monitoring, global warming), to industrial operations (factory floor optimization), to multi-media and information retrieval (content-based video meta-data extraction), to entertainment (input devices for games), and to transportation (driver assistance)."
182,1031917,"Student Poster Program and Travel Scholarships for International Conference on Machine Learning (ICML) 2010; Haifa, Israel",IIS,Robust Intelligence,07/01/2010,07/06/2010,Alan Fern,OR,Oregon State University,Standard Grant,Sven G. Koenig,06/30/2011,"$30,000.00",,afern@eecs.oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,7495,7495,$0.00,"The project supports graduate student participation in the 27th International Conference on Machine Learning (ICML 2010). Specifically, the project supports travel to the conference for those who might not otherwise be able to attend for financial reasons and organizes a student poster-presentation program that will facilitate one-on-one discussions and other mentoring with the world's leading researchers in machine learning. Students are exposed to state-of-the-art work by other researchers and have the opportunity to attend tutorials on material that is not taught at their home institutions. Participating students receive feedback from senior researchers beyond their institutional and national boundaries. Furthermore, participation in the poster session and conference helps to integrate these students into the research community and represents a natural integration of research and education."
183,958286,"Collaborative:  II-EN:  Development of Publicly Available,  Easily Searchable, Linguistically Analyzed, Video Corpora for Sign Language  and Gesture Research",CNS,CCRI-CISE Cmnty Rsrch Infrstrc,04/01/2010,03/31/2010,Vassilis Athitsos,TX,University of Texas at Arlington,Standard Grant,Ephraim Glinert,03/31/2011,"$10,000.00",,athitsos@uta.edu,"701 S Nedderman Dr, Box 19145",Arlington,TX,760190145,8172722105,CSE,7359,"9218, HPCC",$0.00,"American Sign Language (ASL) is used by as many as two million people in the United States, with additional users elsewhere in North America.  The purpose of this ""planning grant"" is to enable the PI and her multi-institutional team to explore the case for a possible future NSF investment in an annotated, publicly available, and easily searchable corpus consisting of terabytes of ASL video data (deriving in part from prior work by the PI and her colleagues), including diverse types of content such as dialogues, narratives, elicited sentences illustrating specific grammatical constructions, and isolated signs.  The PI contends such a resource would constitute an important infrastructure that would be exploited by a broad research community to advance the fields of linguistics (the structure of ASL), computer vision (machine recognition of gestures), indexing of visual information (through the expansion of mark up vocabularies), and education.  The PI notes that the potential value of the existing corpora remains largely untapped, notwithstanding their extensive and productive use by her team and others, due to hardware and software limitations that make it cumbersome to search, identify, and share data of interest.  <br/><br/>Broader Impacts:  The new resource would be easily accessible by the research community and the broader public, via a user-friendly Web-based interface.  Availability of the resource online would allow ASL teachers and users, and others, to access the data directly.  Users would be able to look up an unknown sign by submitting a video example of that sign.  Students of ASL would be able to retrieve video showing examples of a specific sign used in actual sentences, or examples of a grammatical construction.  ASL instructors and teachers of the Deaf would have easy access to video examples of lexical items and grammatical constructions as used by a variety of native signers, for use in language instruction and evaluation."
185,954083,"CAREER:  Discriminative Spatiotemporal Models for Recognizing Humans, Objects, and their Interactions",IIS,ROBUST INTELLIGENCE,06/01/2010,05/19/2014,Deva Ramanan,CA,University of California-Irvine,Continuing grant,Jie Yang,10/31/2015,"$444,511.00",,deva@cs.cmu.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,7495,"1045, 1187",$0.00,"One of the goals of computer vision is to build a system that can see people and recognize their activities. Human actions are rarely performed in isolation -- the surrounding environment, nearby objects, and nearby humans affect the nature of the performed activity.<br/>Examples include actions such as ""eating"" and ""shaking hands."" The research goal of this project is to approach human performance in understanding videos of activities defined by human-object and human-human interactions.<br/><br/>This project makes use of structured, contextual representations to make predictions given spatiotemporal data. It does so by extending recent successful work on object recognition to the space-time domain, introducing extensions for spatiotemporal grouping and contextual modeling. Video enables the extraction of additional dynamic cues absent in static images, but this poses additional computational burdens that are addressed through algorithmic innovations for approximate parsing and large-scale discriminative learning.<br/><br/>To place activity recognition on firm quantitative ground, the proposed models are evaluated using concrete metrics based on activities of daily living (ADL) and human proxemic models from the medical and anthropological communities. Examples include systems for automated monitoring of stroke patients interacting with everyday objects and automated analysis of crisis response team interactions during emergency drills. This project produces non-scripted, real-world, labeled action recognition datasets, of benefit to the research community as a whole."
186,1017828,DC:Small: Collaborative Research: Data Intensive Computing for General Relational Data Learning,CCF,DATA-INTENSIVE COMPUTING,09/01/2010,08/10/2010,Zhongfei Zhang,NY,SUNY at Binghamton,Standard Grant,Jie Yang,08/31/2015,"$250,000.00",,zhongfei@cs.binghamton.edu,4400 VESTAL PKWY E,BINGHAMTON,NY,139026000,6077776136,CSE,7793,"7793, 9218, HPCC",$0.00,"It is well-observed that the whole world is full of data that are highly related and of diverse data object types such as people, organizations, and events. In many applications, it is intended to discover the hidden structures through such relationships involving different types of data objects in the world, in addition to ""clusters"" of the same type of data objects. On the other hand, relational data learning typically involves a large collection of data objects and thus algorithms for relational data learning are computation-intensive as well as data intensive. This calls for massively parallel solutions in order to make the algorithms scalable to large collections of data. This project addresses a three year integrated research and education program focusing on engaging in-depth research in developing novel parallel frameworks for a wide spectrum of state-of-the-art solutions to a series of fundamental problems in relational data learning. This research promotes the revolutionized understanding of relational data learning in the context of distributed computation environment. The project addresses fundamental problems in the literature of relational data learning as well as the expected breakthrough in the interdisciplinary and multidisciplinary research communities including parallel computation and scheduling, data mining and machine learning, and pattern analysis. The technologies generated from the research can be immediately deployed in important applications such as social network analysis, biological information discovery, financial and economic development analysis and prediction, natural disaster prediction, as well as military intelligence analysis.<br/><br/>Project url:<br/><br/>http://www.fortune.binghamton.edu/nsf-iis-1017828.htm"
187,1017672,RI: Small: Towards Portable Navigational Devices for the Visually Impaired,IIS,"ROBUST INTELLIGENCE, EPSCoR Co-Funding",08/01/2010,08/08/2010,Cang Ye,AR,University of Arkansas Little Rock,Standard Grant,gregory chirikjian,07/31/2015,"$320,389.00",,cye@vcu.edu,2801 South University,Little Rock,AR,722041000,5015698474,CSE,"7495, 9150","7923, 9150",$0.00,"The objective of this project is to devise computer vision methods that enable a Portable Blind Navigational Device (PBND) to guide a visually impaired person in unstructured environments. The main research question of this project is to answer if the approach of employing a single perception sensor can solve blind navigation problem, including localization of the PBND and object recognition. A distinctive feature of this work is that it addresses blind navigation problem by simultaneously processing the visual and range information of a 3D imaging sensor. <br/><br/>The project consists of four related research endeavors. First, it investigates techniques for accurate and precise pose estimation of the PBND in a GPS-denied environment.  Second, it develops an effective 3D data segmentation method to allow scene recognition for wayfinding. Third, it applies the pose estimation method to register 3D range data and devises methods to reduce registration error. Four, it addresses real-time implementation of the methods in the PBND with limited computing power.    <br/><br/>The research will result in new algorithms that can improve the lives of the visually impaired in the near term. They will also enable the autonomy of small robots that have wider applications in military situational awareness, firefighting, and search and rescue. The discoveries will revolutionize small robot autonomy and impact the robotics research community as a whole. Broader impacts also include training of undergraduate and graduate students, and educating the public on robotics through workshops and robot exhibits in science museums and technology showcases."
188,1025120,Manifold Alignment of High-Dimensional Data Sets,CCF,"MSPA-INTERDISCIPLINARY, FOUNDATIONS VISUAL ANALYTICS",09/01/2010,07/22/2010,Sridhar Mahadevan,MA,University of Massachusetts Amherst,Standard Grant,Tie Luo,08/31/2014,"$499,909.00",Rui Wang,mahadeva@cs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,"7454, 7703",7923,$0.00,"As the availability and size of digital information repositories continues to burgeon, the problem of extracting deep semantic structure from high-dimensional data becomes more critical. This project addresses the fundamental problem of transfer learning, in particular it investigates methods for aligning multiple heterogeneous data sets to find correspondences and extract shared latent semantic structure. Domains of applicability include automatic machine translation, bioinformatics, cross-lingual information retrieval, perceptual learning, robotic control, and sensor-based activity modeling.  The proposed research will investigate a geometric framework for transfer learning based on finding correspondences between data by aligning their projections onto lower dimensional manifolds. The proposed research will investigate a broad spectrum of approaches to manifold alignment, including one-step vs. two-step alignment, instance-based vs. feature-based alignment, semi-supervised vs. unsupervised alignment, and finally one-level vs. multi-scale alignment. Visualization tools that use alignment information will be developed to facilitate interactive learning from data analysis. To aid the processing of large data sets, the parallel computational power of modern graphics processing units (GPUs) will be exploited.<br/><br/>Given the rapidly increasing availability of digital data sets from a diverse variety of domains, the scientific question of extracting knowledge from massive unstructured information repositories is becoming ever more critical. The proposed research combines the study of machine learning algorithms for discovering latent correspondences between seemingly disparate data sets, and the development of visualization tools to aid human interpretation of high-dimensional data.  Empirical studies on a variety of real-world applications will be carried out, ranging from bioinformatics, Internet web archives, multilingual text, and sequential time-series data sets. The broader impacts of the proposed research include algorithmic advances in the analysis and visualization of high-dimensional data, and empirical studies on a variety of real-world applications. The data sets and software developed in this research will be disseminated through the web. The research will be communicated through a variety of conferences, workshops and seminars in several disciplines ranging from computer science, engineering, mathematics, and statistics. The PIs will make significant efforts to recruit underrepresented groups, including women and other minorities, in this research.  New course material on advanced data analysis and visualization will be developed based on the proposed research."
189,1018651,RI: Small: Spectral Methods for Learning Time Series and Graphical Models,IIS,ROBUST INTELLIGENCE,08/01/2010,03/15/2013,Sham Kakade,PA,University of Pennsylvania,Continuing grant,Todd Leen,07/31/2013,"$224,998.00",,sham@cs.washington.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,7495,"7923, 9150",$0.00,"The investigators study a new class of statistical methods for learning time series and graphical models. Their approach is based on spectral analysis and matrix decomposition methods that have enjoyed tremendous success in applications, but their use in graphical models has drawn less attention. The goal of this investigation is to extend the enormous previous successes of matrix decomposition methods to the realm of more complicated time series and certain graphical models, which will lead to new statistical machine learning algorithms with important practical applications.<br/><br/>In the information age, an important measure of computer intelligence is the ability to analyze huge amount of data that become available electronically, and make critical decisions under uncertain environment. Statistical machine learning is the main technique for analyzing electronic data, and graphical models are mathematical tools for understanding these complex data both by computer systems and by human operators in order to facilitate decision making. However, traditional algorithms for learning graphical models have limitations that restrict capabilities of modern computing systems. The current research attempts a new class of mathematical algorithms that can be used to design more effective graphical models, which in turn allows modern computers to analyze data more accurately and achieve higher level of intelligence."
191,1016061,RI: Small: Spectral Methods for Learning Time Series and Graphical Models,IIS,ROBUST INTELLIGENCE,08/01/2010,06/16/2011,Tong Zhang,NJ,Rutgers University New Brunswick,Continuing grant,Todd Leen,07/31/2014,"$224,646.00",,tzhang@stat.rutgers.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,7495,7923,$0.00,"The investigators study a new class of statistical methods for learning time series and graphical models. Their approach is based on spectral analysis and matrix decomposition methods that have enjoyed tremendous success in applications, but their use in graphical models has drawn less attention. The goal of this investigation is to extend the enormous previous successes of matrix decomposition methods to the realm of more complicated time series and certain graphical models, which will lead to new statistical machine learning algorithms with important practical applications. <br/><br/>In the information age, an important measure of computer intelligence is the ability to analyze huge amount of data that become available electronically, and make critical decisions under uncertain environment. Statistical machine learning is the main technique for analyzing electronic data, and graphical models are mathematical tools for understanding these complex data both by computer systems and by human operators in order to facilitate decision making. However, traditional algorithms for learning graphical models have limitations that restrict capabilities of modern computing systems. The current research attempts a new class of mathematical algorithms that can be used to design more effective graphical models, which in turn allows modern computers to analyze data more accurately and achieve higher level of intelligence."
193,964797,EAGR:  Perceptually Optimized Semantic Media Adaptation for Mobile Device Access,IIS,Robust Intelligence,04/01/2010,03/23/2010,Chang Wen Chen,NY,SUNY at Buffalo,Standard Grant,Jie Yang,03/31/2011,"$59,999.00",,chencw@buffalo.edu,520 Lee Entrance,Buffalo,NY,142282567,7166452634,CSE,7495,"7495, 7916",$0.00,"This project develops a semantic media adaptation scheme for mobile access of information that is perceptually optimized for users to enjoy semantically relevant media content using small display mobile devices. The research team explores seamless integration of multidisciplinary technologies from computer vision, media coding and transmission, wireless networking, mobile device, and human visual perception to tackle the challenges in closing the gap between rich content in high resolution and size limited mobile device access.<br/><br/>The intellectual merit of this project lies in the exploration and development of several relevant techniques in (1) Limited user interface media semantic extraction; (2) Capacity and resource constrained media content adaptation; (3) Perceptually optimized delivery and display of adapted media to small sized mobile devices. The research team addresses these issues by seamless integration of technologies from different research fields that traditionally have less interaction. <br/><br/>The project bridges both semantic gap and user intention gap in mobile multimedia search and access. First, the innovative scheme of semantic adaptation can be extended for any media search application based on semantically relevant characteristics.  Second, the adaptation of high resolution media content for small sized mobile device plays a key role in media gateway for wireless mobile access. Finally, the investigation of perceptual optimized display on mobile devices shall open up a new research avenue to understand how mobile users perceive rich media content with small displays."
194,1017626,RI: Small: Probabilistic Latent Variable Models for Sparse Data,IIS,ROBUST INTELLIGENCE,12/01/2010,12/03/2010,Raquel Urtasun,IL,Toyota Technological Institute at Chicago,Standard Grant,Jie Yang,11/30/2011,"$149,988.00",,rurtasun@ttic.edu,6045 S Kenwood Ave,Chicago,IL,606372803,7738340409,CSE,7495,7923,$0.00,"This project focuses on learning parsimonious representations of complex high-dimensional data. In recent years, the PI has developed probabilistic latent variable models based on Gaussian processes that are able to capture complex interactions and perform state of the art prediction in diverse applications such as 3D human body tracking and collaborative filtering. However, in real-word applications such as the analysis of human motion or object recognition from images, the data is structured (e.g., the correlations in a video sequence can be captured with tensors), can come from different sources of information (e.g., video and audio), can be generated from a complex dynamical process or additional information might be available (e.g., labels). <br/><br/>To address these real world problems, this project investigates extensions of the aforementioned probabilistic latent variable models to learn parsimonious representations of this complex data, focusing on the development of efficient learning algorithms that are able to handle large and sparse datasets. This research is strongly tied to an empirical performance goal, consisting of improving the state-of-the-art in both pose estimation and object recognition applications through the modeling of such complex interactions.  The proposed research has broad impact in several areas of computer vision in particular human body motion estimation and tracking."
195,1018751,RI:  Small:  Learning  and Inference with And-Or Graphs for Image Understanding,IIS,ROBUST INTELLIGENCE,08/01/2010,11/13/2014,Song-Chun Zhu,CA,University of California-Los Angeles,Continuing grant,Jie Yang,06/30/2015,"$450,000.00",Yingnian Wu,sczhu@stat.ucla.edu,10889 Wilshire Boulevard,LOS ANGELES,CA,900951406,3107940102,CSE,7495,"7923, 9150",$0.00,"In this project, the PIs and students study a probabilistic and graphical representation, called the And-or graph (AoG) for visual knowledge representation.  This AoG model embodies hierarchical and contextual models for visual objects and scenes and is the key to robust object and scene recognition. More specifically, the project addresses two major technical challenges: (i)  Learning the AoG for representing objects and scenes in an unsupervised way; and (ii)  Developing effective inference algorithm by scheduling top-down and bottom-up processes to extract semantic contents in a parse graph under the guidance of the AoG. The extracted semantics include the hierarchical decomposition of the image from scene to objects, and parts, as well as the contextual relations. These contents are crucial for filling in the semantic gap in large scale image search and retrieval.  The technologies studied in this project are key to a number of applications, such as image content extraction for security surveillance, information gathering, Internet image search, and situation awareness. One specific application studied in this project is autonomous driving assistant for designing safer vehicles and reducing car accidence. The project also supports the training of 3 graduate students over the three year period. Research results are disseminated through public publications in major computer vision conferences and journals, institutional webpages, and shared data sets and code in the Internet."
196,1017344,RI: Small: Theory and Experiments with Tumbling Robots,IIS,ROBUST INTELLIGENCE,08/01/2010,06/19/2015,Nikolaos Papanikolopoulos,MN,University of Minnesota-Twin Cities,Standard Grant,Jie Yang,07/31/2016,"$497,995.00",,npapas@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,7495,"7495, 7923, 9251",$0.00,"This project revolves around tumbling which is an exciting area of robotic locomotion that takes advantage of ground-body interactions to achieve high mobility on smaller scales when compared to conventional methods. Additionally, the required hardware complexity to produce such locomotion is very low. In this respect, tumbling can be viewed as a minimalistic approach to producing miniature mobile robots capable of traversing complex and dynamic terrains. Due to the nature of tumbling however, the added mobility comes at the price of increased control complexity. The minimalistic nature of tumbling robots generally results in underactuated systems that exhibit nonholonomic constraints which greatly complicate the motion planning problem. Additionally, tumbling often involves time-varying supports and sliding contacts with the ground. Ultimately, this research views tumbling as a largely unexplored yet promising area of research. This work addresses the intricacies of tumbling locomotion. Specifically, we are developing general planning algorithms for tumbling robots and identify important design characteristics of tumbling robots that lead to simplified control. <br/><br/>Seminars and workshops to bring together practitioners, end-users, researchers, and policy makers will be organized to have the maximal impact. Web-based dissemination of the algorithms and rapid prototyping/simulation tools ensure that the results of this project reach all communities. Students trained in this project participate in the US FIRST competitions, summer mentoring programs for high school students, summer schools in robotics, and other outreach programs."
197,1026141,Middle East Robotics Research Collaboration Planning,IIS,"Catalyzing New Intl Collab, Robust Intelligence",06/01/2010,06/07/2010,Rajiv Dubey,FL,University of South Florida,Standard Grant,Richard Voyles,05/31/2012,"$49,440.00",Redwan Alqasemi,dubey@usf.edu,4019 E. Fowler Avenue,Tampa,FL,336172008,8139742897,CSE,"7299, 7495","5976, 7495, 7506, 7534, 7542, 9150",$0.00,"The objective of this planning visit is to explore and identify potential collaborations in robotics with specific emphasis on rehabilitation robotics, humanoids and medical robotics, in the United Arab Emirates, Saudi Arabia and Qatar, and to meet with the researchers, administrators and government officials there to discuss future research collaborations.   Rehabilitation and assistive robotics are active research fields that can significantly change the lives of the elderly and individuals with physical disabilities.   A U.S. team of 4 faculty members has been assembled.  The team is well qualified to address the objective and has expertise in broad robotics areas including rehabilitation robotics, assistive technology, kinematic and dynamic synthesis, smart and intelligent systems, computer vision and sensing, robotic control, and mechanism design.  Immediate outcome of this Planning Visit will be a report summarizing the findings and recommendations for potential collaborations.  We anticipate proposal submissions (e.g. NSF PIRE) aimed toward long-term goals to continue international collaborations. Our visit is expected to be ""ambassador-like"" and not just purely academic.  It is a ?fact finding"" mission to potentially pave the way for increased US-Gulf collaborations in areas of NSF CISE interest. This planning visit is funded jointly by IIS and the Office of International Science and Engineering (OISE)."
206,1017903,III: Small: Collection Construction Methodologies for Learning-to-Rank,IIS,Info Integration & Informatics,09/01/2010,09/02/2010,Javed Aslam,MA,Northeastern University,Standard Grant,Maria Zemankova,08/31/2013,"$488,723.00",,jaa@ccs.neu.edu,360 HUNTINGTON AVE,BOSTON,MA,21155005,6173733004,CSE,7364,7923,$0.00,"Modern search engines, especially those designed for the World Wide Web, commonly analyze and combine hundreds of features extracted from the submitted query and underlying documents (e.g., web pages) in order to assess the relative relevance of a document to a given query and thus rank the underlying collection. The sheer size of this problem has led to the development of learning-to-rank algorithms that can automate the construction of such ranking functions: Given a training set of (feature vector, relevance) pairs, a machine learning procedure learns how to combine the query and document features in such a way so as to effectively assess the relevance of any document to any query and thus rank a collection in response to a user input. Much thought and research has been placed on feature extraction and the development of sophisticated learning-to-rank algorithms. However, relatively little research has been conducted on the choice of documents and queries for learning-to-rank data sets nor on the effect of these choices on the ability of a learning-to-rank algorithm to ""learn"", effectively and efficiently.<br/><br/>The proposed work investigates the effect of query, document, and feature selection on the ability of learning-to-rank algorithms to efficiently and effectively learn ranking functions.  In preliminary results on document selection, a pilot study has already determined that training sets whose sizes are as small as 2 to 5% of those typically used are just as effective for learning-to-rank purposes. Thus, one can train more efficiently over a much smaller (though effectively equivalent) data set, or, at an equal cost, one can train over a far ""larger"" and more representative data set.  In addition to formally characterizing this phenomenon for document selection, the proposed work investigate this phenomenon for query and feature selection as well, with the end goals of (1) understanding the effect of document, query, and feature selection on learning-to-rank algorithms and (2) developing collection construction methodologies that are efficient and effective for learning-to-rank purposes.<br/><br/>In addition to characterizing and developing collection construction methodologies, the project plan includes development and release of new, efficient, and effective learning-to-rank data sets for use by academia and industry.  In fostering this effort, the project team has close ties with the National Institute of Standards and Technology (NIST) and Microsoft Research, two of the premier organizations that develop and release Information Retrieval data sets.  All research results and data sets developed as part of this project will be made available at the project website (http://www.ccs.neu.edu/home/jaa/IIS-1017903/). The project provides an educational and training experience for students."
207,953274,CAREER: Combinatorial Online Learning and its Applications,IIS,Robust Intelligence,04/01/2010,04/30/2013,Arindam Banerjee,MN,University of Minnesota-Twin Cities,Continuing grant,Weng-keen Wong,03/31/2017,"$495,804.00",,banerjee@cs.umn.edu,200 OAK ST SE,Minneapolis,MN,554552070,6126245599,CSE,7495,1045,$0.00,"Several important problems in machine learning, such as maximum<br/>aposteriori (MAP) inference in graphical models, are inherently combinatorial. While extensive research has been devoted to designing approximation algorithms for such problems, existing algorithms do not scale well to large problems. This project focuses on leveraging ideas from online learning with expert advice to develop a novel family of online learning algorithms for combinatorial optimization problems. <br/><br/>Algorithms for combinatorial online learning are efficient and simple to analyze in order to establish guarantees. Unlike existing literature on approximation algorithms for combinatorial problems which rely on suitable real relaxations of the original problem, combinatorial online learning algorithms never use relaxations; they work directly with binary/integer solutions and have global approximation guarantees.  The project investigates generalizations of the framework to solve online and batch binary quadratic programming problems, yielding approximation algorithms for a variety of combinatorial problems, including NP-complete problems, and MAP inference in directed and undirected graphical models. The project considers three important real life applications: portfolio selection for effectively investing in the stock market, automating surgical pathology by expediting disease detection in tissue images, and climate change detection for discovering abrupt climate changes from spatiotemporal climate data. <br/><br/>The project is expected to be transformative, especially in the context of surgical pathology and climate change detection, yielding significant long term societal benefits. The research results will be disseminated to the community through research papers, tutorials, open source software, and outreach activities using games based on mock stock markets."
208,1016312,RI:  Small:  Perceptually Grounded Learning of Instructional Language,IIS,Robust Intelligence,09/01/2010,06/10/2011,Raymond Mooney,TX,University of Texas at Austin,Continuing grant,Tatiana Korelsky,08/31/2014,"$450,000.00",,mooney@cs.utexas.edu,"3925 W Braker Lane, Ste 3.340",Austin,TX,787595316,5124716424,CSE,7495,7923,$0.00,"This project is developing methods that allow a computer to automatically learn to understand and generate instructions in human language. Traditional approaches to natural-language learning require linguistic experts to laboriously annotate large numbers of sentences with detailed information about their grammar and meaning. In this project, instructional language is initially learned by simply observing humans following instructions given by other humans.  Once the system has learned reasonably well from observation, it also actively participates in the learning process by following human-given instructions itself, or giving its own instructions to humans and observing their behavior. The approach is being evaluated on its ability to interpret and generate English instructions for navigating in a virtual environment (e.g. ""Go down the hall and turn left after you pass the chair."").  A novel machine learning method infers a probable formal meaning for a sentence from the resulting actions performed by a human follower, and then existing language-learning methods are used to acquire a language interpreter and generator.  The learned system is being evaluated in a range of virtual environments, testing its ability to follow human-provided natural language instructions to achieve prescribed goals, as well as to generate natural language instructions that humans can successfully follow to find specific destinations. The methods developed for this project will contribute to the development of virtual agents in games and educational simulations that learn to interpret and generate English instructions, and eventually aid the development of robots that can learn to interpret human language instruction from observation."
209,1018114,DC:Small:Collaborative Research:Data Intensive Computing  for General Relational Data Learning,CCF,DATA-INTENSIVE COMPUTING,09/01/2010,03/23/2011,Lixin Gao,MA,University of Massachusetts Amherst,Standard Grant,Jie Yang,08/31/2015,"$257,997.00",,lgao@ecs.umass.edu,Research Administration Building,Hadley,MA,10359450,4135450698,CSE,7793,"7793, 9218, 9251, HPCC",$0.00,"It is well-observed that the whole world is full of data that are highly related and of diverse data object types such as people, organizations, and events. In many applications, it is intended to discover the hidden structures through such relationships involving different types of data objects in the world, in addition to ""clusters"" of the same type of data objects. On the other hand, relational data learning typically involves a large collection of data objects and thus algorithms for relational data learning are computation-intensive as well as data intensive. This calls for massively parallel solutions in order to make the algorithms scalable to large collections of data. This project addresses a three year integrated research and education program focusing on engaging in-depth research in developing novel parallel frameworks for a wide spectrum of state-of-the-art solutions to a series of fundamental problems in relational data learning. This research promotes the revolutionized understanding of relational data learning in the context of distributed computation environment. The project addresses fundamental problems in the literature of relational data learning as well as the expected breakthrough in the interdisciplinary and multidisciplinary research communities including parallel computation and scheduling, data mining and machine learning, and pattern analysis. The technologies generated from the research can be immediately deployed in important applications such as social network analysis, biological information discovery, financial and economic development analysis and prediction, natural disaster prediction, as well as military intelligence analysis. <br/><br/>Project url: <br/><br/>http://www.fortune.binghamton.edu/nsf-iis-1017828.htm"
211,968487,SoCS:  Effectively Leveraging Contributions in Human Computation Systems,IIS,"Special Projects - CCF, SOCIAL-COMPUTATIONAL SYSTEMS",08/01/2010,04/20/2011,Luis von Ahn,PA,Carnegie-Mellon University,Standard Grant,Tatiana Korelsky,07/31/2013,"$753,500.00",Tom Mitchell,biglou@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"2878, 7953","7953, 9251",$0.00,"Human computation studies how to collect useful data as a by-product of another activity in which people are interested (e.g., playing games). A popular example is the ESP Game, where two players are shown the same image and must independently generate tags; tags that match become labels for the image. ESP Game players have generated millions of labels that help improve image search engines.<br/><br/>Currently, little is understood about how to capitalize on each person's individual expertise to produce the best results in human computation systems. For example, the ESP Game could generate better results if automotive enthusiasts labeled images of cars while biologists labeled images of animals. This project aims to better understand how each individual's different capabilities can be assessed, dynamically leveraged, and even improved for the purposes of human-driven data collection. <br/><br/>Intellectual Merit: Improved understanding of the strengths and weaknesses of human users as teachers and data sources; an intelligent new objective-driven model of data collection; novel opportunities to study machine learning algorithms that capitalize on human teachers' abilities; and an analysis of learning opportunities as incentives for people to participate in human computation systems.<br/><br/>Broader Impact: Distribution of large new data sets (e.g., Wikipedia articles in multiple languages); several Internet-based human computation systems for large-scale evaluation of machine learning and other algorithms; a new course called ?Human-in-the-Loop Systems?; workshops held in conjunction with major conferences; and outreach activities (e.g., summer projects) that introduce female undergraduate students to interdisciplinary research."
212,1009542,"Text, Neuroimaging, and Memory: Unified Models of Corpora and Cognition",IIS,"Engineering of Biomed Systems, ROBUST INTELLIGENCE",08/01/2010,06/19/2015,Kenneth Norman,NJ,Princeton University,Standard Grant,aude oliva,12/31/2015,"$732,296.00",Kenneth Norman,knorman@princeton.edu,Off. of Research & Proj. Admin.,Princeton,NJ,85442020,6092583090,CSE,"5345, 7495","004E, 7327",$0.00,"The PIs will develop new machine learning algorithms to explore how meaning is represented in the brain and how meaning representations shape human memory.  Current neuroscientific theories of memory posit that forming a memory for a particular event involves associating the details of that event with the person's current mental context, i.e., everything else that she is thinking about at the time.  When trying to remember the event, the person can access stored details by reinstating the mental context that was present when the memory was formed. This fits with the intuition that forgotten details (e.g., the location of misplaced house keys) can be retrieved by mentally ""re-tracing steps"", i.e., trying to reinstate the mindset that was present at the time of the original event.  With these theories in mind, the goal of this work is to develop machine learning algorithms that make it possible to track, based on fMRI brain data and behavioral memory data, the process of ""mentally re-tracing steps""---the proposed algorithms will be able to decode the state of a person's mental context as she forms memories and (later) as she searches for these memories.<br/><br/>The proposed work uses two fundamental ideas about memory and meaning: The first idea is that mental context is shaped by the meanings of recently encountered stimuli.  The second idea is that semantic relationships between concepts in the brain mirror statistical relationships between words in naturally occurring language. The developed algorithms will bring together data from three sources---behavioral data from subjects performing memory recall tasks, fMRI neuroimaging data collected while subjects performed these tasks, and large collections of documents---to discover a latent meaning space that can simultaneously describe all three types of information.  Each point in this space describes a mental context. Thus the core of the proposed work is to develop latent variable models and algorithms that can infer from data how the mental context moves through meaning space as a person stores and searches for memories.<br/><br/>The proposed work will lead to fundamental advances in machine learning (new algorithms for inferring hidden variables based on multiple, heterogeneous data types) and neuroscience (more refined theories of how memory search is accomplished in the brain). Furthermore, this work will catalyze the development of new technologies for diagnosing and remediating memory problems, by making it possible to track how the contextual reinstatement process is going awry in people experiencing memory retrieval failure."
213,1017967,"III:  Small:  Representation, Modeling and Inference for Large Biological and Information Networks",IIS,Info Integration & Informatics,08/01/2010,05/04/2012,Edoardo Airoldi,MA,Harvard University,Continuing grant,Sylvia Spengler,07/31/2014,"$513,780.00",Jun Liu,airoldi@temple.edu,1033 MASSACHUSETTS AVE,Cambridge,MA,21385369,6174955501,CSE,7364,"7364, 7923, 9251",$0.00,"Modern technology has completely transformed the concept of data in the biological and information sciences. Data collections about the flow of information on the web, for instance, or about regulatory and metabolic dynamics that drive cellular functionality are extremely large and heterogeneous. These collections are often characterized as networks of websites, or proteins, where directed edges denote information flow, or chemical reactions, and with node information described in terms of web pages, or chains of amino acids. Knowledge discovery and management is key. The goal of this proposal is to create novel computational and statistical approaches to store, search, and quantify patterns in large networks efficiently, and to explore the extent to which these new tools help address a number of important open problems and computational issues. The research plan includes theoretical, methodological, data analysis, and dissemination aspects.<br/><br/>The approach is to develop new models, methods and algorithms for analyzing large biological and information networks with rich node information. New tools will be developed: to assess the complexity of networks; to compare the fit of alternative network models; to store information about both connectivity and nodes in a network efficiently; to calibrate informative priors for networks that reflect the reality of signaling both in metabolic networks and  in the spread of news on the web for empirical Bayesian analyses; to estimate the effects of node information on the local connectivity in a network; and to infer influence potentials and diffusion channels in online information networks. The proposed research is focused on three specific technical tasks: (1) establishing a new representation of valued, multivariate networks based on a statistical models; (2) developing a flexible family or probabilistic graphical models to link local connectivity in the network to high-dimensional node attributes; and (3) developing scalable algorithms to infer a non-observable network structure from multiple trails of informational artifacts on the network itself. In addition, two in-depth case studies will be developed to illustrate the potential of the proposed methodology. The first is an analysis of the effects of local influence patterns among online newspapers, news collectors and blogs on the diffusion of news and information items. The second is an analysis of the effects of local perturbations of signaling in regulatory networks on global cellular responses, for many known functions, from bacteria to human. Insights gained in tackling the case studies will in turn generalize and foster the development of the next wave of core methodology and theory in machine learning.<br/><br/>The proposed work meets an urgent need for the development of new and principled methods for analyzing massive amounts of network data, as well as the creation of large-scale data sets for testing and benchmarking, to the benefit of the community at large. The research plan is tightly integrated with an interdisciplinary educational program and with the development of a statistical machine learning curriculum, which will attract many undergraduates to research at the intersection of machine learning and the sciences, and will provide opportunities to actively encourage students from underrepresented groups to pursue careers in computer science and statistics. The team will distribute open source software and set-up websites to enable the community to use and build upon the tools."
215,1012017,RI-Large: Activity Learning and Recognition for a   Cognitive Assistant,IIS,"Info Integration & Informatics, Robust Intelligence",08/15/2010,08/03/2012,Henry Kautz,NY,University of Rochester,Continuing grant,Tatiana Korelsky,01/31/2014,"$749,988.00",,kautz@cs.rochester.edu,"518 HYLAN, RC BOX 270140",Rochester,NY,146270140,5852754031,CSE,"7364, 7495",7925,$0.00,"This project addresses a key problem in advancing the state of the art in cognitive assistant systems that can interact naturally with humans in order to help them perform everyday tasks more effectively. Such a system would help not only people with cognitive disabilities but all individuals as they perform complex tasks they are unfamiliar with. The research focuses on structured activities of daily living that lend themselves to practical experimentation, such as meal preparation and other kitchen activities.<br/><br/>Specifically, the core focus of the research is activity recognition, i.e., systems that can identify the goals and individual actions a person is performing as they work on a task. Key innovations of this work are 1) that the activity models are learned from the user via intuitive natural demonstration, and 2) that the system is able to reason over activity models to generalize and adapt them. In contrast, current practice requires specialized training supervised by the researchers and supports no reasoning over the models. This advance is accomplished by integrating capabilities that are typically studied separately, including activity recognition, knowledge representation and reasoning, natural language understanding and machine learning. The work addresses a significant step towards the goal of building practical and flexible in-home automated assistants."
216,1017429,HCC: Small: Learning Routines to Support People's Activities,IIS,HCC-Human-Centered Computing,08/15/2010,04/25/2011,Anind Dey,PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,07/31/2014,"$507,592.00",John Zimmerman,anind@uw.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7367,"7367, 7923, 9150, 9251",$0.00,"People construct routines as they repeatedly perform the same sequence of actions. Routines provide a huge benefit by freeing people?s attention, allowing them to carry out their daily tasks without constantly thinking about every little thing they must do. Problems begin to arise when people must deviate from their routines. Families rely heavily on their routines to address the complex logistics and conflicting agendas of work, school, family, and enrichment activities. However, families often deviate from their routines, and when breakdowns in the plans occur, they feel their lives are out of control.<br/><br/>This research will develop a system that learns the routine movements of family members, and a planning system that leverages this model in order to generate a speculative plan for future days.  The system will also predict conflicts with scheduled deviations and detect when plans begin to breakdown, such as when someone forgets to deviate from a routine. A calendar interface that displays the routine movements of family members along with their scheduled deviations and a small set of reminder applications that help people enact their plans and that support them when plans breakdown will form the basis for evaluating the underlying systems. This research is transformative in the novel integration of machine learning and planning techniques, and its application to a real-world and complex problem. Finally, this research provides insights on how intelligent, ubiquitous computing technology influences families? feelings of control and their quality of life. <br/><br/>The proposed work has the potential to significantly improve the quality of life for millions of families by reducing stress caused from breakdowns in plans and routines. Lowering stress can improve the quality of marriages, the quality of parenting, and the physical and mental health of children. We will involve undergraduate and graduate students in our research and will incorporate our findings into our courses on ubiquitous computing, interaction design, and on smart homes. We expect that our focus on a social problem will attract non-science-focused students to science and expose science-focused students to design methods of inquiry."
220,1012205,RI-Large: Activity Learning and Recognition for a   Cognitive Assistant,IIS,Robust Intelligence,08/15/2010,08/03/2012,James Allen,FL,"Florida Institute for Human and Machine Cognition, Inc.",Continuing Grant,Tatiana Korelsky,01/31/2014,"$750,000.00",,jallen@ihmc.us,40 S. Alcaniz St.,Pensacola,FL,325026008,8502024473,CSE,7495,7925,$0.00,"This project addresses a key problem in advancing the state of the art in cognitive assistant systems that can interact naturally with humans in order to help them perform everyday tasks more effectively. Such a system would help not only people with cognitive disabilities but all individuals as they perform complex tasks they are unfamiliar with. The research focuses on structured activities of daily living that lend themselves to practical experimentation, such as meal preparation and other kitchen activities.<br/><br/>Specifically, the core focus of the research is activity recognition, i.e., systems that can identify the goals and individual actions a person is performing as they work on a task. Key innovations of this work are 1) that the activity models are learned from the user via intuitive natural demonstration, and 2) that the system is able to reason over activity models to generalize and adapt them. In contrast, current practice requires specialized training supervised by the researchers and supports no reasoning over the models. This advance is accomplished by integrating capabilities that are typically studied separately, including activity recognition, knowledge representation and reasoning, natural language understanding and machine learning. The work addresses a significant step towards the goal of building practical and flexible in-home automated assistants."
221,1017938,HCC: Small: Body Language Animation for Virtual Worlds and Computer-Mediated Communication,IIS,HCC-Human-Centered Computing,09/01/2010,09/02/2010,Vladlen Koltun,CA,Stanford University,Standard Grant,William Bainbridge,08/31/2013,"$495,208.00",,vladlen@stanford.edu,450 Jane Stanford Way,Stanford,CA,943052004,6507232300,CSE,7367,7923,$0.00,"This project will enable full-body nonverbal communication in virtual worlds, applying state-of-the-art machine learning and computer animation techniques to the synthesis of nonverbal communication, advancing and refining these techniques in the process. Virtual worlds are an emerging computer-mediated communication medium that situates geographically distributed participants in a shared communication space and enables embodied interaction with others in a simulated environment. Participants are represented as animated virtual humans that can convey both speech and body language. Yet no viable technology exists that can animate the virtual human's body during a live conversation without resorting to esoteric hardware or brittle algorithmic techniques.<br/><br/>This research will develop an approach that can convey body language through virtual humans in real time, using a natural control interface: the speech and motion of the participants. The proposal is based on, and sometimes advances, the state of the art in machine learning, computer animation, and the relevant aspects of linguistics and cognitive psychology. Body language animation based purely on visual tracking of the participant's motion is prone to significant defects due to tracking noise and failure. Thus this approach analyzes the speech of the participant together with the motion. This principled integration of live speech and motion input constitutes a fundamentally new approach to the control of nonverbal expression of human self-representations in virtual worlds.<br/><br/>The ability to convey rich nonverbal communication in virtual worlds will advance the capabilities of computer-mediated communication as a whole. This will provide basic infrastructure for distributed collaboration in science and engineering. Powerful forms of situated learning and social-scientific inquiry in education will be enabled, with positive impact on the self-efficacy of students who traditionally underperform in science curricula. Social science will be enriched with a new medium for the study of human interaction."
222,953149,CAREER:  Cross-Document Cross-Lingual Event Extraction and Tracking,IIS,Info Integration & Informatics,03/01/2010,06/27/2014,Heng Ji,NY,CUNY Queens College,Continuing grant,Maria Zemankova,03/31/2015,"$543,384.00",,jih@rpi.edu,65 30 Kissena Blvd,Flushing,NY,113671575,7189975400,CSE,7364,"1045, 7364, 9102, 9215, 9251, HPCC",$0.00,"The goal of this research project is advance the Information Extraction (IE) paradigm beyond ""slot filling"", and achieve more accurate, salient, complete, concise and coherent extraction results by exploiting dynamic background knowledge and cross-document cross-lingual event ranking and tracking. The approach consists of cross-document inference, unknown implicit event time prediction and reasoning, cross-document entity coreference resolution with global contexts, centroid entity detection, event attribute extraction and graph-based clustering algorithms for redundancy and contradiction detection, automatic new event clustering and active learning, abstractive summary generation based on extraction results, name translations with comparable corpora and cross-lingual co-training.<br/><br/>The experimental research is integrated with educational activities, including project-related curriculum development. The project involves PhD students as well as undergraduate students, engages non-Computer Science undergraduate students in utility evaluation and corpus annotation, and attracts elementary school and high school students by tutorials, regular research seminars and an extensive summer workshop. The results of this project will also have a benefit in E-Science and E-Learning by extracting and tracking the related knowledge from scientific literature and learning materials used in elementary schools and high schools.<br/><br/>Project results, including open source software, task definition guidelines, annotated corpora, scoring metrics will be disseminated via project Web site<br/>(http://nlp.cs.qc.cuny.edu/blendeet.html)."
228,1048515,EAGER: Investigating Diversity in Online Community Filtering,IIS,HCC-Human-Centered Computing,08/01/2010,08/07/2010,Rachel Greenstadt,PA,Drexel University,Standard Grant,William Bainbridge,07/31/2012,"$95,822.00",Jennifer Rode,greenstadt@nyu.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,7367,7916,$0.00,"A transition is occurring from a world in which gatekeepers and editors filter content before it is published to a world full of user-generated content in which information filtering is done after publication. Today's online communities have developed a variety of community-based filtering and rating mechanisms to help maintain quality and manageability. However, it is an open question  whether these filtering mechanisms represent ""the wisdom of crowds"" or ""the censoring mob.""<br/><br/>This project will apply statistical machine learning and ethnographic studies to understand the mechanisms by which online communities censor content from the bottom up. This understanding will provide insight into how values are and can be embedded into these large, socially intelligent systems. Ultimately, the goal is to design socially intelligent community filtering systems in which individuals, communities, and intelligent software agents collaborate, to explain the mechanisms behind social, bottom-up filtering, and expand the range of the possible in terms of the values these systems can reflect and the communities it can serve. This project will study the mechanisms through which the social construction of gender impacts community filtering systems. This will be done via an in-depth study of two online communities that have vigorous community policed comment filtering; one whose participants are predominantly male and another whose participants are predominantly female.<br/><br/>Online communities are rapidly becoming the modern public square and community filtering has the potential to make the space vibrant and useful and/or degenerate into a form of censorship. The health of our civil society and its ability to address large challenges depends on the health of its public discourse. By creating systems for socially intelligent filtering that reflect the community we facilitate diversity, in that minority positions are protected and preserved, while at the same time majority positions have the opportunity to develop and refine cogent arguments necessary for a well reasoned debate."
229,1045306,The Second Workshop on Large-Scale Data Mining: Theory and Applications,IIS,Info Integration & Informatics,07/15/2010,07/13/2010,Christos Faloutsos,PA,Carnegie-Mellon University,Standard Grant,Sylvia Spengler,06/30/2011,"$10,000.00",,christos@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7364,7364,$0.00,"This project will provide travel fellowships to support US students to <br/>attend the 2nd workshop on Large-scale Data Mining: Theory and Applications <br/>(LDMTA) in conjunction with KDD 2010 on July 25, 2010 in Washington DC. The <br/>LDMTA workshop will cover topics on  scalable machine learning and data mining <br/>algorithms, and their applications, such as medical informatics, <br/>telecommunications, social network analysis, and e-commerce. PIs aim at <br/>investigating the scalability and efficiency of existing machine learning and <br/>data mining algorithms with respect to both theoretical and experimental <br/>perspectives. <br/><br/>Due to the recent data explosion in many applications, governments and <br/>companies can easily collect data spanning terabytes, petabytes or more. <br/>Several traditional data mining algorithms need to be replaced, or drastically <br/>re-designed, to handle such volumes through parallel architecture such as <br/>MapReduce/Hadoop. The focus of the workshop is exactly to bridge the gap <br/>between theory and practice of data mining, focusing on the fundamental <br/>research on large-scale data mining theory and applications. The goal of this <br/>workshop is to assemble the leaders in data mining research and industry to <br/>present their views on the need and challenges for large-scale data mining and<br/>also attract graduate students to study on large-scale data mining.<br/>The proposed student support will attract the US students to participate in <br/>this workshop and present their works on topics related to large-scale data <br/>mining, to encourage them to focus on the extremely promising research <br/>direction of large-scale data mining as their thesis research. In particular,<br/>PIs will try to broaden the involvement of female and minority students by<br/>prioritizing the award to them. <br/><br/>For further information about this project see the project website at <br/>http://arnetminer.org/LDMTA2010"
232,1059283,EAGER: Foundations for Predictive Resource Management in Next-Generation Multicore Processor Systems,CCF,COMPUTER ARCHITECTURE,09/15/2010,09/15/2010,Sangyeun Cho,PA,University of Pittsburgh,Standard Grant,Hong Jiang,08/31/2012,"$100,000.00",,cho@cs.pitt.edu,300 Murdoch Building,Pittsburgh,PA,152603203,4126247400,CSE,7941,"7916, 9218, HPCC",$0.00,"Future multicore processor systems will have a growing amount of system-wide shared resources. However, shared resources will present significant undesirable asymmetry. For example, the capabilities of processor cores, cache access latency, and memory access cost will differ depending on the time and the location of their usage. If such asymmetry is not properly managed, the full potential of the multicore computing paradigm will not be achieved. This exploratory research will investigate a novel predictive resource management framework called MAESTRO. The proposed framework automatically learns asymmetry in the system and useful application behavior; the learned knowledge is accumulated and refined; and resource management decisions, such as cache capacity allocation, are made in a predictive manner by exploiting the accumulated knowledge. It is expected that MAESTRO's predictive strategies with detailed system and application knowledge will be a more effective solution to new multicore resource management problems than conventional reactive strategies with limited knowledge. The PI will validate this expectation with solid system prototyping and by studying two target resource management problems.<br/> <br/>The project has the potential to impact the way future computer systems are designed and managed. It is inter-disciplinary by nature and requires understating of applications, computer architecture, OS and machine learning. Students working on this project will receive rigorous inter-disciplinary training."
233,1050448,III: EAGER: Data Integration as a Dialogue with the User,IIS,Info Integration & Informatics,09/01/2010,08/24/2010,Zachary Ives,PA,University of Pennsylvania,Standard Grant,Frank Olken,08/31/2012,"$150,000.00",,zives@cis.upenn.edu,Research Services,Philadelphia,PA,191046205,2158987293,CSE,7364,7916,$0.00,"This work establishes a new approach to providing ad hoc (""discovery"") queries requiring integration and structuring:  such queries help scientists learn possible relationships between topics, and help decision-makers or consumers explore options.  The work develops a new system and underlying architecture based on an iterative process, where the system and user engage in a dialogue until the user has answers meeting his or her information need. <br/><br/>The resulting system takes sources on the Web, discovers semantic relationships among them, and allows users to pose discovery queries.   It leverages existing extraction, matching, and recommendation algorithms as sources of evidence to generate hypotheses and corresponding queries, and adjusts these hypotheses based on user feedback over the query results.  Innovations include scalable models for combining features and learning to re weight hypotheses; query and source recommendation techniques; and means of generalizing tuple-based feedback to support or refute hypotheses. <br/><br/>The research impact is a new paradigm for data integration by end users, which scalably combines machine learning and database concepts.  The broader impact includes better discovery tools for scientific users and other users who sorely need them; improved integration of existing Web data resources; and new educational material on how networks of data can be as important as networks of systems and people.  The PI is incorporating the research concepts into courses in the University of Pennsylvania's new Market and Social Systems Engineering Program, focused on the interface between people, protocols, and systems on the Internet, especially through social and data networks, as well as markets.  More information on the project can be found on the project website at http://www.cis.upenn.edu/~zives/dialogue/"
235,1025177,Multi-Source Visual Analytics,CCF,"GRAPHICS & VISUALIZATION, FOUNDATIONS VISUAL ANALYTICS, MSPA-INTERDISCIPLINARY",08/01/2010,07/31/2010,Jieping Ye,AZ,Arizona State University,Standard Grant,Sankar Basu,07/31/2014,"$498,485.00","Anshuman Razdan, Peter Wonka",jpye@umich.edu,ORSPA,TEMPE,AZ,852816011,4809655479,CSE,"7453, 7703, 7454","7703, 9218, 9215, HPCC",$0.00,"Abstract<br/><br/>Data visualization forms an important aspect of analysis in the field of visual analytics. Analysts rely on visual tools to process massive data sets and discover meaningful patterns in the data. A common strategy for many visualization tools is to transform high-dimensional data to an intermediate lower-dimensional space and then project to screen space using a visualization transformation. For example, a data set with 200 dimensions can be transformed to an intermediate 4D representation and then mapped to screen space by using two-dimensions<br/>for the location and two dimensions to determine shape and color. Therefore, the mathematical foundations of visualization are closely related to the problem of dimensionality reduction.<br/>While dimensionality reduction is a necessary step to visualize the data, the final goal of visual analytics is data analysis, such as searching, clustering, and the detection of outliers. Therefore, there is an urgent need to study dimensionality reduction techniques that are especially useful for data analysis. <br/><br/>This research involves the development and implementation of linear and nonlinear dimensionality reduction algorithms for the transformation and visualization of high-dimensional data. The novel aspect of the transformation is that dimensionality reduction and clustering are performed simultaneously in a joint framework. In addition, this research involves the development and implementation of novel algorithms for multi-source data transformations based on multiple kernel learning (MKL). This addresses the question of fusing a multitude of heterogeneous independently collected data. In the past, most research on MKL has focused on supervised learning. One major contribution of this research is to extend MKL to the unsupervised case. This research presents visual analytics as a bridge between theoretical foundations in machine learning and real-world applications. This research is utilizing two testbed data bases, one consisting of printed documents as might be used by the intelligence community and one based on public health information."
236,952918,CAREER: The Dynamics of Collective Intelligence,IIS,Robust Intelligence,06/01/2010,01/25/2010,Sanmay Das,NY,Rensselaer Polytechnic Institute,Continuing Grant,Edwina L. Rissland,11/30/2012,"$288,082.00",,sanmay@wustl.edu,110 8TH ST,Troy,NY,121803522,5182766000,CSE,7495,1045,$0.00,"This project studies the design of information systems like wikis and information markets. Research in social science has established that often there is a ""wisdom of the crowd"" -- i.e., collectives can display more intelligence than the individuals they are composed of. When such collective information systems work, they serve as superb aggregators and disseminators of information. However, fundamental computational challenges remain in understanding how to design them optimally.<br/><br/>This research is advancing along several lines, including<br/><br/>(1) general theories of how information is aggregated in different social media, developed and validated using real data gathered from existing databases and generated from user experiments; <br/><br/>(2) algorithms for facilitation of user interactions so that the medium in question can deliver the promised results (for example, market-making algorithms for liquidity provision in information markets);<br/><br/>(3) theoretical and practical characterization of the possibilities for rogue users to manipulate collective wisdom systems;<br/><br/>(4) algorithms for detecting malicious users, and mechanisms that thwart miscreants. <br/><br/>The research is naturally interdisciplinary in nature, drawing from machine learning and probabilistic reasoning, data mining and social networks, as well as finance and economics. It contributes to our understanding of complex social phenomena like the growth of information in wikis and blogs, as well as to the development of intelligent reasoning algorithms for agents in complex, uncertain multi-agent environments like markets.<br/><br/>The design of agents that participate in markets and social systems improves the quality of online markets and improves information flow in virtual spaces. Further, insights gained from modeling market structures and social spaces can tell us how to design them better. For example, understanding the impact of different levels of central control on wiki articles or open source software projects yields guidelines for how much central control is optimal in different settings.<br/><br/>In a world where computation and social systems are increasingly intertwined, the PI's research and education program exposes students to multidisciplinary ideas through the introduction of a new class on collective intelligence, social networks and e-commerce, and the development and extensive use of the very objects of study -- information markets and wikis -- in classroom and lab settings. The PI is also developing an experimental project for putting freely accessible course wikis online, similar to online course materials at other universities, but open to editing by the community."
237,1026078,Workshop: 10th International Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+10),IIS,ROBUST INTELLIGENCE,06/01/2010,06/07/2010,Robert Frank,CT,Yale University,Standard Grant,Tatiana D. Korelsky,05/31/2011,"$15,000.00",,bob.frank@yale.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,7495,7495,$0.00,"The past two decades have witnessed the exploration of a range of grammatical formalisms by computational, theoretical, and psycho linguists, for their utility in building natural language interfaces and machine translation systems, characterizing the nature of human linguistic knowledge, and constructing models of language processing.  Because many of these formalisms share important formal and linguistic properties (most prominently, mild context-sensitivity and lexicalization), there are many potential synergies, computational, theoretical and psychological, that can be gotten by considering ideas that stem from work outside of particular formalism.   Moreover, though theoreticians, computationalists, and psychologists are concerned with solving different problems, ideas that derive from one community often turn out to have a significant consequences for the others.  <br/><br/>The goal of this NSF-sponsored workshop, which will take place at Yale University on June 10-12, 2010, is to foster both of these types of connections: across the formalism divide and the theoretical-computational-psycho divide.   The Tree-Adjoining Grammar community has a history of exploring these connections, and this workshop aims to expand the community of researchers involved in such cross-pollination even further.  The workshop will bring together researchers from the Tree-Adjoining Grammar, Minimalism, Categorial Grammar, Dependency Grammar, HPSG,  and LFG  communities to look at the similarities and differences of the formalisms, with the goals of developing shared, broad-coverage grammars, transferring parsing and machine learning algorithms from one formalism to another. and gaining new insights into the properties of different formalisms and their capacity for linguistic and psycholinguistic explanation. <br/><br/>This award provides support crucial to attract to the workshop not only prominent researchers, who will give invited presentations and tutorial lectures, but also, and perhaps even more importantly, PhD students.  By introducing junior researchers to the fruitfulness of cross-framework and cross-disciplinary interactions at an early stage in their careers, our hope is that the award will have a transformative effect on the kind of work they will engage in during their entire careers, potentially leading to a broader, more integrated perspective in the field at large."
239,1018733,RI: Small: Probabilistic Models for Reconstructing Ancient Languages,IIS,"LINGUISTICS, ROBUST INTELLIGENCE",08/15/2010,08/16/2010,Dan Klein,CA,University of California-Berkeley,Standard Grant,Tatiana Korelsky,07/31/2014,"$460,143.00",Thomas Griffiths,klein@cs.berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947101749,5106433891,CSE,"1311, 7495",7923,$0.00,"One of the oldest problems in linguistics is to reconstruct ancient protolanguages on the basis of their modern descendants. Identifying ancestral word forms makes it possible to evaluate proposals about the nature of language change and to draw inferences about human prehistory.  Currently, linguists painstakingly reconstruct protolanguages by hand, using knowledge of the relationships between languages and the plausibility of sound changes.  This research project develops statistical, computational methods that automate or augment the reconstruction process.  Unlike past computational approaches, these new models use detailed phonological representations to infer hidden sound changes. Moreover, they automatically infer which words are co-descendent (cognates).  <br/><br/>These advances, combined with new algorithms for large-scale statistical inference, enable the analysis of orders of magnitude more data than prior work.  The models from this project significantly expand the computational tools available to linguists; large-scale reconstructions make it possible to collect quantitative data to help answer long-standing questions about language change.  Beyond word reconstruction, the models and tools from this project will be useful for other related applications, such as machine translation, where reconstructions can be used to fill gaps in the mapping between the vocabularies of different languages, and the alignment of biological sequences, which requires considering which regions in those sequences are co-descendent.  In addition, the technical advances in probabilistic modeling and approximate inference methods will have cross-cutting implications for a range of modeling problems in computational linguistics, bioinformatics, statistics, machine learning, and cognitive science."
241,1017961,SHF: Small: Exploring Statistical Models to Optimize Hardware and Software under Processor Reliability Constraints,CCF,"COMPUTER ARCHITECTURE, EPSCoR Co-Funding",08/01/2010,08/10/2010,Lu Peng,LA,Louisiana State University,Standard Grant,tao li,07/31/2015,"$374,424.00",Bin Li,lpeng@lsu.edu,202 Himes Hall,Baton Rouge,LA,708032701,2255782760,CSE,"7941, 9150","9150, 9215, 9218, HPCC",$0.00,"With technology scaling coupled with increasing power densities, modern processors suffer from potential soft errors and hard errors. The reliability analysis of such multi-threaded processors, e.g. Simultaneous Multithreading (SMT) and Chip-Multiprocessors (CMP), where inter-thread resource contention exists, is a relatively unexplored area. Furthermore, the modeling complexity is exacerbated by two additional factors: (1) increasing number of cores in a chip; and (2) heterogeneity brought by manufacturing process variation. Software wise, traditional compiler designs are aimed at providing high performance and recently low power when generating object codes. With increasing hardware vulnerabilities, however, high performance computing programs suffer from unexpected errors and exceptions, which might be mitigated by using fault-tolerance techniques such as error detections and check pointing, but still eventually hurt their performance. Apart from a reliable hardware platform, software designers can further improve system reliability by generating error resilient codes. Moreover, analysis of software's architectural vulnerability is still in an ad hoc stage. Therefore, this project proposes a predictive framework to handle the above challenges by employing modern statistical and machine learning methods. The outcomes of this project include a predictive framework which guides for reliable software and hardware optimization and its applications to high performance computing.<br/><br/>The broader impact plans include outreach activities and undergraduate and graduate training. The interdisciplinary nature of the proposed work allows students to learn cutting-edge knowledge from different areas to broaden their scope of training as well as to enhance their productivity. Students from the under-represented groups will be encouraged and given priorities for joining the project."
242,1005175,REU Site:  EcoInformatics Summer Institute,OAC,"RSCH EXPER FOR UNDERGRAD SITES, , , ",09/01/2010,09/07/2012,Desiree Tullos,OR,Oregon State University,Continuing Grant,Almadena Chtchelkanova,08/31/2013,"$296,784.00",Julia Jones,desiree.tullos@oregonstate.edu,OREGON STATE UNIVERSITY,Corvallis,OR,973318507,5417374933,CSE,"1139, J103, J243, K629","7736, 9215, 9250, HPCC",$0.00,"The objectives of this REU Site are to (1) Train students from ecosystem, earth,  engineering, mathematics, and computer sciences in collaborative interdisciplinary research and professional development, (2) Forestall the flight of US citizens from STEM (science, technology, engineering, and mathematics) disciplines by recruiting qualified, diverse students to engage in ecological problems requiring computer, mathematical sciences and engineering input, and (3) Conduct research to develop and apply novel techniques in computer science, engineering, and mathematics to solve natural resource management problems, allowing informatics to enable the science and the science to enable tool development.  We will achieve these objectives through structured research experiences, thematic and professional development seminars, exchanges with other REU sites, immersive field experiences, and mentoring and development of collegial relationships.  Students will be recruited from ecology, geosciences, engineering, mathematics, and computer science. We will actively recruit Native, Black, and Hispanic Americans and will provide all students with high quality mentoring, graduate school fellowship opportunities, and, and career counseling so they will enter the work force equipped to make key contributions to natural resources management and policy. We intend to provide students with skills for today?s science environment where information technology and models are essential parts of ecosystem management.  <br/> <br/>Mentored by teams of interdisciplinary scientists, participants will address three key research themes: (1) regional climate change and vegetation ""landform"" atmosphere interactions using sensor networks, computer visualization, mathematical models, and field studies of climate and vegetation; (2) landscape-scale changes in species distributions using bioacoustics, machine learning, and large datasets of birds and insects; and (3) network-scale river restoration using fiber optic temperature sensors, physical models of channel hydraulics, and mathematical modeling.   Each theme integrates ecological principles, field experiences, novel engineering techniques, new developments in computer science, and mathematical modeling and problem solving.    <br/><br/>This REU site will serve as a national model for transforming the education of undergraduates to embrace Ecosystem Informatics (EI) as both a set of tools and a mindset for approaching and solving natural resources problems in an interdisciplinary context.   The activities will advance discovery while promoting training and learning in key social issues including climate change, ecological change, and restoration.  It will recruit and train underrepresented minorities, enhance infrastructure and programs at the Andrews Forest LTER and OSU Wave Lab, link with an IGERT and REUs at OSU, and disseminate management and policy implications to USFS partners.    <br/>"
243,964416,RI: Medium:  Active Scene Interpretation by Entropy Pursuit,IIS,ROBUST INTELLIGENCE,07/01/2010,06/15/2011,Donald Geman,MD,Johns Hopkins University,Continuing grant,Jie Yang,06/30/2014,"$794,824.00","Rene Vidal, Laurent Younes",geman@jhu.edu,1101 E 33rd St,Baltimore,MD,212182686,4439971898,CSE,7495,"7495, 7924",$0.00,"This project develops a new strategy for scene interpretation, especially for annotating cluttered scenes with instances from many object categories (e.g., a kitchen scene) and videos of people interacting with objects in everyday life (e.g., cooking). The research team develops a statistical model for scene interpretations and image measurements. One component of the model is a prior distribution on a huge interpretation vector. Each bit of this vector represents a high-level scene attribute with widely varying degrees of specificity and resolution ? some are very coarse (general hypotheses) and some are very fine (specific hypotheses). The other component is a simple conditional data model for a corresponding family of learned binary classifiers, one per bit. The scene interpretation is then computed by assessing hypotheses in a highly coarse-to-fine manner, using an image parsing algorithm called ?entropy pursuit? based on stepwise uncertainty reduction, and classifiers for detecting events in spatiotemporal volumes which leverage on recent advances at the intersection of machine learning and dynamical systems.  The computational models and scene parsing algorithms developed in this project are broadly applicable to scene interpretation problems arising in many areas of science and engineering. Specific applications include home surveillance and security, assisted home living, infant and elderly care, etc. The project also provides research opportunities for graduate students in underrepresented minorities and even high school students."
244,1017149,TC: Small: Collaborative Research: User-Centric Privacy Control for Collaborative Social Media,CNS,TRUSTWORTHY COMPUTING,09/01/2010,03/19/2013,H. Jagadish,MI,Regents of the University of Michigan - Ann Arbor,Standard Grant,Sylvia Spengler,08/31/2015,"$226,654.00",,jag@umich.edu,3003 South State St. Room 1062,Ann Arbor,MI,481091274,7347636438,CSE,7795,7923,$0.00,"Social-networking sites (e.g., Facebook, MySpace, LinkedIn, etc.) and other online collaborative tools have emerged as places where people can post and share information.  This information-sharing has many benefits, ranging from practical  (e.g., sharing a business document) to purely social (e.g., communicating with distant friends). At the same time, information sharing inevitably poses significant threats to user privacy. In social-networking sites, for example, documented threats range from identity theft to digital stalking and personalized spam.  As a result, a growing number of such sites allow individual users to specify fine-grained policies that indicate who can access their data, and to what extent. However, studies have consistently shown that most end-users find the task of specifying access-control policies for their own data overwhelming; as a result, users often skip the process altogether.<br/><br/><br/>The goal of this project is to help collaborative and social-media users gain control of their data.  To that end, the project will include three main components: assisted specification, feedback, and refinement recommendations.  To assist users in initially specifying access-control policies for their data, the project will develop a ""privacy wizard,"" which employs data mining and machine learning methods, including active learning, to construct an accurate policy, with minimal input from the user.  To provide feedback regarding existing privacy settings, the project will pursue two approaches: aggregate scores and visualizations.  For example, an aggregate score can be used to concisely explain to the user how her settings differ from those of other users.   Preliminary work found that Item Response Theory (IRT) can be used effectively for this purpose.  Finally,  the project will consider how aggregate scores and visual feedback can be enriched with recommendations for refinements to help the user achieve an expressed level of social exposure.<br/><br/>Online collaborative tools and social media offer great promise in a number of arenas. In addition to communicating with friends via social networking sites, collaborative tools are now used in fields as diverse as business, medicine and education. However, the absence of usable privacy and access control prevents such tools from realizing their full potential.  Results of this project will be disseminated via prototype implementations, as well as research publications. New undergraduate and graduate curriculum modules will also increase awareness of the importance of policy-specification and emerging research in this area."
246,964302,"III:  Medium:  Collaborative Research:  Integrating Behavioral, Geometrical and Graphical Modeling to Simulate and Visualize Urban Areas",IIS,GRAPHICS & VISUALIZATION,09/01/2010,06/14/2011,Daniel Aliaga,IN,Purdue University,Continuing grant,Ephraim Glinert,08/31/2014,"$449,818.00",Bedrich Benes,aliaga@cs.purdue.edu,Young Hall,West Lafayette,IN,479072114,7654941055,CSE,7453,7924,$0.00,"In this project, the PI and his team will develop a new simulation framework to interactively model and visualize socio-economic and geometric characteristics of urban areas.  The framework will consist of a synergistic collaboration of three different areas: behavioral urban modeling, probabilistic graphical modeling, and visualization and computer graphics.  In machine learning and statistics, the area of probabilistic graphical modeling offers a flexible framework to build, estimate and simulate from models of substantial complexity and scale, with partially observed data.  By accounting for uncertainty and interdependencies, including aspects of dynamic equilibrium that arise in modeling the complex spatio-temporal dynamics of urban areas, the PI argues there is significant potential for breakthroughs in modeling large-scale urban systems.  Similarly, by integrating behavioral and geometrical dimensions of urban areas, he expects to exploit the power of behavioral simulations more effectively by filling in geometric details that behavioral models are not well suited to manage, and at the same time provide a powerful framework to generate 2D and 3D geometric representations of urban areas that are behaviorally and geometrically consistent.  The PI will take advantage of massive datasets available for urban areas, including parcel and building inventories, business establishment inventories, census data, household surveys, and GIS data on physical and political features, and will fuse these data into a coherent and consistent database to support his modeling objectives.  This data fusion will address imputation of missing data, accounting for complex spatial and relational connections among the data sources.  The PI will evaluate the accuracy and usability of his system through several deployments in diverse contexts.  The PI has elicited engagement from the Urban Land Institute, the European Research Council, and the Council for Scientific and Industrial Research.  Several organizations in the San Francisco Bay Area in California and the Puget Sound region in Washington will serve as testbeds for the research. Finally, the PI will collaborate with other NSF-funded research projects, such as the Drought Research Initiative Network, in order to investigate correlations between urban development and water/drought. <br/><br/>Broader Impacts:  The results of this multidisciplinary project will have a transformative effect on the area of urban simulation, in that they will enable non-professionals as well as the general public to better understand urban phenomena.  City planners, researchers, students, and citizens will be able to efficiently simulate urban processes not previously possible, and to visualize the effects of adopting different urban policies on urban livability and sustainability outcomes, and to address local and global concerns regarding equity, infrastructure, and economic development.  The framework will provide interactive desktop and web-based interfaces for configuring urban scenario inputs to a simulation that may reach petabytes in data size, and to visualize the simulation results using 2D aerial views, 3D city walkthroughs, and choroplethic maps and tables of indicators portraying the simulated area.  Thus, the work will also advance the fields of visualization and computer graphics, through development of new techniques for large-scale urban modeling and rendering.  The PI will develop an open-source system to make the results of this research widely available."
248,940575,BPC-LSA: Scaling and Adapting Computing Alliance of Hispanic-Serving Institutions (CAHSI) Initiatives,CNS,"SPECIAL PROJECTS - CISE, BROADENING PARTIC IN COMPUTING",02/01/2010,12/21/2011,Miguel Alonso Jr,FL,Miami Dade College,Continuing grant,Janice Cuny,01/31/2014,"$970,219.00","Rocio Guillen-Castrillo, Danmary Albertini, Andres Figueroa, James Poe",malonsoj@fiu.edu,300 NE 2nd Avenue,Miami,FL,331322204,3052373910,CSE,"1714, 7482","9218, HPCC",$0.00,"Miami Dade College, California State University San Marco, and the University of Texas Pan-American propose a program-called SACI for ""Scaling and Adapting Computing Alliance of Hispanic-Serving Institutions (CAHSI) Inititatives"" which will join with CAHSI and apply CAHSI best practices to advance student success among Hispanics and other groups underrepresented in computing fields. CAHSI is an NSF-funded Alliance with seven universities that has developed and demonstrated the effectiveness of a series of initiatives. The SACI partners will adapt five CAHSI strategies: (1) a new introductory course designed to attract students and prepare them for majors in computing fields, (2) a peer-led team learning structure, to provide academic support and motivation for students to persist in computing disciplines, (3) an affinity research group model, to promote undergraduate retention through early research experiences and prepare students for success in upper-division and graduate studies, (4) faculty and peer mentoring, to improve student retention and success, and (5) outreach workshops, to stimulate interest in computing careers among high school and undergraduate students and to disseminate project research and evaluation findings.  SACI will join CAHSI, significantly extending the Alliance and its impact, and leveraging the Alliance's educational and research strengths; SACI will participate in the CAHSI Alliance-wide evaluation."
249,1017529,TC: Small: Collaborative Research: User-centric Privacy Control for Collaborative Social Media,CNS,TRUSTWORTHY COMPUTING,09/01/2010,08/02/2010,Evimaria Terzi,MA,Trustees of Boston University,Standard Grant,Sylvia J. Spengler,08/31/2014,"$247,323.00",,evimaria@bu.edu,881 COMMONWEALTH AVE,BOSTON,MA,22151300,6173534365,CSE,7795,7923,$0.00,"Social-networking sites (e.g., Facebook, MySpace, LinkedIn, etc.) and other online collaborative tools have emerged as places where people can post and share information. This information-sharing has many benefits, ranging from practical (e.g., sharing a business document) to purely social (e.g., communicating with distant friends). At the same time, information sharing inevitably poses significant threats to user privacy. In social-networking sites, for example, documented threats range from identity theft to digital stalking and personalized spam. As a result, a growing number of such sites allow individual users to specify fine-grained policies that indicate who can access their data, and to what extent. However, studies have consistently shown that most end-users find the task of specifying access-control policies for their own data overwhelming; as a result, users often skip the process altogether.<br/><br/><br/>The goal of this project is to help collaborative and social-media users gain control of their data. To that end, the project will include three main components: assisted specification, feedback, and refinement recommendations. To assist users in initially specifying access-control policies for their data, the project will develop a ""privacy wizard,"" which employs data mining and machine learning methods, including active learning, to construct an accurate policy, with minimal input from the user. To provide feedback regarding existing privacy settings, the project will pursue two approaches: aggregate scores and visualizations. For example, an aggregate score can be used to concisely explain to the user how her settings differ from those of other users. Preliminary work found that Item Response Theory (IRT) can be used effectively for this purpose. Finally, the project will consider how aggregate scores and visual feedback can be enriched with recommendations for refinements to help the user achieve an expressed level of social exposure.<br/><br/>Online collaborative tools and social media offer great promise in a number of arenas. In addition to communicating with friends via social networking sites, collaborative tools are now used in fields as diverse as business, medicine and education. However, the absence of usable privacy and access control prevents such tools from realizing their full potential. Results of this project will be disseminated via prototype implementations, as well as research publications. New undergraduate and graduate curriculum modules will also increase awareness of the importance of policy-specification and emerging research in this area."
250,959958,MRI-R2: Acquisition of Robots and Robot Accessories for Interdisciplinary Faculty and Student Research at Fayetteville State University,CNS,MAJOR RESEARCH INSTRUMENTATION,05/01/2010,02/08/2012,Sambit Bhattacharya,NC,Fayetteville State University,Standard Grant,Rita V. Rodriguez,04/30/2013,"$175,092.00","Daniel Montoya, Michael Almeida, Bogdan Czejdo",sbhattac@uncfsu.edu,1200 Murchison Road,Fayetteville,NC,283014252,9106721141,CSE,1189,6890,"$175,092.00","""This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).""<br/>Proposal #: 09-59958<br/>PI(s):  Bhattacharya, Sambit; Almeida, Michael; Czejdo, Bogdan, D.; Montoya, Daniel<br/>Institution: Fayetteville State University <br/>Title:  MRI-R2: Acq. of Robots and Robot Accessories for Interdisciplinary Faculty and Student Research<br/>Project Proposed:<br/>This project, acquiring four research grade robot platforms along with accessories required for navigation, robot vision, and robot-human interaction within a hybrid architecture, enables research in mobile reactive and hybrid robots. It also forms the basis of a robotics laboratory for conducting such research.<br/>The work addresses research in the following areas: spatial and temporal representation and reasoning using cognitive maps, stereo vision and object recognition, rapid modification and testing for correctness of reactive behaviors, and human experience of embodiment using robots.  Although the institution currently utilizes educational robots in teaching activities, a robot platform suitable for human-robot interaction research is needed.  Currently, no advanced robotics research facility exists at FSU or other local universities.<br/>The acquisition of this equipment for a Robotics Lab strengthens interdisciplinary collaboration between the Departments of Psychology and Mathematics and Computer Science. Students in Psychology benefit from learning about computer hardware components and programming algorithms, while students in Computer Science learn about and work with concepts of cognitive psychology. A room within the science building at FSU is currently being refurbished to conduct the research projects described in this proposal, and store the robots.  The PI and a co-PIs are responsible for installation of the robots at FSU.  Most accessory and software installation in the robot bases will mainly be done by the vendor before shipping, so very little time and effort will be required to get started using the robots.  Since one robot base will be used per project described in the proposal, there is no initial allocation needed.  A long term maintenance contract from the vendor is included as part of the proposal.<br/>Broader Impacts: <br/>The equipment enables research activities involving undergraduate and graduate students, contributing to train them in advanced scientific research methodology and application development.  This training benefits students from segments of population who are traditionally underrepresented in the STEM disciplines since FSU is a minority serving institution. The existing facilities at FSU are adequate for introductory programming and behavior based robotics courses.  This new equipment and the space committed by the university to support the project enables advanced research and training.  The activities supported by the equipment strengthen research at FSU.  The new equipment will be available to regional faculty who are interested in conducting research in robotics and related fields."
251,1016668,III: Small: An Automatic Framework for Processing Drosophila Embryonic Images,IIS,"Info Integration & Informatics, EPSCoR Co-Funding",10/01/2010,09/16/2010,Qi Li,KY,Western Kentucky University Research Foundation,Standard Grant,Sylvia Spengler,09/30/2013,"$78,557.00",,qi.li@wku.edu,Western Kentucky University,Bowling Green,KY,421011016,2707454652,CSE,"7364, 9150","7923, 9150",$0.00,"High resolution embryonic images, e.g., the data set BDGP (Berkley Drosophila Genome Project), have been introduced as an important tool for the discovery of gene-gene interaction. These images contain not only temporal information of a gene but also precise spatial information of expression regions of genes. So the biologic problem of the discovery of gene-gene interaction can be characterized as a computational problem of matching expression patterns of embryos at the same developmental stage. It is, however, very challenging to design a fully automatic computational system due to severe imaging and artificial variations in embryonic images. Current research on embryonic image processing involves significant manual manipulation or addresses only a small subset of variations. In this proposal, I propose a comprehensive automatic framework to achieve the three fundamental tasks: image standardization, stage determination, and expression pattern modeling. The proposed project will essentially advance the integration of biologic, image processing and pattern recognition, and machine learning. The PI will develop a series of analysis modules to standardize the variation across images, provide for inpainting, and provide estimates of the boundaries of embryos.  The expression pattern modeling will develop discriminate features to address issues of distinguishing specific pixels in varied refraction circumstances.  A key concept is to develop an imbalance point detection scheme that will minimize the occurrences of edge points and provide a measure of the imbalance degree.<br/><br/>These methods should be adaptable for analysis of images from other model species, e.g., mouse. The proposed work will directly facilitate basic and applied research on image processing crucial to biological image analysis. The challenges in analyzing developmental biological images as compared to natural images have created increasing demands on and opportunities for developing novel image processing techniques. The algorithms and tools developed in this project will have made available to the community. This project will also facilitate the development of new courses and laboratory infrastructure for knowledge discovery from biological data."
254,953943,CAREER: A Multi-Disciplinary Approach to the Next Generation of Collaborative Technologies,IIS,HCC-Human-Centered Computing,01/01/2010,04/15/2014,Darren Gergle,IL,Northwestern University,Continuing Grant,William Bainbridge,06/30/2015,"$501,918.00",,dgergle@northwestern.edu,750 N. Lake Shore Drive,Chicago,IL,606114579,3125037955,CSE,7367,"1045, 1187, 7367, 9215, 9251, HPCC",$0.00,"This research aims to enable the development of the next generation of collaborative technologies and to study their effects on human collaboration. It does so by improving our theoretical understanding of how various features of shared visual context affect communication, coordination and collaboration. The research develops and makes available the code for a new dual eye tracking methodology that can be used to study coordination and collaboration. It also develops a new set of metrics that can be more generally used to understand coordinated eye movements as they relate to dialogue and conversation. The results of this work will add to knowledge in a number of disciplines, including human-computer interaction, language technologies, computer science, computational linguistics, communication studies, cognitive science, and social and cognitive psychology.<br/><br/>As recent efforts in telemedicine, distance education, and remote training and repair attest, there exists enormous potential for technologies to support these activities at a distance, ultimately resulting in widespread benefits such as equal access to quality education and medical care. The education activities in this research include: (1) developing a new Ph.D. course that teaches a theory-driven design approach; (2) developing a series of course modules that use the dual eye tracking methodology to teach behavioral coding, statistics and machine learning; (3) developing a publicly available multimodal corpus with a set of tutorials, and (4) developing a series of international workshops on dual eye tracking. Finally, the research will simultaneously advance discovery and understanding while training both graduate and undergraduate students in interdisciplinary research methods and will contribute to the development of traditionally underrepresented individuals in the fields of computer and information sciences.<br/>"
255,1018321,III: Small: Modeling and Inferring Searcher Intent by Mining User Interactions,IIS,Info Integration & Informatics,09/01/2010,08/01/2010,Yevgeny Agichtein,GA,Emory University,Standard Grant,Maria Zemankova,08/31/2014,"$500,000.00",,eugene.agichtein@emory.edu,"1599 Clifton Rd NE, 4th Floor",Atlanta,GA,303224250,4047272503,CSE,7364,7923,$0.00,"Inferring searcher intent is a central problem in information retrieval and web search: for effective ranking and result presentation, the search engine must know what the user is looking for. Yet, expressing a searcher information need currently relies on entering the ?right? search keywords, which can require multiple rounds of trial-and-error from the searcher. The goal of this project is to develop effective methods for a search engine to automatically infer searcher intent and information needs from the searcher interactions and behavior data. Specifically, the project addresses two main challenges of search intent inference: developing accurate and robust models of searcher intent and behavior, and exploiting these models to infer search intent for each individual user. This project significantly advances previous efforts on implicit feedback and search modeling, by considering a wide range of user interaction and contextual features, and by developing novel techniques for mining and exploiting these signals to improve web search and information access.<br/><br/>To develop robust search intent and behavior models, the project uses machine learning and data mining techniques to model the connection between search actions and result page behavior and the searcher intent. The first stage of the project develops and evaluates these models in controlled lab environments, by combining eye tracking and search interface instrumentation data. The second stage of the project empirically validates the intent inference models through a large-scale collection of search behavior data using a variety of remote user studies with instrumented search interfaces. Finally, the project applies the resulting models and algorithms to improve performance on key information retrieval tasks including result ranking, automatic query expansion, and search result presentation. <br/><br/>The techniques developed in this project are expected to make web search and information access more intuitive and effective for millions of users through collaboration with major search engine companies. Additional broader impacts will be achieved through domain-specific applications of the developed techniques, ranging from improved library search to web-based diagnostics of cognitive impairment. All aspects of the project will involve graduate and undergraduate students, and the resulting tools and datasets are to be integrated into undergraduate course instruction and projects, thus broadening participation in computer science research. The resulting publications, software, and datasets will be made publicly available on the project website (http://ir.mathcs.emory.edu/intent/)."
258,1018463,AF: Small: Algorithm Design Using Spectral Graph Theory,CCF,ALGORITHMS,09/01/2010,11/20/2014,Gary Miller,PA,Carnegie-Mellon University,Standard Grant,Balasubramanian Kalyanasundaram,08/31/2014,"$498,228.00","David Tolliver, Ioannis Koutis",glmiller@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7926,"9150, 9218, HPCC",$0.00,"Spectral Graph Theory or Algebraic Graph Theory, as it is also known, is the study of the relationship between the eigenvalues and eigenvectors of graphs and their combinatorial properties.  The project will focus on furthering our understanding of this relationship and exploit this understanding to design new and efficient algorithms.  Included in this list of algorithmic problems will be fast and reliable linear system solvers and graph partitioners.  These new algorithms will in turn be used to find better and more efficient algorithms for problems in image processing, medical imaging, machine learning, and linear and non-linear optimizations. Enabling technology will include linear-work or O(m log m)-work algorithms for computing extreme eigenvalues of symmetric diagonally dominate systems.  The project will uses ideas and techniques from graph theory such as graph sparsifiers, graph cuts, and Steiner trees.  These graph theoretic ideas will be combined with numerical methods such as Krylov subspaces methods, interior point methods, and preconditioning methods to design and analyze these new algorithms.  When possible, code for the basic algorithms and their applications will be made available over the web to researchers.<br/><br/>The use of Spectral Graph Theory in computer science applications has become  increasingly important and popular. A notable application is the algorithm patented by Google to rank order web pages.  Other applications include image processing, in particular,  medical image segmentation and  denoising.  This project will further contribute to the design of better algorithms for these problem domains by combining the best ideas from numerical analysis and graph theory.  The goal is to design algorithms with very strong guarantees for both run time and robustness so that these algorithms will be appropriate for critical applications such as real-time image processing in a clinician's office. Dissemination will not only include journal and conference publications, but also giving a biannual spectral graph theory class and spectral graph theory lectures in both undergraduate and graduate algorithm classes."
260,1011228,AF: Large: Collaborative Research:  Compact Representations and Efficient Algorithms for Distributed Geometric Data,CCF,COMPUTATIONAL GEOMETRY,09/01/2010,08/22/2010,Leonidas Guibas,CA,Stanford University,Standard Grant,Tracy Kimbrel,08/31/2015,"$432,364.00",,guibas@cs.stanford.edu,450 Jane Stanford Way,Stanford,CA,943052004,6507232300,CSE,7929,"9218, HPCC",$0.00,"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection.  Much of this data has a geometric character, either directly or indirectly.   For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br/><br/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago.  Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems.  An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets.  These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently.  The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br/><br/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties.  Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data).  The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns.  This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network.  Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br/><br/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology."
261,1017362,III-Core:Small: MoveMine: Mining Sophisticated Patterns and Actionable Knowledge from Massive Moving Object Data,IIS,Info Integration & Informatics,09/01/2010,07/23/2015,Jiawei Han,IL,University of Illinois at Urbana-Champaign,Continuing grant,Maria Zemankova,08/31/2016,"$500,000.00",,hanj@cs.uiuc.edu,1901 South First Street,Champaign,IL,618207406,2173332187,CSE,7364,7923,$0.00,"This research project is to investigate principles and methods for uncovering sophisticated patterns and actionable knowledge from massive moving object data.  Thanks to the rapid progress and broad adoption of sensor, GPS, wireless network, and other advanced technologies, moving object data have been accumulating in unprecedented scale. However, moving object data could be dynamic, sparse, scattered, and noisy, and patterns and knowledge to be mined could be deeply hidden, sophisticated, and subtle.  The MoveMine project investigates effective and scalable methods for mining various kinds of complex patterns from dynamic and noisy moving object data, finding multiple interleaved periodic patterns, and performing in-depth multidimensional analysis of moving object data.  It integrates and extends multiple disciplinary approaches derived from spatiotemporal data analysis, data mining, pattern recognition, statistics, and machine learning.  The study takes bird and animal movement data and traffic data as the major sources of data for investigation.  However, developed methods can be applied to the analysis of many other kinds of moving object data for environmental study, traffic control, law enforcement, and protection of homeland security.  The study also addresses the issue of ensuring privacy and security protection while developing powerful pattern and knowledge discovery mechanisms.  The research results are to be published in various research and application forums and be integrated into the educational programs at UIUC.  The progress of the project and the research results are also disseminated via the project Web site (http://www.cs.uiuc.edu/homes/hanj/projs/movemine.htm)."
262,1018769,GV: Small: Collaborative Research: Supporting Knowledge Discovery through a Scientific Visualization Language,IIS,"GRAPHICS & VISUALIZATION, EPSCoR Co-Funding",11/01/2010,09/09/2010,Jian Chen,MS,University of Southern Mississippi,Standard Grant,Maria Zemankova,02/28/2013,"$205,001.00",,chen.8028@osu.edu,2609 WEST 4TH ST,Hattiesburg,MS,394015876,6012664119,CSE,"7453, 9150","7453, 7923, 9150",$0.00,"This collaborative research brings together computer scientists from University of Southern Mississippi (USM) and Brown University and neuroscientists from the University of Mississippi Medical Center (UMMC) to study the design of a scientific visualization language (SVL). Despite the numerous visualization approaches already devised, visualization remains more of an art than a science. Grounded in theories and methods from human-centered computing, machine learning, and cognitive psychology, this work is to develop and evaluate a scientific visualization language (SVL) to provide a principled way to help scientists understand how and why visualizations work. Tools and theories developed in this project can lead to efficient knowledge discovery to help neuroscientists study brains using diffusion tensor magnetic resonance imaging (DTI).<br/><br/>This work has the following specific objectives and outcomes: (1) close collaboration with scientists to discover, refine, and verify a symbol space, (2) a semantic space that describes the relationship among symbols, (3) a testbed that implements SVL for neuroscientists to compose visualizations, (4) development of new and enhanced courses at University of Southern Mississippi and Brown University, and (5) wide dissemination of the research outcomes through open-source software, experimental data, open labs, publications, and presentations.<br/><br/>This project is expected to have broad impact. It may lead to significantly better approaches to human knowledge discovery and decision making in many disciplines where visualizations have found successful application, including neuroscience, biomedicine, bioinformatics, biology, chemistry, geosciences, business, economics, and education. Undergraduate and graduate students are expected to participate in the research through our courses, and student exchanges are planned between USM and Brown. K-12 students can visit the USM lab while the project is in progress. Software and results will be disseminated via the project Web site (https://sites.google.com/site/simplevisualizationlanguage)."
265,1012254,AF: Large: Collaborative Research: Compact Representations and Efficient Algorithms for Distributed Geometric Data,CCF,"ALGORITHMIC FOUNDATIONS, COMPUTATIONAL GEOMETRY",09/01/2010,05/13/2013,Pankaj Agarwal,NC,Duke University,Continuing grant,Tracy J. Kimbrel,08/31/2015,"$448,539.00",,pankaj@cs.duke.edu,"2200 W. Main St, Suite 710",Durham,NC,277054010,9196843030,CSE,"7796, 7929","7925, 9251, 9218, HPCC, 7929",$0.00,"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection. Much of this data has a geometric character, either directly or indirectly. For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br/><br/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago. Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems. An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets. These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently. The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br/><br/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties. Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data). The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns. This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network. Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br/><br/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology."
267,1018006,SHF:  Small:  An Integrated Parallel Constraint Programming Platform for Combinatorial Search Problems,CCF,PROGRAMMING LANGUAGES,08/01/2010,07/28/2010,Neng-Fa Zhou,NY,CUNY Brooklyn College,Standard Grant,Anindya Banerjee,07/31/2015,"$277,065.00",,zhou@sci.brooklyn.cuny.edu,Office of Research & Sponsored P,Brooklyn,NY,112102889,7189515622,CSE,7943,"9150, 9215, HPCC",$0.00,"Many real-world problems, ranging from scheduling in industrial production lines, planning for intelligent robots, protein structure predication, resource allocation, to various network optimization problems are combinatorial search problems. Constraint Programming (CP) and Answer Set Programming (ASP) are emerging techniques for solving these problems. CP over Finite Domains (FD) has had great successes in many application areas, such as scheduling, where use of global constraints is very effective. ASP has been found amenable to knowledge-intensive search problems such as planning and configuration problems. Recently, there has been great interest in parallelizing CP and ASP solvers to take advantage of the power provided by multi-core processors. <br/><br/>This research aims to develop an integrated parallel constraint programming platform for combinatorial search problems. It entails three tasks. Firstly, this research will enhance the power of CLP(FD) (Constraint Logic Programming over FD) by enabling constraints over Composite Finite Domains (CFD). The resulting language, CLP(CFD), allows for natural and efficient modeling of problems with multi-attributed objects. Action Rules (AR), a successful language developed by the PI, will be enhanced and used to implement CLP(CFD). Secondly, this research will develop a compiler to translate ASP programs into AR. For an ASP program, the generated program maintains a partial answer set as a pair of disjoint tuple sets and uses labeling and propagation to compute answer sets. Unlike most ASP solvers, the AR-based solver requires no prior grounding of programs. Thirdly, this research will parallelize AR. Since AR is used as a common intermediate language for both CLP(CFD) and ASP, a parallel implementation of AR will directly result in parallel solvers for CLP(CFD) and ASP. This research will advance the implementation techniques for constraint languages and the resulting system will benefit a wide range of real-world applications."
270,1019104,EAGER: Exploratory Evaluation: Scalability and Effectiveness of Data-Intensive Table-based Computing Software Systems,CCF,"HECURA, ",08/01/2010,08/10/2010,Garth Gibson,PA,Carnegie-Mellon University,Standard Grant,Almadena Chtchelkanova,07/31/2012,"$300,000.00",,garth@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"7952, J147","7916, 9218, HPCC",$0.00,"Science and analysis today are increasingly tackled by systematic exploration of high-resolution captured, or simulated, data. With a more expansive sample of raw data, more detailed models and precise questions of the meaning of the data can be formed.  However, massively parallel systems for processing massive data sets render traditional programming, storage and fault tolerance strategies ineffective.  <br/><br/>Table-based or column-oriented distributed data storage systems are being developed to support such large scale data analysis, led by Google?s BigTable and including open source variations such as Apache Hbase.  These new systems have the flavor of database row and column organization, but have simpler semantics, weaker isolation, and non-SQL interfaces, for example. The effectiveness of these new systems for applications other than internet search support is not well understood.<br/><br/>This exploratory project is developing an evaluation framework and exploring a set of these new table-based storage systems, with the goal of capturing an understanding of the state of the art, how they perform and scale, and their reliability and usability.<br/><br/>In addition to benchmarks focussing on key metrics, the project's evaluation framework includes real world applications drawn from machine learning approaches to understanding streams of events, such as internet blog publications, and approaches to understanding complex interrelationships, such as social networking graphs, in order to extract insight about the requirements needed to enable these emerging types of knowledge discovery applications."
272,1049427,EAGER: Optimization in Wireless Mobile and Sensor Networks: A Novel Paradigm Based on Differential Evolution,CNS,"Special Projects - CNS, Networking Technology and Syst",09/01/2010,05/16/2011,Uday Chakraborty,MO,University of Missouri-Saint Louis,Standard Grant,Thyagarajan Nandagopal,08/31/2012,"$137,137.00",,chakrabortyu@umsl.edu,ONE UNIVERSITY BLVD,SAINT LOUIS,MO,631214400,3145165897,CSE,"1714, 7363","7916, 9178, 9251",$0.00,"This EAGER proposal seeks to develop new, improved approaches, based on single- and multi-objective differential evolution, to the following important problems:<br/>(i) QoS-based multicast routing in mobile networks; (ii) Energy-efficient routing in hierarchical (two-tiered) wireless sensor networks; (iii) Stability-aware clustering in mobile ad hoc networks with special consideration of group mobility; and (iv) Cross-layer optimization in wireless sensor networks by joint routing and link scheduling in the presence of energy constraints, link interference and noise.<br/><br/>The goal is to achieve higher energy saving, better network performance and extended network lifetimes.<br/><br/>The novelty of this proposal is that it brings the power of differential evolution, a cutting-edge strategy in present-day computational intelligence research, to a group of outstanding, NP-hard problems in computer networks. It presents novel schemes for encoding of trial solutions and also for designing the differential operator for these problems. This research cuts across conventional subject lines ? it embodies an interdisciplinary and transformative application of ideas from electrical engineering, computer communications, computational intelligence, and statistical machine learning. This has the potential to open up a radically new direction in networking research.<br/><br/>The broader impact of this research is far-reaching in this era of ubiquitous and pervasive computing. The efficiency, flexibility, and controllability provided in the proposed methods can be used to save costs and improve the quality of the final products in the industry. The proposal also includes well-thought out plans for integrating research and education. The PI will use this project to involve high-school students, women, and undergraduate/graduate students in computer science research."
274,1049139,"Support for US-Based Students to Attend the 2010 IEEE International Conference on Data Mining (ICDM 2010), December 13-17, 2010, Sydney, Australia",IIS,Info Integration & Informatics,09/01/2010,07/15/2010,Xindong Wu,VT,University of Vermont & State Agricultural College,Standard Grant,Maria Zemankova,08/31/2011,"$22,500.00",,xwu@louisiana.edu,85 South Prospect Street,Burlington,VT,54050160,8026563660,CSE,7364,"7556, 9150",$0.00,"This grant provides international travel support for U.S. based graduate student participants to attend the 2010 International Conference on Data Mining (ICDM 2010), which will be held in Sydney, Australia, on December 13-17, 2010. ICDM has established itself as the world's premier research conference in data mining. It provides an international forum for presentation of original research results, as well as exchange and dissemination of innovative, practical development experiences.<br/><br/>The conference seeks to continuously advance the state-of-the-art in data mining, including algorithms, software and systems, as well as related areas such as data management, machine learning and their use in a wide range of applications. With the growth of the Web, wireless communication and data intensive technologies such as sensor networks, social media, multimedia information systems, cloud computing, and application domains such as bioinformatics, climate change, or security, advances in data mining have a significant impact. <br/><br/>A strong representation of U.S. researchers at the Conference is useful in maintaining U.S. competitiveness in this important area. The total number of ICDM participants in the past has been in excess of 300, with a majority of the participants from the U.S., then Europe and Asia. It is expected to provide scholarships to 15 U.S. based graduate student participants. This grant will partially support the travel costs for the U.S. based graduate student participants. <br/><br/>The ICDM proceedings are published by IEEE. The student award results will be announced at the ICDM 2010 conference website (http://datamining.it.uts.edu.au/icdm10/)."
275,968481,Collaborative Research: SoCS:  Analysis of Social Media Driven By Theories of Political Psychology,IIS,"Information Technology Researc, Special Projects - CCF",08/15/2010,08/18/2010,William Cohen,PA,Carnegie-Mellon University,Standard Grant,William Bainbridge,07/31/2013,"$356,349.00",,wcohen@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"1640, 2878",9215,$0.00,"Understanding how people make decisions in complex settings is crucial in many application areas, including marketing, intelligence analysis, and political decision making. Traditionally, human decision-makers are modeled as rational agents seeking to maximize some mathematical measure of utility. In fact, however, people are overwhelmed in information-rich environments, and have developed cognitive and emotional strategies to navigate such environments.  One such strategy is ""motivated reasoning"", where information is first evaluated subconsciously for emotional content, with the goal of maintaining an existing emotional commitment, and cognitive processing of the information is then conditioned on this emotional evaluation. Political scientists have demonstrated motivated reasoning in evaluation of both candidates and issues. In general, decision-making and information-gathering are strongly influenced by emotion, prior knowledge, and the social communities to which a person belongs. Evidence suggests that accurate models of human decision-making must be complex enough to model not only utility, but prior knowledge and beliefs, human cognitive abilities, and social context.  Building such cognitive models requires substantially extending the state-of-the-art in machine learning.<br/><br/>In the past, the ability of researchers in political psychology to develop such complex models of decision-making was limited by the amount of data obtainable obtain from surveys or human-subject experiments. The recent explosion of on-line political communities provides an opportunity to overcome this limitation. We will model human behavior for socially-driven information gathering and decision-making tasks - specifically for political decisions - by combining human-subject experiments with analysis of large datasets of social media and social interactions."
276,1016828,CSR: Small: Adaptive Synchronization for Multicore Systems,CNS,CSR-Computer Systems Research,08/01/2010,07/20/2010,Michael Spear,PA,Lehigh University,Standard Grant,Marilyn McClure,07/31/2014,"$250,025.00",,spear@cse.lehigh.edu,Alumni Building 27,Bethlehem,PA,180153005,6107583021,CSE,7354,7923,$0.00,"Transactional Memory (TM) is among the most promising techniques for simplifying the development of correct parallel programs.  Dozens of different techniques have been developed to implement TM, with each appearing ideally suited to some combination of application and hardware characteristics.  Unfortunately, when the wrong algorithm is chosen for a workload, pathologically bad performance can result.  <br/><br/>The problem is particularly acute in programs whose behavior varies over<br/>time: the best TM implementation for one phase of execution may be unacceptable during another phase.  This research will create new algorithms for dynamic adaptivity, so that the implementation of TM can be changed repeatedly during program execution, thereby maximizing performance during each program phase.<br/><br/>The research will explore both mechanism and policy.  It will create new algorithms and heuristics for selecting TM implementations.  It will also model the behavior of a wide array of TM algorithms and workloads on multiple architectures, in order to create a knowledge base suitable for guiding adaptivity.  To achieve maximum performance, the research will consider a broad set of characteristics, to include TM implementation details, bottlenecks, and overheads; risk of pathology; properties of the hardware environment; and workload requirements such as frequency of inter-thread synchronization, I/O, and nontransactional access to shared data.  This research will also develop novel static analyses and a dynamic optimization framework to avoid any overhead while providing robust, adaptive TM.  Prototypes and source code will be distributed as open-source software."
277,1017921,GV: Small: Collaborative Research: Supporting Knowledge Discovery Through a Scientific Visualization Language,IIS,"GRAPHICS & VISUALIZATION, EPSCoR Co-Funding",11/01/2010,05/24/2011,Alexander Auchus,MS,University of Mississippi Medical Center,Standard Grant,Maria Zemankova,10/31/2014,"$32,976.00",,aauchus@umc.edu,2500 North State Street,Jackson,MS,392164505,6018155000,CSE,"7453, 9150","7453, 7923, 9150",$0.00,"This collaborative research brings together computer scientists from University of Southern Mississippi (USM) and Brown University and neuroscientists from the University of Mississippi Medical Center (UMMC) to study the design of a scientific visualization language (SVL). Despite the numerous visualization approaches already devised, visualization remains more of an art than a science. Grounded in theories and methods from human-centered computing, machine learning, and cognitive psychology, this work is to develop and evaluate a scientific visualization language (SVL) to provide a principled way to help scientists understand how and why visualizations work. Tools and theories developed in this project can lead to efficient knowledge discovery to help neuroscientists study brains using diffusion tensor magnetic resonance imaging (DTI).<br/><br/>This work has the following specific objectives and outcomes: (1) close collaboration with scientists to discover, refine, and verify a symbol space, (2) a semantic space that describes the relationship among symbols, (3) a testbed that implements SVL for neuroscientists to compose visualizations, (4) development of new and enhanced courses at University of Southern Mississippi and Brown University, and (5) wide dissemination of the research outcomes through open-source software, experimental data, open labs, publications, and presentations.<br/><br/>This project is expected to have broad impact. It may lead to significantly better approaches to human knowledge discovery and decision making in many disciplines where visualizations have found successful application, including neuroscience, biomedicine, bioinformatics, biology, chemistry, geosciences, business, economics, and education. Undergraduate and graduate students are expected to participate in the research through our courses, and student exchanges are planned between USM and Brown. K-12 students can visit the USM lab while the project is in progress. Software and results will be disseminated via the project Web site (https://sites.google.com/site/simplevisualizationlanguage)."
278,964412,"III:  Medium:  Collaborative Research:  Integrating Behavioral, Geometrical and Graphical Modeling to Simulate  and Visualize Urban Areas",IIS,GRAPHICS & VISUALIZATION,09/01/2010,08/12/2011,Paul Waddell,CA,University of California-Berkeley,Continuing grant,Ephraim Glinert,08/31/2014,"$450,000.00",Michael Jordan,waddell@berkeley.edu,Sponsored Projects Office,BERKELEY,CA,947101749,5106433891,CSE,7453,7924,$0.00,"In this project, the PI and his team will develop a new simulation framework to interactively model and visualize socio-economic and geometric characteristics of urban areas.  The framework will consist of a synergistic collaboration of three different areas: behavioral urban modeling, probabilistic graphical modeling, and visualization and computer graphics.  In machine learning and statistics, the area of probabilistic graphical modeling offers a flexible framework to build, estimate and simulate from models of substantial complexity and scale, with partially observed data.  By accounting for uncertainty and interdependencies, including aspects of dynamic equilibrium that arise in modeling the complex spatio-temporal dynamics of urban areas, the PI argues there is significant potential for breakthroughs in modeling large-scale urban systems.  Similarly, by integrating behavioral and geometrical dimensions of urban areas, he expects to exploit the power of behavioral simulations more effectively by filling in geometric details that behavioral models are not well suited to manage, and at the same time provide a powerful framework to generate 2D and 3D geometric representations of urban areas that are behaviorally and geometrically consistent.  The PI will take advantage of massive datasets available for urban areas, including parcel and building inventories, business establishment inventories, census data, household surveys, and GIS data on physical and political features, and will fuse these data into a coherent and consistent database to support his modeling objectives.  This data fusion will address imputation of missing data, accounting for complex spatial and relational connections among the data sources.  The PI will evaluate the accuracy and usability of his system through several deployments in diverse contexts.  The PI has elicited engagement from the Urban Land Institute, the European Research Council, and the Council for Scientific and Industrial Research.  Several organizations in the San Francisco Bay Area in California and the Puget Sound region in Washington will serve as testbeds for the research. Finally, the PI will collaborate with other NSF-funded research projects, such as the Drought Research Initiative Network, in order to investigate correlations between urban development and water/drought. <br/><br/>Broader Impacts:  The results of this multidisciplinary project will have a transformative effect on the area of urban simulation, in that they will enable non-professionals as well as the general public to better understand urban phenomena.  City planners, researchers, students, and citizens will be able to efficiently simulate urban processes not previously possible, and to visualize the effects of adopting different urban policies on urban livability and sustainability outcomes, and to address local and global concerns regarding equity, infrastructure, and economic development.  The framework will provide interactive desktop and web-based interfaces for configuring urban scenario inputs to a simulation that may reach petabytes in data size, and to visualize the simulation results using 2D aerial views, 3D city walkthroughs, and choroplethic maps and tables of indicators portraying the simulated area.  Thus, the work will also advance the fields of visualization and computer graphics, through development of new techniques for large-scale urban modeling and rendering.  The PI will develop an open-source system to make the results of this research widely available."
280,1012042,AF: Large: Collaborative Research:  Compact Representations and Efficient Algorithms for Distributed Geometric Data,CCF,COMPUTATIONAL GEOMETRY,09/01/2010,08/22/2010,Piotr Indyk,MA,Massachusetts Institute of Technology,Standard Grant,Tracy J. Kimbrel,08/31/2014,"$433,000.00",,indyk@mit.edu,77 MASSACHUSETTS AVE,Cambridge,MA,21394301,6172531000,CSE,7929,"9218, HPCC",$0.00,"Across many fields of science, engineering, and business, massive data sets are being generated at unprecedented rate by high-bandwidth sensors and cameras, large-scale simulations, or web-enabled large scale data collection.  Much of this data has a geometric character, either directly or indirectly.   For example, second generation LiDARs can map the earth's surface at 15-20 cm resolution; the Large Synoptic Telescope is set to produce about 30 terabytes of data each night; thirteen hours of video are uploaded to YouTube every minute; Facebook manages over 40 billion photos requiring more than one petabyte of data.<br/><br/>These data sets provide tremendous opportunities to enable novel capabilities that were unimaginable a few years ago.  Capitalizing on these opportunities, however, and transforming these massive amounts of heterogeneous data into useful information for vastly different types of applications and users requires solving challenging algorithmic problems.  An effective way of addressing this challenge is by designing efficient methods for producing informative yet succinct summaries of such geometric data sets.  These summaries must work at multiple scales, and allow a wide variety of queries to be answered approximately but efficiently.  The goal of this project is to study the theoretical underpinnings of compact representations and efficient algorithms for organizing, summarizing, cross-correlating, interlinking, and querying large distributed geometric data sets.<br/><br/>This project will design methods for computing summaries of many kinds of flavors, all with provable properties.  Summaries can be combinatorial and metric (core sets and kernels), algebraic (linear sketches), topological (persistence diagrams), feature-based, and structural (encoding self-similarities in the data).  The properties they aim to capture extend from low-level metric attributes, such as the diameter or width of a point set, to higher-level attributes revealing the internal structure of the data, as in the detection of symmetries and repeated patterns.  This processing must be done in the presence of uncertainty in data coming from sensors, and optimize multiple performance measures, including communication cost for data distributed across multiple locations in a network.  Another key aspect of this project is that it aims to understand not individual data sets in isolation but rather the inter-relationships and correspondences among different data sets, and to do so by communicating only summary information, without even having all the data in one place. <br/><br/>This work touches upon many topics in theoretical computer science and applied mathematics including low-distortion embeddings, compressive sensing, transportation metrics, spectral graph theory or harmonic analysis, machine learning, and computational topology."
282,968295,Collaborative Research:  SoCS: Analysis of Social Media Driven By Theories of Political Psychology,IIS,"INFORMATION TECHNOLOGY RESEARC, SPECIAL PROJECTS - CCF",08/15/2010,08/18/2010,David Redlawsk,NJ,Rutgers University New Brunswick,Standard Grant,William Bainbridge,07/31/2014,"$388,111.00",,redlawsk@udel.edu,33 Knightsbridge Road,Piscataway,NJ,88543925,8489320150,CSE,"1640, 2878",9215,$0.00,"Understanding how people make decisions in complex settings is crucial in many application areas, including marketing, intelligence analysis, and political decision making. Traditionally, human decision-makers are modeled as rational agents seeking to maximize some mathematical measure of utility. In fact, however, people are overwhelmed in information-rich environments, and have developed cognitive and emotional strategies to navigate such environments. One such strategy is ""motivated reasoning"", where information is first evaluated subconsciously for emotional content, with the goal of maintaining an existing emotional commitment, and cognitive processing of the information is then conditioned on this emotional evaluation. Political scientists have demonstrated motivated reasoning in evaluation of both candidates and issues. In general, decision-making and information-gathering are strongly influenced by emotion, prior knowledge, and the social communities to which a person belongs. Evidence suggests that accurate models of human decision-making must be complex enough to model not only utility, but prior knowledge and beliefs, human cognitive abilities, and social context. Building such cognitive models requires substantially extending the state-of-the-art in machine learning. <br/><br/>In the past, the ability of researchers in political psychology to develop such complex models of decision-making was limited by the amount of data obtainable obtain from surveys or human-subject experiments. The recent explosion of on-line political communities provides an opportunity to overcome this limitation. We will model human behavior for socially-driven information gathering and decision-making tasks - specifically for political decisions - by combining human-subject experiments with analysis of large datasets of social media and social interactions."
287,964429,RI: Medium: Collaborative Research: Recognition of Materials,IIS,ROBUST INTELLIGENCE,07/01/2010,06/18/2013,Shree Nayar,NY,Columbia University,Continuing grant,Kenneth C. Whang,06/30/2014,"$285,959.00",,nayar@cs.columbia.edu,2960 Broadway,NEW YORK,NY,100276902,2128546851,CSE,7495,7924,$0.00,"We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.<br/><br/>The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums."
293,964420,RI: Medium: Collaborative Research:  Recognition of Materials,IIS,Robust Intelligence,07/01/2010,06/18/2013,Ko Nishino,PA,Drexel University,Continuing grant,Kenneth Whang,06/30/2015,"$392,638.00",,kon@drexel.edu,"1505 Race St, 10th Floor",Philadelphia,PA,191021119,2158955849,CSE,7495,7924,$0.00,"We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.<br/><br/>The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums."
294,1032683,SDCI Data: Improvement: Java Graphical Authorship Attribution Program (JGAAP),OAC,SOFTWARE DEVELOPEMENT FOR CI,09/01/2010,08/30/2010,Patrick Juola,PA,Duquesne University,Standard Grant,Amy Walton,08/31/2014,"$1,622,036.00",,juola@mathcs.duq.edu,Room 310 Administration Building,Pittsburgh,PA,152193016,4123961537,CSE,7683,7683,$0.00,"Recent developments in machine learning and corpus linguistics have shown it to be possible to make automatic determinations about authorship using statistics; the NSF- funded JGAAP (Java Graphical Authorship Attribution Program) system has been part of these developments.  JGAAP has helped support the emerging authorship attribution community and create a useful tool for a wide variety of scholastic specialties. <br/><br/>Although JGAAP incorporates thousands of possible methods, there are many more in the literature that have been proposed but not rigorously tested. Comparative testing on a large scale will require the development of new methods and test corpora. In addition, there are many key problems to address to meet the needs of the community, such as the open class problem, the adversarial problem, and the coauthorship problem. Finally, we will examine applications of JGAAP and similar systems to key areas in linguistic profiling, such as determining gender, education, native language, psychological profile, medical condition, age (of document or writer), or even attempted deceptiveness.  Again, by applying a rigorous testing method to these new problems and corpora, the project can establish accuracy benchmarks for various techniques (under the various testing conditions), find new combinations resulting in improved techniques, and establish a recommendation for 'best practices.' <br/><br/>Improved authorship attribution will be immediately useful both to scholars and in broader social contexts, such as law enforcement and forensics where there are direct demands for this kind of security technology. The historical/social analysis will also provide better access between the related disciplines of digital humanities, sociology, history, and computer science, providing the basis for a better understanding of traditional humanities issues. Profiling work can help medical and psychological practitioners by providing a non-invasive method to detect certain aspects of a person's mind. The software developed (and the planned development/distribution process) will help improve the effectiveness of both digital humanities scholarship and computer science, especially through the establishment of software review standards and processes. In particular, by providing direct evidence of the conditions and expected error rates involved in various techniques, the information gained will help authorship attribution meet the Daubert criteria for expert evidence, allowing authorship attribution to be used in a formal legal setting. Finally, the funding of this research will help support the unique interdisciplinary Duquesne University Computational Mathematics program, providing a broader access to an unusual and atypical audience for technological education."
295,964562,RI: Medium: Collaborative Research:  Recognition of Materials,IIS,Robust Intelligence,07/01/2010,07/15/2013,Srinivasa Narasimhan,PA,Carnegie-Mellon University,Continuing grant,Kenneth Whang,06/30/2015,"$406,581.00",,srinivas@cs.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,7495,"7495, 7924, 9251",$0.00,"We live in a world made of diverse materials whose variations in appearance enrich our visual experience. It is also this variability of materials that adds daunting complexity to image understanding. This research program aims to establish the theoretical and computational foundation for automatic visual understanding and recognition of real-world materials. The program tackles this challenging problem from three key aspects, namely, deriving 1) novel hybrid physically-based and data-driven representations of the spatial, angular, spectral, temporal, and scale variations of material appearance, 2) active and passive methods for estimating the values of physically-based parameters that govern material appearance, and 3) single-image material recognition methods that leverage physically-based optical parameters as priors or invariants to guide machine learning techniques. These research thrusts lead to a comprehensive set of computational tools to recognize materials in real-world images despite their complex appearance variations, such as recognizing rusted metals, discerning soft cloth from hard concrete, identifying different fat content of milks, and labeling image regions with material traits like soft, hard, rough, and heavy.<br/><br/>The capabilities resulting from this program are crucial to a broad range of scenarios, for instance, to enable humanoid robots to understand that it should not squeeze the soft hands of a child, autonomous vehicles to understand what regions to avoid in a rugged terrain, visual analyses of tissues to help medical diagnosis, and automated inspection systems to reliably discover sub-standard quality food to prevent ill-health. The PIs work with research groups in these specific application areas to closely integrate the results from this project into their efforts. The results from this research are also broadly disseminated via publications, websites, databases, new courses and symposiums."
296,1016623,GV: Small: Collaborative Research: Supporting Knowledge Discovery through a Scientific Visualization Language,IIS,"GRAPHICS & VISUALIZATION, EPSCoR Co-Funding",11/01/2010,04/26/2011,David Laidlaw,RI,Brown University,Standard Grant,Maria Zemankova,10/31/2014,"$268,596.00",,dhl@cs.brown.edu,BOX 1929,Providence,RI,29129002,4018632777,CSE,"7453, 9150","7453, 7923, 9150, 9251",$0.00,"This collaborative research brings together computer scientists from University of Southern Mississippi (USM) and Brown University and neuroscientists from the University of Mississippi Medical Center (UMMC) to study the design of a scientific visualization language (SVL). Despite the numerous visualization approaches already devised, visualization remains more of an art than a science. Grounded in theories and methods from human-centered computing, machine learning, and cognitive psychology, this work is to develop and evaluate a scientific visualization language (SVL) to provide a principled way to help scientists understand how and why visualizations work. Tools and theories developed in this project can lead to efficient knowledge discovery to help neuroscientists study brains using diffusion tensor magnetic resonance imaging (DTI).<br/><br/>This work has the following specific objectives and outcomes: (1) close collaboration with scientists to discover, refine, and verify a symbol space, (2) a semantic space that describes the relationship among symbols, (3) a testbed that implements SVL for neuroscientists to compose visualizations, (4) development of new and enhanced courses at University of Southern Mississippi and Brown University, and (5) wide dissemination of the research outcomes through open-source software, experimental data, open labs, publications, and presentations.<br/><br/>This project is expected to have broad impact. It may lead to significantly better approaches to human knowledge discovery and decision making in many disciplines where visualizations have found successful application, including neuroscience, biomedicine, bioinformatics, biology, chemistry, geosciences, business, economics, and education. Undergraduate and graduate students are expected to participate in the research through our courses, and student exchanges are planned between USM and Brown. K-12 students can visit the USM lab while the project is in progress. Software and results will be disseminated via the project Web site (https://sites.google.com/site/simplevisualizationlanguage)."
300,1017719,TC: Small: THWART: Trojan Hardware in Wireless ICs - Analysis and Remedies for Trust,CNS,"SPECIAL PROJECTS - CISE, TRUSTWORTHY COMPUTING",09/01/2010,06/06/2011,Yiorgos Makris,CT,Yale University,Standard Grant,carl landwehr,09/30/2011,"$507,877.00",,yiorgos.makris@utdallas.edu,Office of Sponsored Projects,New Haven,CT,65208327,2037854689,CSE,"1714, 7795","7923, 9178, 9251",$0.00,"Towards enhancing trustworthiness of wireless integrated circuits, this project investigates the problem of hardware Trojans in the analog/RF domain. Hardware Trojans are maliciously-intended modifications to fabricated integrated circuits, making them capable of additional functionality which is unknown to the designer and user, but which can be exploited by the perpetrator after chip deployment to sabotage or incapacitate it, or to steal sensitive information. The motivation for this research is two-fold: First, partly because of design outsourcing and migration of fabrication to low-cost areas across the globe, and partly because of increased reliance on external intellectual property and design automation software, the integrated circuit supply chain is now considered far more vulnerable to such malicious modifications than ever before. Second, wireless integrated circuits constitute an indispensable part of modern electronic systems and their ability to communicate data (possibly encrypted) over public channels makes them a prime attack candidate. To address this problem, this project focuses on (i) delineating the threat and potential impact of hardware Trojans in wireless cryptographic ICs, (ii) elucidating the shortcomings of existing test methods in exposing them, (iii) developing preventive countermeasures for obfuscating the chip design and complicating the development of hardware Trojans, and (iv) devising efficient hardware Trojan detection methods based on statistical analysis and machine learning. The anticipated impact of this research lies in the attainment of a better understanding of the hardware Trojan threat and in the development of appropriate remedies, thus enabling secure deployment of wireless integrated circuits and fostering technology trustworthiness."
302,968480,SoCS: Collaborative Research: Conversational Dynamics in Online Support Groups,IIS,"Information Technology Researc, SOCIAL-COMPUTATIONAL SYSTEMS",09/15/2010,09/17/2010,John Levine,PA,University of Pittsburgh,Standard Grant,Betty Tuller,08/31/2015,"$112,229.00",,jml@pitt.edu,300 Murdoch Building,Pittsburgh,PA,152603203,4126247400,CSE,"1640, 7953","7752, 7953, 9215, 9251",$0.00,"Health support groups, including those on the internet, can substantially benefit participants, but the social processes responsible for these benefits are unclear.  A team of researchers led by Robert Kraut at Carnegie-Mellon University will explore how the conversational dynamics of online cancer support groups influence group functioning and participant quality of life and will develop computational tools that can be used to analyze online conversations and improve their effectiveness. The research project has four specific goals. (1) To understand how conversational episodes in online support groups facilitate social support. For example, what must a person say to get others to respond empathically? (2) To understand how support in these groups influences group commitment and affects health outcomes. (3) To develop computational tools to make the analysis of large datasets of health conversations tractable. (4) To use these tools to improve the training of support group facilitators.<br/><br/>Online health support groups are popular, being used by about 58% of American adults. Identifying the role of communication in online cancer support groups will provide valuable information to users and facilitators of these groups and will enhance their training. Moreover, a tool for analyzing large corpora of conversational data will facilitate the work of researchers who are interested in conversational behavior in other kinds of online groups"
303,1018374,SHF:  Small:  Open Source Software Components:  Utilization Assessment and Automatic Retrieval,CCF,"Software & Hardware Foundation, SOFTWARE ENG & FORMAL METHODS",08/01/2010,06/01/2012,Cristina Lopes,CA,University of California-Irvine,Continuing Grant,Sol Greenspan,07/31/2015,"$499,619.00",,lopes@ics.uci.edu,"141 Innovation Drive, Ste 250",Irvine,CA,926173213,9498247295,CSE,"7798, 7944","9150, 9215, HPCC",$0.00,"Software quality has been an important but illusive concept for several decades, with experts different, sometimes conflicting, guidelines. Using an ecosystem of about 20,000 open source Java projects, this study will to try to discover correlations between open source component utilization and software quality metrics, in order to provide the strongest empirical evidence yet as to how the several metrics pertaining to software quality correlate with actual utilization of reusable components. This study will provide a scientific basis to some of the existing guidelines and to the dismissal of some others. If no correlations are found, this result will disrupt current conceptualizations of component quality, forcing researchers and developers to reassess their understanding of software quality and reusable components. Software being a foundation of modern society, and Open Source development being a significant movement in society at large, it is critical to gain a deeper understanding of software quality on a global scale, leading to the development of innovative tools and methods.<br/><br/>The metrics used in this study are those defined by the SQO-OSS Quality Model. To understand correlations,  the following method will be used. First the dependency graph will be built, capturing software dependencies at the global scale. This requires overcoming technical challenges in cleaning up and clustering the data, as real world projects contain all sorts of idiosyncrasies related to the use of external components. Second, a suite of utilization metrics will be developed using this global dependency graph that capture the depth and breadth of component usage by these projects. Finally, the SQO-OSS Quality metrics for a significant subset of projects in the data set will be computed and compared with the projects' utilization metrics in order to reveal the correlations."
304,964350,NeTS: Medium: Collaborative Research: A Comprehensive Approach for Data Quality and Provenance in Sensor Networks,CNS,"Networking Technology and Syst, TRUSTWORTHY COMPUTING, Secure &Trustworthy Cyberspace",06/01/2010,05/31/2012,Murat Kantarcioglu,TX,University of Texas at Dallas,Continuing grant,Thyagarajan Nandagopal,05/31/2014,"$150,000.00",,muratk@utdallas.edu,"800 W. Campbell Rd., AD15",Richardson,TX,750803021,9728832313,CSE,"7363, 7795, 8060",7924,$0.00,"Sensor networks enable real-time gathering of large amounts of data that can be mined and analyzed for taking critical actions. As such, sensor networks are a key component of decision-making infrastructures. A critical issue in this context is the trustworthiness of the data being collected. Data integrity and quality decide the trustworthiness of data.  Data integrity can be undermined not only because of errors by users, measurement devices and applications, but also because of malicious subjects who may inject inaccurate data with the goal of deceiving the data users. A fundamental tradeoff exists between data quality and the cost to gather and protect this data, e.g., in terms of sensor node energy. This project focuses on a multi-faceted solution to the problem of assessing integrity of data streams in sensor networks, taking into account cost and energy constraints. Key elements of the solution are: (a) a cyclic framework supporting the assessment of sensor data trustworthiness based on provenance, and sensor trustworthiness based on data that sensors provide; (b) strategies for continuously updating trust scores of sensor data and nodes; (c) a game-theoretic model to analyze and mitigate the risks due to active adversaries that try to undermine data integrity; (d) protocols for sensor network sleep/wake scheduling and routing that balance the data quality and energy efficiency tradeoff. The project also includes the development of tools for assessing data trustworthiness, and experimental evaluation of the system performance.  The research has impact on healthcare, homeland security, and applications in several other domains."
305,968485,SoCS: Collaborative Research: Conversational Dynamics in Online Support Groups,IIS,"Information Technology Researc, SOCIAL-COMPUTATIONAL SYSTEMS",09/15/2010,06/19/2012,Robert Kraut,PA,Carnegie-Mellon University,Standard Grant,Betty Tuller,08/31/2014,"$667,444.00",Carolyn Rose,kraut@andrew.cmu.edu,5000 Forbes Avenue,PITTSBURGH,PA,152133815,4122688746,CSE,"1640, 7953","7752, 7953, 9215, 9251",$0.00,"Health support groups, including those on the internet, can substantially benefit participants, but the social processes responsible for these benefits are unclear.  A team of researchers led by Robert Kraut at Carnegie-Mellon University will explore how the conversational dynamics of online cancer support groups influence group functioning and participant quality of life and will develop computational tools that can be used to analyze online conversations and improve their effectiveness. The research project has four specific goals. (1) To understand how conversational episodes in online support groups facilitate social support. For example, what must a person say to get others to respond empathically? (2) To understand how support in these groups influences group commitment and affects health outcomes. (3) To develop computational tools to make the analysis of large datasets of health conversations tractable. (4) To use these tools to improve the training of support group facilitators.<br/><br/>Online health support groups are popular, being used by about 58% of American adults. Identifying the role of communication in online cancer support groups will provide valuable information to users and facilitators of these groups and will enhance their training. Moreover, a tool for analyzing large corpora of conversational data will facilitate the work of researchers who are interested in conversational behavior in other kinds of online groups"
306,1035866,CPS: Medium: Collaborative Research: Dynamic Routing and Robotic Coordination for Oceanographic Adaptive Sampling,CNS,"Information Technology Researc, CPS-Cyber-Physical Systems",09/15/2010,09/07/2010,Gaurav Sukhatme,CA,University of Southern California,Standard Grant,Radhakisan Baheti,08/31/2015,"$345,000.00",,gaurav@cs.usc.edu,University Park,Los Angeles,CA,900890001,2137407762,CSE,"1640, 7918","7918, 7924",$0.00,"The objective of this research is the design of innovative routing,<br/>planning and coordination strategies for robot networks, and their<br/>application to oceanography.  The approach is organized in three<br/>synergistic thrusts: (1) the application of queueing theory and<br/>combinatorial techniques to networked robots performing sequential tasks,<br/>(2) the design of novel distributed optimization and coordination schemes<br/>relying only on asynchronous and asymmetric communication, (3) the design<br/>of practical routing and coordination algorithms for the USC Networked<br/>Aquatic Platforms.  In collaboration with oceanographers and marine<br/>biologists, the project aims to design motion, communication and<br/>interaction protocols that maximize the amount of scientific information<br/>collected by the platforms.<br/><br/>This proposal addresses multi-dimensional problems of relevance in<br/>Engineering and Computer Science by unifying fundamental concepts from<br/>multiple cyberphysical domains (robotics, autonomy, combinatorics, and<br/>network science).  Our team has expertise in a broad range of scientific<br/>disciplines, including control theory and theoretical computer science and<br/>their applications to multi-agent systems, robotics and sensor networks.<br/><br/>The proposed research will have a positive impact on the emerging<br/>technology of autonomous and reliable robotic networks, performing a broad<br/>range of environmental monitoring and logistic tasks.  Our educational and<br/>outreach objectives are manifold and focus on (1) integrating the proposed<br/>research themes into undergraduate education and research, e.g., via the<br/>existing NSF REU site at the USC Computer Science Department, and (2)<br/>mounting a vigorous program of outreach activities, e.g., via a<br/>well-developed collaboration with the UCSB Center for Science and<br/>Engineering Partnerships."